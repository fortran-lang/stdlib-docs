<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
   <meta name="description" content="A community driven standard library for (modern) Fortran">
    <meta name="author" content="fortran-lang/stdlib contributors" >
    <link rel="icon" href="../favicon.png">

    <title>All Procedures &ndash; Fortran-lang/stdlib
</title>

    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
    <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
    <script src="../js/jquery-2.1.3.min.js"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>

  </head>

  <body>

    <!-- Fixed navbar -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../index.html">Fortran-lang/stdlib </a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href='../page/index.html'>Contributing and specs</a></li>
            <li class="dropdown hidden-xs visible-sm visible-md hidden-lg">
              <a href="#" class="dropdown-toggle"
              data-toggle="dropdown" role="button"
              aria-haspopup="true"
     aria-expanded="false">Contents <span class="caret"></span></a>
        <ul class="dropdown-menu">
            <li><a href="../lists/files.html">Source Files</a></li>
            <li><a href="../lists/modules.html">Modules</a></li>
            <li><a href="../lists/procedures.html">Procedures</a></li>
            <li><a href="../lists/absint.html">Abstract Interfaces</a></li>
                   <li><a href="../lists/types.html">Derived Types</a></li>
       
            </ul>
        
            </li>
<li class="visible-xs hidden-sm visible-lg"><a href="../lists/files.html">Source Files</a></li>
<li class="visible-xs hidden-sm visible-lg"><a href="../lists/modules.html">Modules</a></li>
<li class="visible-xs hidden-sm visible-lg"><a href="../lists/procedures.html">Procedures</a></li>
<li class="visible-xs hidden-sm visible-lg"><a href="../lists/absint.html">Abstract Interfaces</a></li>
                             <li class="visible-xs hidden-sm visible-lg"><a href="../lists/types.html">Derived Types</a></li>
          </ul>
        <form action="../search.html" class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="text" class="form-control" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
        </div>
<!--
        <button type="submit" class="btn btn-default">Submit</button>
-->
        </form>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
      <div class="row">
        <div class="col-lg-12" id='text'>
			 <h1>Procedures</h1>
			 <table class="table table-striped">
			 <thead><tr><th>Procedure</th><th>Location</th><th>Procedure Type</th><th>Description</th></tr></thead>
			 <tbody>
			   <tr><td><a href='../interface/adjustl.html'>adjustl</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Left-adjust the character sequence represented by the string.
The length of the character sequence remains unchanged.</p><a href="../interface/adjustl.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/adjustr.html'>adjustr</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Right-adjust the character sequence represented by the string.
The length of the character sequence remains unchanged.</p><a href="../interface/adjustr.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/all_close.html'>all_close</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Returns a boolean scalar where two arrays are element-wise equal within a tolerance.
(<a href="../page/specs/stdlib_math.html#all_close-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/and.html'>and</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Sets the bits in <code>set1</code> to the bitwise <code>and</code> of the original bits in <code>set1</code>
 and <code>set2</code>. The sets must have the same number of bits
 otherwise the result is undefined.
 (<a href="../page/specs/stdlib_bitsets.html#and-bitwise-and-of-the-bits-of-two-bitsets">Specification</a>)</p><a href="../interface/and.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/and_not.html'>and_not</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Sets the bits in <code>set1</code> to the bitwise and of the original bits in <code>set1</code>
 with the bitwise negation of <code>set2</code>. The sets must have the same
 number of bits otherwise the result is undefined.</p><a href="../interface/and_not.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/arange.html'>arange</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p><code>arange</code> creates a one-dimensional <code>array</code> of the <code>integer/real</code> type 
 with fixed-spaced values of given spacing, within a given interval.
(<a href="../page/specs/stdlib_math.html#arange-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/arg.html'>arg</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p><code>arg</code> computes the phase angle in the interval (-π,π].
(<a href="../page/specs/stdlib_math.html#arg-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/arg_select.html'>arg_select</a></td><td><a href='../module/stdlib_selection.html'>stdlib_selection</a></td><td>Interface</td><td><p>(<a href="..//page/specs/stdlib_selection.html#arg_select-find-the-index-of-the-k-th-smallest-value-in-an-input-array">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/argd.html'>argd</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p><code>argd</code> computes the phase angle of degree version in the interval (-180.0,180.0].
(<a href="../page/specs/stdlib_math.html#argd-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/argpi.html'>argpi</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p><code>argpi</code> computes the phase angle of circular version in the interval (-1.0,1.0].
(<a href="../page/specs/stdlib_math.html#argpi-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/assignment%28%3D%29.html'>assignment(=)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Assign a character sequence to a string.</p></td></tr>
			   <tr><td><a href='../interface/assignment%28%3D%29~2.html'>assignment(=)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Used to define assignment for <code>bitset_large</code>.
 (<a href="../page/specs/stdlib_bitsets.html#-compare-two-bitsets-to-determine-whether-the-bits-have-the-same-value">Specification</a>)</p><a href="../interface/assignment%28%3D%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/axpy.html'>axpy</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>AXPY: constant times a vector plus a vector.</p></td></tr>
			   <tr><td><a href='../interface/bbcsd.html'>bbcsd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>bidiagonal-block form,
[ B11 | B12 0  0 ]
[  0  |  0 -I  0 ]
X = [----------------]
[ B21 | B22 0  0 ]
[  0  |  0  0  I ]
[  C | -S  0  0 ]
[ U1 |    ] [  0 |  0 -I  0 ] [ V1 |    ]**H
= [---------] [---------------] [---------]   .
[    | U2 ] [  S |  C  0  0 ] [    | V2 ]
[  0 |  0  0  I ]
X is M-by-M, its top-left block is P-by-Q, and Q must be no larger
than P, M-P, or M-Q. (If Q is not the smallest index, then X must be
transposed and/or permuted. This can be done in constant time using
the TRANS and SIGNS options. See CUNCSD for details.)
The bidiagonal matrices B11, B12, B21, and B22 are represented
implicitly by angles THETA(1:Q) and PHI(1:Q-1).
The unitary matrices U1, U2, V1T, and V2T are input/output.
The input matrices are pre- or post-multiplied by the appropriate
singular vector matrices.</p></td></tr>
			   <tr><td><a href='../interface/bdsdc.html'>bdsdc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>N-by-N (upper or lower) bidiagonal matrix B:  B = U * S * VT,
using a divide and conquer method, where S is a diagonal matrix
with non-negative diagonal elements (the singular values of B), and
U and VT are orthogonal matrices of left and right singular vectors,
respectively. BDSDC can be used to compute all singular values,
and optionally, singular vectors or singular vectors in compact form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See DLASD3 for details.
The code currently calls DLASDQ if singular values only are desired.
However, it can be slightly modified to compute singular values
using the divide and conquer method.</p></td></tr>
			   <tr><td><a href='../interface/bdsqr.html'>bdsqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>left singular vectors from the singular value decomposition (SVD) of
a real N-by-N (upper or lower) bidiagonal matrix B using the implicit
zero-shift QR algorithm.  The SVD of B has the form
B = Q * S * P<strong>H
where S is the diagonal matrix of singular values, Q is an orthogonal
matrix of left singular vectors, and P is an orthogonal matrix of
right singular vectors.  If left singular vectors are requested, this
subroutine actually returns U*Q instead of Q, and, if right singular
vectors are requested, this subroutine returns P</strong>H<em>VT instead of
P</em><em>H, for given complex input matrices U and VT.  When U and VT are
the unitary matrices that reduce a general matrix A to bidiagonal
form: A = U</em>B<em>VT, as computed by CGEBRD, then
A = (U</em>Q) * S * (P<strong>H*VT)
is the SVD of A.  Optionally, the subroutine may also compute Q</strong>H*C
for a given complex input matrix C.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3 (or SIAM J. Sci. Statist. Comput. vol. 11,
no. 5, pp. 873-912, Sept 1990) and
"Accurate singular values and differential qd algorithms," by
B. Parlett and V. Fernando, Technical Report CPAM-554, Mathematics
Department, University of California at Berkeley, July 1992
for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../interface/bidx.html'>bidx</a></td><td><a href='../module/stdlib_stringlist_type.html'>stdlib_stringlist_type</a></td><td>Interface</td><td><p>Returns an instance of type 'stringlist_index_type' representing backward index
<a href="../page/specs/stdlib_stringlist_type.html#bidx">Specifications</a></p></td></tr>
			   <tr><td><a href='../proc/bits.html'>bits</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Function</td><td><p>Returns the number of bit positions in <code>self</code>.</p></td></tr>
			   <tr><td><a href='../interface/cdf_exp.html'>cdf_exp</a></td><td><a href='../module/stdlib_stats_distribution_exponential.html'>stdlib_stats_distribution_exponential</a></td><td>Interface</td><td><p>Version experimental</p><a href="../interface/cdf_exp.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/cdf_normal.html'>cdf_normal</a></td><td><a href='../module/stdlib_stats_distribution_normal.html'>stdlib_stats_distribution_normal</a></td><td>Interface</td><td><p>Normal Distribution Cumulative Distribution Function
(<a href="../page/specs/stdlib_stats_distribution_normal.html#
cdf_normal-normal-distribution-cumulative-distribution-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/cdf_uniform.html'>cdf_uniform</a></td><td><a href='../module/stdlib_stats_distribution_uniform.html'>stdlib_stats_distribution_uniform</a></td><td>Interface</td><td><p>Get uniform distribution cumulative distribution function (cdf) for integer,
real and complex variables.
(<a href="../page/specs/stdlib_stats_distribution_uniform.html#
cdf_uniform-uniform-cumulative-distribution-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/char.html'>char</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Return the character sequence represented by the string.</p><a href="../interface/char.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/check.html'>check</a></td><td><a href='../module/stdlib_error.html'>stdlib_error</a></td><td>Subroutine</td><td><p>Checks the value of a logical condition
 (<a href="../page/specs/stdlib_error.html#description">Specification</a>)</p><a href="../proc/check.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/chomp.html'>chomp</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Remove trailing characters in set from string.
If no character set is provided trailing whitespace is removed.</p><a href="../interface/chomp.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/clip.html'>clip</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/copy.html'>copy</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>COPY: copies a vector x to a vector y.</p></td></tr>
			   <tr><td><a href='../proc/copy_key.html'>copy_key</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Subroutine</td><td><p>Copies the contents of the key, old_key, to the key, new_key
(<a href="../page/specs/stdlib_hashmaps.html#copy_key-returns-a-copy-of-the-key">Specifications</a>)</p><a href="../proc/copy_key.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/copy_other.html'>copy_other</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Subroutine</td><td><p>Copies the other data, other_in, to the variable, other_out
(<a href="../page/specs/stdlib_hashmaps.html#copy_other-returns-a-copy-of-the-other-data">Specifications</a>)</p><a href="../proc/copy_other.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/corr.html'>corr</a></td><td><a href='../module/stdlib_stats.html'>stdlib_stats</a></td><td>Interface</td><td><p>Pearson correlation of array elements
(<a href="../page/specs/stdlib_stats.html#corr-pearson-correlation-of-array-elements">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/count.html'>count</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Returns the number of times substring 'pattern' has appeared in the
input string 'string'
<a href="../page/specs/stdlib_strings.html#count">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/cov.html'>cov</a></td><td><a href='../module/stdlib_stats.html'>stdlib_stats</a></td><td>Interface</td><td><p>Covariance of array elements
(<a href="../page/specs/stdlib_stats.html#cov-covariance-of-array-elements">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/cross_product.html'>cross_product</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Computes the cross product of two vectors, returning a rank-1 and size-3 array
(<a href="../page/specs/stdlib_linalg.html#cross_product-computes-the-cross-product-of-two-3-d-vectors">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/diag.html'>diag</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Creates a diagonal array or extract the diagonal elements of an array
(<a href="../page/specs/stdlib_linalg.html#
diag-create-a-diagonal-array-or-extract-the-diagonal-elements-of-an-array">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/diff.html'>diff</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Computes differences between adjacent elements of an array.
(<a href="../page/specs/stdlib_math.html#diff-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/disna.html'>disna</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real symmetric or complex Hermitian matrix or for the left or
right singular vectors of a general m-by-n matrix. The reciprocal
condition number is the 'gap' between the corresponding eigenvalue or
singular value and the nearest other one.
The bound on the error, measured by angle in radians, in the I-th
computed vector is given by
DLAMCH( 'E' ) * ( ANORM / SEP( I ) )
where ANORM = 2-norm(A) = max( abs( D(j) ) ).  SEP(I) is not allowed
to be smaller than DLAMCH( 'E' )*ANORM in order to limit the size of
the error bound.
DISNA may also be used to compute error bounds for eigenvectors of
the generalized symmetric definite eigenproblem.</p></td></tr>
			   <tr><td><a href='../interface/dist_rand.html'>dist_rand</a></td><td><a href='../module/stdlib_random.html'>stdlib_random</a></td><td>Interface</td><td><p>Version experimental</p><a href="../interface/dist_rand.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/dlegendre.html'>dlegendre</a></td><td><a href='../module/stdlib_specialfunctions.html'>stdlib_specialfunctions</a></td><td>Interface</td><td><p>First derivative Legendre polynomial</p></td></tr>
			   <tr><td><a href='../interface/dot.html'>dot</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>uses unrolled loops for increments equal to one.</p></td></tr>
			   <tr><td><a href='../interface/dotc.html'>dotc</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>DOTC = X^H * Y</p></td></tr>
			   <tr><td><a href='../interface/dotu.html'>dotu</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>DOTU = X^T * Y</p></td></tr>
			   <tr><td><a href='../interface/ends_with.html'>ends_with</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Check whether a string ends with substring or not</p><a href="../interface/ends_with.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/error_handler.html'>error_handler</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../interface/error_stop.html'>error_stop</a></td><td><a href='../module/stdlib_error.html'>stdlib_error</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/extract.html'>extract</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Creates a new bitset, <code>new</code>, from a range, <code>start_pos</code> to <code>stop_pos</code>, in
 bitset <code>old</code>. If <code>start_pos</code> is greater than <code>stop_pos</code> the new bitset is
 empty. If <code>start_pos</code> is less than zero or <code>stop_pos</code> is greater than
 <code>bits(old)-1</code> then if <code>status</code> is present it has the value
 <code>index_invalid_error</code> and <code>new</code> is undefined, otherwise processing stops
 with an informative message.
 (<a href="../page/specs/stdlib_bitsets.html#extract-create-a-new-bitset-from-a-range-in-an-old-bitset">Specification</a>)</p><a href="../interface/extract.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/eye.html'>eye</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Function</td><td><p>Constructs the identity matrix.
(<a href="../page/specs/stdlib_linalg.html#eye-construct-the-identity-matrix">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/falseloc.html'>falseloc</a></td><td><a href='../module/stdlib_array.html'>stdlib_array</a></td><td>Function</td><td><p>Return the positions of the false elements in array.
<a href="../page/specs/stdlib_array.html#falseloc">Specification</a></p></td></tr>
			   <tr><td><a href='../proc/fibonacci_hash.html'>fibonacci_hash</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Function</td><td><p>Maps the 64 bit integer <code>key</code> to an unsigned integer value with only <code>nbits</code>
bits where <code>nbits</code> is less than 64
(<a href="../page/specs/stdlib_hash_procedures.html#fibonacci_hash-maps-an-integer-to-a-smaller-number-of-bits_1">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/fibonacci_hash~2.html'>fibonacci_hash</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Function</td><td><p>Maps the 32 bit integer <code>key</code> to an unsigned integer value with only <code>nbits</code>
bits where <code>nbits</code> is less than 32
(<a href="../page/specs/stdlib_hash_procedures.html#fibonacci_hash-maps-an-integer-to-a-smaller-number-of-bits">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/fidx.html'>fidx</a></td><td><a href='../module/stdlib_stringlist_type.html'>stdlib_stringlist_type</a></td><td>Interface</td><td><p>Returns an instance of type 'stringlist_index_type' representing forward index
<a href="../page/specs/stdlib_stringlist_type.html#fidx">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/find.html'>find</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Finds the starting index of substring 'pattern' in the input 'string'
<a href="link to the specs - to be completed">Specifications</a></p><a href="../interface/find.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/fnv_1_hash.html'>fnv_1_hash</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td><p>FNV_1 interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#fnv_1-calculates-a-hash-code-from-a-key">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/fnv_1_hash~2.html'>fnv_1_hash</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>FNV_1 interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#fnv_1_hash-calculates-a-hash-code-from-a-key">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/fnv_1_hasher.html'>fnv_1_hasher</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Function</td><td><p>Hashes a key with the FNV_1 algorithm
Arguments:
    key  - the key to be hashed</p></td></tr>
			   <tr><td><a href='../interface/fnv_1a_hash.html'>fnv_1a_hash</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td><p>FNV_1A interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#fnv_1a-calculates-a-hash-code-from-a-key">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/fnv_1a_hash~2.html'>fnv_1a_hash</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>FNV_1A interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#fnv_1a_hash-calculates-a-hash-code-from-a-key">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/fnv_1a_hasher.html'>fnv_1a_hasher</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Function</td><td><p>Hashes a key with the FNV_1a algorithm
(<a href="../page/specs/stdlib_hashmaps.html#fnv_1a_hasher-calculates-a-hash-code-from-a-key">Specifications</a>)</p><a href="../proc/fnv_1a_hasher.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/free_key.html'>free_key</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Subroutine</td><td><p>Frees the memory in a key
(<a href="../page/specs/stdlib_hashmaps.html#free_key-frees-the-memory-associated-with-a-key">Specifications</a>)</p><a href="../proc/free_key.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/free_other.html'>free_other</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Subroutine</td><td><p>Frees the memory in the other data
(<a href="../page/specs/stdlib_hashmaps.html#free_other-frees-the-memory-associated-with-other-data">Specifications</a>)</p><a href="../proc/free_other.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/gamma.html'>gamma</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Gamma function for integer and complex numbers</p></td></tr>
			   <tr><td><a href='../interface/gauss_legendre.html'>gauss_legendre</a></td><td><a href='../module/stdlib_quadrature.html'>stdlib_quadrature</a></td><td>Interface</td><td><p>Computes Gauss-Legendre quadrature nodes and weights.</p></td></tr>
			   <tr><td><a href='../interface/gauss_legendre_lobatto.html'>gauss_legendre_lobatto</a></td><td><a href='../module/stdlib_quadrature.html'>stdlib_quadrature</a></td><td>Interface</td><td><p>Computes Gauss-Legendre-Lobatto quadrature nodes and weights.</p></td></tr>
			   <tr><td><a href='../interface/gbbrd.html'>gbbrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>bidiagonal form B by a unitary transformation: Q<strong>H * A * P = B.
The routine computes B, and optionally forms Q or P</strong>H, or computes
Q*<em>H</em>C for a given matrix C.</p></td></tr>
			   <tr><td><a href='../interface/gbcon.html'>gbcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>general band matrix A, in either the 1-norm or the infinity-norm,
using the LU factorization computed by CGBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../interface/gbequ.html'>gbequ</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N band matrix A and reduce its condition number.  R returns the
row scale factors and C the column scale factors, chosen to try to
make the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../interface/gbequb.html'>gbequb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from CGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../interface/gbmv.html'>gbmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<strong>T<em>x + beta</em>y,   or
y := alpha*A</strong>H<em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n band matrix, with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../interface/gbrfs.html'>gbrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is banded, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../interface/gbsv.html'>gbsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B, where A is a band matrix of order N with KL subdiagonals
and KU superdiagonals, and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as A = L * U, where L is a product of permutation
and unit lower triangular matrices with KL subdiagonals, and U is
upper triangular with KL+KU superdiagonals.  The factored form of A
is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/gbtrf.html'>gbtrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using partial pivoting with row interchanges.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/gbtrs.html'>gbtrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B
with a general band matrix A using the LU factorization computed
by CGBTRF.</p></td></tr>
			   <tr><td><a href='../interface/gcd.html'>gcd</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Returns the greatest common divisor of two integers
(<a href="../page/specs/stdlib_math.html#gcd">Specification</a>)</p><a href="../interface/gcd.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/gebak.html'>gebak</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix by backward transformation on the computed eigenvectors of the
balanced matrix output by CGEBAL.</p></td></tr>
			   <tr><td><a href='../interface/gebal.html'>gebal</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>permuting A by a similarity transformation to isolate eigenvalues
in the first 1 to ILO-1 and last IHI+1 to N elements on the
diagonal; and second, applying a diagonal similarity transformation
to rows and columns ILO to IHI to make the rows and columns as
close in norm as possible.  Both steps are optional.
Balancing may reduce the 1-norm of the matrix, and improve the
accuracy of the computed eigenvalues and/or eigenvectors.</p></td></tr>
			   <tr><td><a href='../interface/gebrd.html'>gebrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>bidiagonal form B by a unitary transformation: Q**H * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../interface/gecon.html'>gecon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>complex matrix A, in either the 1-norm or the infinity-norm, using
the LU factorization computed by CGETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../interface/geequ.html'>geequ</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../interface/geequb.html'>geequb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from CGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../interface/gees.html'>gees</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvalues, the Schur form T, and, optionally, the matrix of Schur
vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z**H).
Optionally, it also orders the eigenvalues on the diagonal of the
Schur form so that selected eigenvalues are at the top left.
The leading columns of Z then form an orthonormal basis for the
invariant subspace corresponding to the selected eigenvalues.
A complex matrix is in Schur form if it is upper triangular.</p></td></tr>
			   <tr><td><a href='../interface/geev.html'>geev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)**H denotes the conjugate transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.</p></td></tr>
			   <tr><td><a href='../interface/gehrd.html'>gehrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>an unitary similarity transformation:  Q**H * A * Q = H .</p></td></tr>
			   <tr><td><a href='../interface/gejsv.html'>gejsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix [A], where M &gt;= N. The SVD of [A] is written as
[A] = [U] * [SIGMA] * [V]^*,
where [SIGMA] is an N-by-N (M-by-N) matrix which is zero except for its N
diagonal elements, [U] is an M-by-N (or M-by-M) unitary matrix, and
[V] is an N-by-N unitary matrix. The diagonal elements of [SIGMA] are
the singular values of [A]. The columns of [U] and [V] are the left and
the right singular vectors of [A], respectively. The matrices [U] and [V]
are computed and stored in the arrays U and V, respectively. The diagonal
of [SIGMA] is computed and stored in the array SVA.</p></td></tr>
			   <tr><td><a href='../interface/gelq.html'>gelq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../interface/gelqf.html'>gelqf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../interface/gelqt.html'>gelqt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../interface/gelqt3.html'>gelqt3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../interface/gels.html'>gels</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>involving an M-by-N matrix A, or its conjugate-transpose, using a QR
or LQ factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'C' and m &gt;= n:  find the minimum norm solution of
an underdetermined system A</em><em>H * X = B.
4. If TRANS = 'C' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*H * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../interface/gelsd.html'>gelsd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>squares problem:
minimize 2-norm(| b - A*x |)
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The problem is solved in three steps:
(1) Reduce the coefficient matrix A to bidiagonal form with
Householder transformations, reducing the original problem
into a "bidiagonal least squares problem" (BLS)
(2) Solve the BLS using a divide and conquer approach.
(3) Apply back all the Householder transformations to solve
the original least squares problem.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/gelss.html'>gelss</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>least squares problem:
Minimize 2-norm(| b - A*x |).
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix
X.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.</p></td></tr>
			   <tr><td><a href='../interface/gelsy.html'>gelsy</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>squares problem:
minimize || A * X - B ||
using a complete orthogonal factorization of A.  A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The routine first computes a QR factorization with column pivoting:
A * P = Q * [ R11 R12 ]
[  0  R22 ]
with R11 defined as the largest leading submatrix whose estimated
condition number is less than 1/RCOND.  The order of R11, RANK,
is the effective rank of A.
Then, R22 is considered to be negligible, and R12 is annihilated
by unitary transformations from the right, arriving at the
complete orthogonal factorization:
A * P = Q * [ T11 0 ] * Z
[  0  0 ]
The minimum-norm solution is then
X = P * Z<strong>H [ inv(T11)*Q1</strong>H*B ]
[        0         ]
where Q1 consists of the first RANK columns of Q.
This routine is basically identical to the original xGELSX except
three differences:
o The permutation of matrix B (the right hand side) is faster and
more simple.
o The call to the subroutine xGEQPF has been substituted by the
the call to the subroutine xGEQP3. This subroutine is a Blas-3
version of the QR factorization with column pivoting.
o Matrix B (the right hand side) is updated with Blas-3.</p></td></tr>
			   <tr><td><a href='../interface/gemlq.html'>gemlq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by short wide
LQ factorization (CGELQ)</p></td></tr>
			   <tr><td><a href='../interface/gemlqt.html'>gemlqt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'C':   Q<strong>H C            C Q</strong>H
where Q is a complex unitary matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**H
generated using the compact WY representation as returned by CGELQT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/gemm.html'>gemm</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>op( A )</em>op( B ) + beta<em>C,
where  op( X ) is one of
op( X ) = X   or   op( X ) = X</em><em>T   or   op( X ) = X</em>*H,
alpha and beta are scalars, and A, B and C are matrices, with op( A )
an m by k matrix,  op( B )  a  k by n matrix and  C an m by n matrix.</p></td></tr>
			   <tr><td><a href='../interface/gemqr.html'>gemqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (CGEQR)</p></td></tr>
			   <tr><td><a href='../interface/gemqrt.html'>gemqrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'C':    Q<strong>H C            C Q</strong>H
where Q is a complex orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**H
generated using the compact WY representation as returned by CGEQRT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/gemv.html'>gemv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<strong>T<em>x + beta</em>y,   or
y := alpha*A</strong>H<em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.</p></td></tr>
			   <tr><td><a href='../interface/geqlf.html'>geqlf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../interface/geqr.html'>geqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../interface/geqr2p.html'>geqr2p</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix with nonnegative diagonal
entries;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../interface/geqrf.html'>geqrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../interface/geqrfp.html'>geqrfp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>CGEQR2P computes a QR factorization of a complex M-by-N matrix A:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix with nonnegative diagonal
entries;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../interface/geqrt.html'>geqrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../interface/geqrt2.html'>geqrt2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../interface/geqrt3.html'>geqrt3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../interface/ger.html'>ger</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y**T + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../interface/gerc.html'>gerc</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y**H + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../interface/gerfs.html'>gerfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations and provides error bounds and backward error estimates for
the solution.</p></td></tr>
			   <tr><td><a href='../interface/gerqf.html'>gerqf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../interface/geru.html'>geru</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y**T + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../interface/gesdd.html'>gesdd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors, by using divide-and-conquer method. The SVD is written
A = U * SIGMA * conjugate-transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M unitary matrix, and
V is an N-by-N unitary matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns VT = V**H, not V.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/gesv.html'>gesv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as
A = P * L * U,
where P is a permutation matrix, L is unit lower triangular, and U is
upper triangular.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/gesvd.html'>gesvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors. The SVD is written
A = U * SIGMA * conjugate-transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M unitary matrix, and
V is an N-by-N unitary matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns V**H, not V.</p></td></tr>
			   <tr><td><a href='../interface/gesvdq.html'>gesvdq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N unitary matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../interface/gesvj.html'>gesvj</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N unitary matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../interface/get.html'>get</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../proc/get_stdlib_version.html'>get_stdlib_version</a></td><td><a href='../module/stdlib_version.html'>stdlib_version</a></td><td>Subroutine</td><td><p>Getter function to retrieve standard library version</p></td></tr>
			   <tr><td><a href='../interface/getline.html'>getline</a></td><td><a href='../module/stdlib_io.html'>stdlib_io</a></td><td>Interface</td><td><p>Read a whole line from a formatted unit into a string variable</p></td></tr>
			   <tr><td><a href='../interface/getrf.html'>getrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../interface/getrf2.html'>getrf2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = min(m,n)/2
[  A21 | A22  ]       n2 = n-n1
[ A11 ]
The subroutine calls itself to factor [ --- ],
[ A12 ]
[ A12 ]
do the swaps on [ --- ], solve A12, update A22,
[ A22 ]
then calls itself to factor A22 and do the swaps on A21.</p></td></tr>
			   <tr><td><a href='../interface/getri.html'>getri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>computed by CGETRF.
This method inverts U and then computes inv(A) by solving the system
inv(A)*L = inv(U) for inv(A).</p></td></tr>
			   <tr><td><a href='../interface/getrs.html'>getrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B
with a general N-by-N matrix A using the LU factorization computed
by CGETRF.</p></td></tr>
			   <tr><td><a href='../interface/getsls.html'>getsls</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>involving an M-by-N matrix A, using a tall skinny QR or short wide LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'C' and m &gt;= n:  find the minimum norm solution of
an undetermined system A</em><em>T * X = B.
4. If TRANS = 'C' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../interface/getsqrhrt.html'>getsqrhrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex M-by-N matrix A with M &gt;= N,
A = Q * R.
The routine uses internally a NB1-sized column blocked and MB1-sized
row blocked TSQR-factorization and perfors the reconstruction
of the Householder vectors from the TSQR output. The routine also
converts the R_tsqr factor from the TSQR-factorization output into
the R factor that corresponds to the Householder QR-factorization,
A = Q_tsqr * R_tsqr = Q * R.
The output Q and R factors are stored in the same format as in CGEQRT
(Q is in blocked compact WY-representation). See the documentation
of CGEQRT for more details on the format.</p></td></tr>
			   <tr><td><a href='../interface/ggbak.html'>ggbak</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvalue problem A<em>x = lambda</em>B*x, by backward transformation on
the computed eigenvectors of the balanced pair of matrices output by
CGGBAL.</p></td></tr>
			   <tr><td><a href='../interface/ggbal.html'>ggbal</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>involves, first, permuting A and B by similarity transformations to
isolate eigenvalues in the first 1 to ILO$-$1 and last IHI+1 to N
elements on the diagonal; and second, applying a diagonal similarity
transformation to rows and columns ILO to IHI to make the rows
and columns as close in norm as possible. Both steps are optional.
Balancing may reduce the 1-norm of the matrices, and improve the
accuracy of the computed eigenvalues and/or eigenvectors in the
generalized eigenvalue problem A<em>x = lambda</em>B*x.</p></td></tr>
			   <tr><td><a href='../interface/gges.html'>gges</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>(A,B), the generalized eigenvalues, the generalized complex Schur
form (S, T), and optionally left and/or right Schur vectors (VSL
and VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>H, (VSL)<em>T</em>(VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T. The leading
columns of VSL and VSR then form an unitary basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
CGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0, and even for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if S
and T are upper triangular and, in addition, the diagonal elements
of T are non-negative real numbers.</p></td></tr>
			   <tr><td><a href='../interface/ggev.html'>ggev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>(A,B), the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right generalized eigenvector v(j) corresponding to the
generalized eigenvalue lambda(j) of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left generalized eigenvector u(j) corresponding to the
generalized eigenvalues lambda(j) of (A,B) satisfies
u(j)</em><em>H * A = lambda(j) * u(j)</em><em>H * B
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../interface/ggglm.html'>ggglm</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>minimize || y ||_2   subject to   d = A<em>x + B</em>y
x
where A is an N-by-M matrix, B is an N-by-P matrix, and d is a
given N-vector. It is assumed that M &lt;= N &lt;= M+P, and
rank(A) = M    and    rank( A B ) = N.
Under these assumptions, the constrained equation is always
consistent, and there is a unique solution x and a minimal 2-norm
solution y, which is obtained using a generalized QR factorization
of the matrices (A, B) given by
A = Q<em>(R),   B = Q</em>T<em>Z.
(0)
In particular, if matrix B is square nonsingular, then the problem
GLM is equivalent to the following weighted linear least squares
problem
minimize || inv(B)</em>(d-A*x) ||_2
x
where inv(B) denotes the inverse of B.</p></td></tr>
			   <tr><td><a href='../interface/gghrd.html'>gghrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hessenberg form using unitary transformations, where A is a
general matrix and B is upper triangular.  The form of the generalized
eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the unitary matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>H</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>H</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>H*x.
The unitary matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>H = (Q1<em>Q) * H * (Z1</em>Z)<strong>H
Q1 * B * Z1</strong>H = (Q1<em>Q) * T * (Z1</em>Z)<em><em>H
If Q1 is the unitary matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then GGHRD reduces the original
problem to generalized Hessenberg form.</p></td></tr>
			   <tr><td><a href='../interface/gglse.html'>gglse</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>minimize || c - A<em>x ||_2   subject to   B</em>x = d
where A is an M-by-N matrix, B is a P-by-N matrix, c is a given
M-vector, and d is a given P-vector. It is assumed that
P &lt;= N &lt;= M+P, and
rank(B) = P and  rank( (A) ) = N.
( (B) )
These conditions ensure that the LSE problem has a unique solution,
which is obtained using a generalized RQ factorization of the
matrices (B, A) given by
B = (0 R)<em>Q,   A = Z</em>T*Q.</p></td></tr>
			   <tr><td><a href='../interface/ggqrf.html'>ggqrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>and an N-by-P matrix B:
A = Q<em>R,        B = Q</em>T<em>Z,
where Q is an N-by-N unitary matrix, Z is a P-by-P unitary matrix,
and R and T assume one of the forms:
if N &gt;= M,  R = ( R11 ) M  ,   or if N &lt; M,  R = ( R11  R12 ) N,
(  0  ) N-M                         N   M-N
M
where R11 is upper triangular, and
if N &lt;= P,  T = ( 0  T12 ) N,   or if N &gt; P,  T = ( T11 ) N-P,
P-N  N                           ( T21 ) P
P
where T12 or T21 is upper triangular.
In particular, if B is square and nonsingular, the GQR factorization
of A and B implicitly gives the QR factorization of inv(B)</em>A:
inv(B)<em>A = Z</em><em>H * (inv(T)</em>R)
where inv(B) denotes the inverse of the matrix B, and Z' denotes the
conjugate transpose of matrix Z.</p></td></tr>
			   <tr><td><a href='../interface/ggrqf.html'>ggrqf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>and a P-by-N matrix B:
A = R<em>Q,        B = Z</em>T<em>Q,
where Q is an N-by-N unitary matrix, Z is a P-by-P unitary
matrix, and R and T assume one of the forms:
if M &lt;= N,  R = ( 0  R12 ) M,   or if M &gt; N,  R = ( R11 ) M-N,
N-M  M                           ( R21 ) N
N
where R12 or R21 is upper triangular, and
if P &gt;= N,  T = ( T11 ) N  ,   or if P &lt; N,  T = ( T11  T12 ) P,
(  0  ) P-N                         P   N-P
N
where T11 is upper triangular.
In particular, if B is square and nonsingular, the GRQ factorization
of A and B implicitly gives the RQ factorization of A</em>inv(B):
A<em>inv(B) = (R</em>inv(T))<em>Z</em><em>H
where inv(B) denotes the inverse of the matrix B, and Z</em>*H denotes the
conjugate transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../interface/gsvj0.html'>gsvj0</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>purpose. It applies Jacobi rotations in the same way as CGESVJ does, but
it does not check convergence (stopping criterion). Few tuning
parameters (marked by [TP]) are available for the implementer.</p></td></tr>
			   <tr><td><a href='../interface/gsvj1.html'>gsvj1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>purpose. It applies Jacobi rotations in the same way as CGESVJ does, but
it targets only particular pivots and it does not check convergence
(stopping criterion). Few tuning parameters (marked by [TP]) are
available for the implementer.
Further Details
~~~~~~~~~~~~~~~
GSVJ1 applies few sweeps of Jacobi rotations in the column space of
the input M-by-N matrix A. The pivot pairs are taken from the (1,2)
off-diagonal block in the corresponding N-by-N Gram matrix A^T * A. The
block-entries (tiles) of the (1,2) off-diagonal block are marked by the
[x]'s in the following scheme:
| *  *  * [x] [x] [x]|
| *  *  * [x] [x] [x]|    Row-cycling in the nblr-by-nblc [x] blocks.
| *  *  * [x] [x] [x]|    Row-cyclic pivoting inside each [x] block.
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
In terms of the columns of A, the first N1 columns are rotated 'against'
the remaining N-N1 columns, trying to increase the angle between the
corresponding subspaces. The off-diagonal block is N1-by(N-N1) and it is
tiled using quadratic tiles of side KBL. Here, KBL is a tuning parameter.
The number of sweeps is given in NSWEEP and the orthogonality threshold
is given in TOL.</p></td></tr>
			   <tr><td><a href='../interface/gtcon.html'>gtcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal matrix A using the LU factorization as computed by
CGTTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/gtrfs.html'>gtrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is tridiagonal, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../interface/gtsv.html'>gtsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A<em>X = B,
where A is an N-by-N tridiagonal matrix, by Gaussian elimination with
partial pivoting.
Note that the equation  A</em><em>T </em>X = B  may be solved by interchanging the
order of the arguments DU and DL.</p></td></tr>
			   <tr><td><a href='../interface/gttrf.html'>gttrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using elimination with partial pivoting and row interchanges.
The factorization has the form
A = L * U
where L is a product of permutation and unit lower bidiagonal
matrices and U is upper triangular with nonzeros in only the main
diagonal and first two superdiagonals.</p></td></tr>
			   <tr><td><a href='../interface/gttrs.html'>gttrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
with a tridiagonal matrix A using the LU factorization computed
by CGTTRF.</p></td></tr>
			   <tr><td><a href='../interface/hb2st_kernels.html'>hb2st_kernels</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>subroutine.</p></td></tr>
			   <tr><td><a href='../interface/hbev.html'>hbev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex Hermitian band matrix A.</p></td></tr>
			   <tr><td><a href='../interface/hbevd.html'>hbevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex Hermitian band matrix A.  If eigenvectors are desired, it
uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/hbgst.html'>hbgst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenproblem  A<em>x = lambda</em>B<em>x  to standard form  C</em>y = lambda<em>y,
such that C has the same bandwidth as A.
B must have been previously factorized as S</em><em>H</em>S by CPBSTF, using a
split Cholesky factorization. A is overwritten by C = X<strong>H<em>A</em>X, where
X = S</strong>(-1)*Q and Q is a unitary matrix chosen to preserve the
bandwidth of A.</p></td></tr>
			   <tr><td><a href='../interface/hbgv.html'>hbgv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../interface/hbgvd.html'>hbgvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/hbmv.html'>hbmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian band matrix, with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../interface/hbtrd.html'>hbtrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/hecon.html'>hecon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/hecon_rook.html'>hecon_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/heequb.html'>heequb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../interface/heev.html'>heev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>complex Hermitian matrix A.</p></td></tr>
			   <tr><td><a href='../interface/heevd.html'>heevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>complex Hermitian matrix A.  If eigenvectors are desired, it uses a
divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/heevr.html'>heevr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex Hermitian matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.
HEEVR first reduces the matrix A to tridiagonal form T with a call
to CHETRD.  Then, whenever possible, HEEVR calls CSTEMR to compute
the eigenspectrum using Relatively Robust Representations.  CSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see CSTEMR's documentation and:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Note 1 : HEEVR calls CSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
HEEVR calls SSTEBZ and CSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of CSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../interface/hegst.html'>hegst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenproblem to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H</em>A<em>L.
B must have been previously factorized as U</em><em>H</em>U or L<em>L</em>*H by CPOTRF.</p></td></tr>
			   <tr><td><a href='../interface/hegv.html'>hegv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be Hermitian and B is also
positive definite.</p></td></tr>
			   <tr><td><a href='../interface/hegvd.html'>hegvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian and B is also positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/hemm.html'>hemm</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where alpha and beta are scalars, A is an hermitian matrix and  B and
C are m by n matrices.</p></td></tr>
			   <tr><td><a href='../interface/hemv.html'>hemv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../interface/her.html'>her</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../interface/her2.html'>her2</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y<strong>H + conjg( alpha )<em>y</em>x</strong>H + A,
where alpha is a scalar, x and y are n element vectors and A is an n
by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../interface/her2k.html'>her2k</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>A</em>B<strong>H + conjg( alpha )<em>B</em>A</strong>H + beta<em>C,
or
C := alpha</em>A<strong>H<em>B + conjg( alpha )</em>B</strong>H<em>A + beta</em>C,
where  alpha and beta  are scalars with  beta  real,  C is an  n by n
hermitian matrix and  A and B  are  n by k matrices in the first case
and  k by n  matrices in the second case.</p></td></tr>
			   <tr><td><a href='../interface/herfs.html'>herfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is Hermitian indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../interface/herk.html'>herk</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>A</em>A<strong>H + beta<em>C,
or
C := alpha</em>A</strong>H<em>A + beta</em>C,
where  alpha and beta  are  real scalars,  C is an  n by n  hermitian
matrix and  A  is an  n by k  matrix in the  first case and a  k by n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../interface/hesv.html'>hesv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>H,  if UPLO = 'U', or
A = L * D * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/hesv_aa.html'>hesv_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>H * T * U,  if UPLO = 'U', or
A = L * T * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is Hermitian and tridiagonal. The factored form
of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/hesv_rk.html'>hesv_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations A * X = B, where A is an N-by-N Hermitian matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
CHETRF_RK is called to compute the factorization of a complex
Hermitian matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine CHETRS_3.</p></td></tr>
			   <tr><td><a href='../interface/hesv_rook.html'>hesv_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
The bounded Bunch-Kaufman ("rook") diagonal pivoting method is used
to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
CHETRF_ROOK is called to compute the factorization of a complex
Hermition matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling CHETRS_ROOK (uses BLAS 2).</p></td></tr>
			   <tr><td><a href='../interface/heswapr.html'>heswapr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a hermitian matrix.</p></td></tr>
			   <tr><td><a href='../interface/hetf2_rk.html'>hetf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../interface/hetf2_rook.html'>hetf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**H is the conjugate transpose of U, and D is
Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/hetrd.html'>hetrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/hetrd_hb2st.html'>hetrd_hb2st</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/hetrd_he2hb.html'>hetrd_he2hb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>band-diagonal form AB by a unitary similarity transformation:
Q**H * A * Q = AB.</p></td></tr>
			   <tr><td><a href='../interface/hetrf.html'>hetrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/hetrf_aa.html'>hetrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>H<em>T</em>U  or  A = L<em>T</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a hermitian tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/hetrf_rk.html'>hetrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../interface/hetrf_rook.html'>hetrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/hetri.html'>hetri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A using the factorization A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by
CHETRF.</p></td></tr>
			   <tr><td><a href='../interface/hetri_rook.html'>hetri_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A using the factorization A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by
CHETRF_ROOK.</p></td></tr>
			   <tr><td><a href='../interface/hetrs.html'>hetrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF.</p></td></tr>
			   <tr><td><a href='../interface/hetrs2.html'>hetrs2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF and converted by CSYCONV.</p></td></tr>
			   <tr><td><a href='../interface/hetrs_3.html'>hetrs_3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A using the factorization computed
by CHETRF_RK or CHETRF_BK:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/hetrs_aa.html'>hetrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>hermitian matrix A using the factorization A = U<strong>H<em>T</em>U or
A = L<em>T</em>L</strong>H computed by CHETRF_AA.</p></td></tr>
			   <tr><td><a href='../interface/hetrs_rook.html'>hetrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF_ROOK.</p></td></tr>
			   <tr><td><a href='../interface/hfrk.html'>hfrk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Level 3 BLAS like routine for C in RFP Format.
HFRK: performs one of the Hermitian rank--k operations
C := alpha<em>A</em>A<strong>H + beta<em>C,
or
C := alpha</em>A</strong>H<em>A + beta</em>C,
where alpha and beta are real scalars, C is an n--by--n Hermitian
matrix and A is an n--by--k matrix in the first case and a k--by--n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../interface/hgeqz.html'>hgeqz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the single-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a complex matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>H,  B = Q1<em>T</em>Z1</strong>H,
as computed by CGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>H,  T = Q<em>P</em>Z</strong>H,
where Q and Z are unitary matrices and S and P are upper triangular.
Optionally, the unitary matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
unitary matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the unitary matrices from CGGHRD that reduced
the matrix pair (A,B) to generalized Hessenberg form, then the output
matrices Q1<em>Q and Z1</em>Z are the unitary factors from the generalized
Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>H,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>H.
To avoid overflow, eigenvalues of the matrix pair (H,T)
(equivalently, of (A,B)) are computed as a pair of complex values
(alpha,beta).  If beta is nonzero, lambda = alpha / beta is an
eigenvalue of the generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
The values of alpha and beta for the i-th eigenvalue can be read
directly from the generalized Schur form:  alpha = S(i,i),
beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.</p></td></tr>
			   <tr><td><a href='../interface/hpcon.html'>hpcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian packed matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/hpev.html'>hpev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>complex Hermitian matrix in packed storage.</p></td></tr>
			   <tr><td><a href='../interface/hpevd.html'>hpevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex Hermitian matrix A in packed storage.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/hpgst.html'>hpgst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenproblem to standard form, using packed storage.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H</em>A<em>L.
B must have been previously factorized as U</em><em>H</em>U or L<em>L</em>*H by CPPTRF.</p></td></tr>
			   <tr><td><a href='../interface/hpgv.html'>hpgv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be Hermitian, stored in packed format,
and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../interface/hpgvd.html'>hpgvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian, stored in packed format, and B is also
positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/hpmv.html'>hpmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/hpr.html'>hpr</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/hpr2.html'>hpr2</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y<strong>H + conjg( alpha )<em>y</em>x</strong>H + A,
where alpha is a scalar, x and y are n element vectors and A is an
n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/hprfs.html'>hprfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is Hermitian indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../interface/hpsv.html'>hpsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>H,  if UPLO = 'U', or
A = L * D * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is Hermitian and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/hptrd.html'>hptrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>real symmetric tridiagonal form T by a unitary similarity
transformation: Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/hptrf.html'>hptrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../interface/hptri.html'>hptri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHPTRF.</p></td></tr>
			   <tr><td><a href='../interface/hptrs.html'>hptrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by CHPTRF.</p></td></tr>
			   <tr><td><a href='../interface/hsein.html'>hsein</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvectors of a complex upper Hessenberg matrix H.
The right eigenvector x and the left eigenvector y of the matrix H
corresponding to an eigenvalue w are defined by:
H * x = w * x,     y<strong>h * H = w * y</strong>h
where y**h denotes the conjugate transpose of the vector y.</p></td></tr>
			   <tr><td><a href='../interface/hseqr.html'>hseqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>T</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../interface/iachar.html'>iachar</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Code in ASCII collating sequence.</p><a href="../interface/iachar.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/ichar.html'>ichar</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Character-to-integer conversion function.</p><a href="../interface/ichar.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/index.html'>index</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Position of a <em>substring</em> within a <em>string</em>.</p><a href="../interface/index.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/is_alpha.html'>is_alpha</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is an ASCII letter (A .. Z, a .. z).</p></td></tr>
			   <tr><td><a href='../proc/is_alphanum.html'>is_alphanum</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is a letter or a number (0 .. 9, a .. z, A .. Z).</p></td></tr>
			   <tr><td><a href='../proc/is_ascii.html'>is_ascii</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether or not <code>c</code> is in the ASCII character set -
i.e. in the range 0 .. 0x7F.</p></td></tr>
			   <tr><td><a href='../proc/is_blank.html'>is_blank</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether or not <code>c</code> is a blank character. That includes the
only the space and tab characters</p></td></tr>
			   <tr><td><a href='../interface/is_close.html'>is_close</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Returns a boolean scalar/array where two scalar/arrays are element-wise equal within a tolerance.
(<a href="../page/specs/stdlib_math.html#is_close-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/is_control.html'>is_control</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is a control character.</p></td></tr>
			   <tr><td><a href='../interface/is_diagonal.html'>is_diagonal</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is diagonal
(<a href="../page/specs/stdlib_linalg.html#
is_diagonal-checks-if-a-matrix-is-diagonal">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/is_digit.html'>is_digit</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is a digit (0 .. 9).</p></td></tr>
			   <tr><td><a href='../proc/is_graphical.html'>is_graphical</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether or not <code>c</code> is a printable character other than the
space character.</p></td></tr>
			   <tr><td><a href='../interface/is_hermitian.html'>is_hermitian</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is Hermitian
(<a href="../page/specs/stdlib_linalg.html#
is_hermitian-checks-if-a-matrix-is-hermitian">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/is_hessenberg.html'>is_hessenberg</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is Hessenberg
(<a href="../page/specs/stdlib_linalg.html#
is_hessenberg-checks-if-a-matrix-is-hessenberg">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/is_hex_digit.html'>is_hex_digit</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is a digit in base 16 (0 .. 9, A .. F, a .. f).</p></td></tr>
			   <tr><td><a href='../proc/is_lower.html'>is_lower</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is a lowercase ASCII letter (a .. z).</p></td></tr>
			   <tr><td><a href='../proc/is_octal_digit.html'>is_octal_digit</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is a digit in base 8 (0 .. 7).</p></td></tr>
			   <tr><td><a href='../proc/is_printable.html'>is_printable</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether or not <code>c</code> is a printable character - including the
space character.</p></td></tr>
			   <tr><td><a href='../proc/is_punctuation.html'>is_punctuation</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether or not <code>c</code> is a punctuation character. That includes
all ASCII characters which are not control characters, letters,
digits, or whitespace.</p></td></tr>
			   <tr><td><a href='../interface/is_skew_symmetric.html'>is_skew_symmetric</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is skew-symmetric
(<a href="../page/specs/stdlib_linalg.html#
is_skew_symmetric-checks-if-a-matrix-is-skew-symmetric">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/is_square.html'>is_square</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is square
(<a href="../page/specs/stdlib_linalg.html#
is_square-checks-if-a-matrix-is-square">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/is_symmetric.html'>is_symmetric</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is symmetric
(<a href="../page/specs/stdlib_linalg.html#
is_symmetric-checks-if-a-matrix-is-symmetric">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/is_triangular.html'>is_triangular</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Checks if a matrix (rank-2 array) is triangular
(<a href="../page/specs/stdlib_linalg.html#
is_triangular-checks-if-a-matrix-is-triangular">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/is_upper.html'>is_upper</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether <code>c</code> is an uppercase ASCII letter (A .. Z).</p></td></tr>
			   <tr><td><a href='../proc/is_white.html'>is_white</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Checks whether or not <code>c</code> is a whitespace character. That includes the
space, tab, vertical tab, form feed, carriage return, and linefeed
characters.</p></td></tr>
			   <tr><td><a href='../interface/isnan.html'>isnan</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>otherwise.  To be replaced by the Fortran 2003 intrinsic in the
future.</p></td></tr>
			   <tr><td><a href='../interface/kronecker_product.html'>kronecker_product</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Computes the Kronecker product of two arrays of size M1xN1, and of M2xN2, returning an (M1<em>M2)x(N1</em>N2) array
(<a href="../page/specs/stdlib_linalg.html#
kronecker_product-computes-the-kronecker-product-of-two-matrices">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/la_gbamv.html'>la_gbamv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../interface/la_gbrcond.html'>la_gbrcond</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number  cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../interface/la_gbrcond_c.html'>la_gbrcond_c</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../interface/la_gbrpvgrw.html'>la_gbrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../interface/la_geamv.html'>la_geamv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../interface/la_gercond.html'>la_gercond</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../interface/la_gercond_c.html'>la_gercond_c</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../interface/la_gerpvgrw.html'>la_gerpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../interface/la_heamv.html'>la_heamv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>CLA_SYAMV  performs the matrix-vector operation
y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../interface/la_hercond_c.html'>la_hercond_c</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../interface/la_herpvgrw.html'>la_herpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../interface/la_lin_berr.html'>la_lin_berr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the formula
max(i) ( abs(R(i)) / ( abs(op(A_s))*abs(Y) + abs(B_s) )(i) )
where abs(Z) is the componentwise absolute value of the matrix
or vector Z.</p></td></tr>
			   <tr><td><a href='../interface/la_porcond.html'>la_porcond</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number  cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../interface/la_porcond_c.html'>la_porcond_c</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector</p></td></tr>
			   <tr><td><a href='../interface/la_porpvgrw.html'>la_porpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../interface/la_syamv.html'>la_syamv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../interface/la_syrcond.html'>la_syrcond</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../interface/la_syrcond_c.html'>la_syrcond_c</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../interface/la_syrpvgrw.html'>la_syrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../interface/la_wwaddw.html'>la_wwaddw</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This works for all extant IBM's hex and binary floating point
arithmetic, but not for decimal.</p></td></tr>
			   <tr><td><a href='../interface/labad.html'>labad</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>overflow, and returns the square root of each of these values if the
log of LARGE is sufficiently large.  This subroutine is intended to
identify machines with a large exponent range, such as the Crays, and
redefine the underflow and overflow limits to be the square roots of
the values computed by DLAMCH.  This subroutine is needed because
DLAMCH does not compensate for poor arithmetic in the upper half of
the exponent range, as is found on a Cray.</p></td></tr>
			   <tr><td><a href='../interface/labrd.html'>labrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>m by n matrix A to upper or lower real bidiagonal form by a unitary
transformation Q**H * A * P, and returns the matrices X and Y which
are needed to apply the transformation to the unreduced part of A.
If m &gt;= n, A is reduced to upper bidiagonal form; if m &lt; n, to lower
bidiagonal form.
This is an auxiliary routine called by CGEBRD</p></td></tr>
			   <tr><td><a href='../interface/lacgv.html'>lacgv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>LACGV: conjugates a complex vector of length N.</p></td></tr>
			   <tr><td><a href='../interface/lacon.html'>lacon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../interface/lacpy.html'>lacpy</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix B.</p></td></tr>
			   <tr><td><a href='../interface/lacrm.html'>lacrm</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>C := A * B,
where A is M by N and complex; B is N by N and real;
C is M by N and complex.</p></td></tr>
			   <tr><td><a href='../interface/lacrt.html'>lacrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>(  c  s )( x )  ==&gt; ( x )
( -s  c )( y )      ( y )
where c and s are complex and the vectors x and y are complex.</p></td></tr>
			   <tr><td><a href='../interface/ladiv1.html'>ladiv1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/ladiv2.html'>ladiv2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/ladiv_f.html'>ladiv_f</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>will not overflow on an intermediary step unless the results
overflows.</p></td></tr>
			   <tr><td><a href='../interface/ladiv_s.html'>ladiv_s</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a + i<em>b
p + i</em>q = ---------
c + i*d
The algorithm is due to Michael Baudin and Robert L. Smith
and can be found in the paper
"A Robust Complex Division in Scilab"</p></td></tr>
			   <tr><td><a href='../interface/laebz.html'>laebz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>function N(w), which is the count of eigenvalues of a symmetric
tridiagonal matrix T less than or equal to its argument  w.  It
performs a choice of two types of loops:
IJOB=1, followed by
IJOB=2: It takes as input a list of intervals and returns a list of
sufficiently small intervals whose union contains the same
eigenvalues as the union of the original intervals.
The input intervals are (AB(j,1),AB(j,2)], j=1,...,MINP.
The output interval (AB(j,1),AB(j,2)] will contain
eigenvalues NAB(j,1)+1,...,NAB(j,2), where 1 &lt;= j &lt;= MOUT.
IJOB=3: It performs a binary search in each input interval
(AB(j,1),AB(j,2)] for a point  w(j)  such that
N(w(j))=NVAL(j), and uses  C(j)  as the starting point of
the search.  If such a w(j) is found, then on output
AB(j,1)=AB(j,2)=w.  If no such w(j) is found, then on output
(AB(j,1),AB(j,2)] will be a small interval containing the
point where N(w) jumps through NVAL(j), unless that point
lies outside the initial interval.
Note that the intervals are in all cases half-open intervals,
i.e., of the form  (a,b] , which includes  b  but not  a .
To avoid underflow, the matrix should be scaled so that its largest
element is no greater than  overflow<strong>(1/2) * underflow</strong>(1/4)
in absolute value.  To assure the most accurate computation
of small eigenvalues, the matrix should be scaled to be
not much smaller than that, either.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966
Note: the arguments are, in general, <em>not</em> checked for unreasonable
values.</p></td></tr>
			   <tr><td><a href='../interface/laed0.html'>laed0</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Using the divide and conquer method, LAED0: computes all eigenvalues
of a symmetric tridiagonal matrix which is one diagonal block of
those from reducing a dense or band Hermitian matrix and
corresponding eigenvectors of the dense or band matrix.</p></td></tr>
			   <tr><td><a href='../interface/laed1.html'>laed1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix after modification by a rank-one symmetric matrix.  This
routine is used only for the eigenproblem which requires all
eigenvalues and eigenvectors of a tridiagonal matrix.  DLAED7 handles
the case in which eigenvalues only or eigenvalues and eigenvectors
of a full symmetric matrix (which was reduced to tridiagonal form)
are desired.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>T ) Q</em><em>T(in) = Q(out) * D(out) * Q</em><em>T(out)
where Z = Q</em><em>T</em>u, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine DLAED2.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine DLAED4 (as called by DLAED3).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../interface/laed4.html'>laed4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This subroutine computes the I-th updated eigenvalue of a symmetric
rank-one modification to a diagonal matrix whose elements are
given in the array d, and that
D(i) &lt; D(j)  for  i &lt; j
and that RHO &gt; 0.  This is arranged by the calling routine, and is
no loss in generality.  The rank-one modified system is thus
diag( D )  +  RHO * Z * Z_transpose.
where we assume the Euclidean norm of Z is 1.
The method consists of approximating the rational functions in the
secular equation by simpler interpolating rational functions.</p></td></tr>
			   <tr><td><a href='../interface/laed5.html'>laed5</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This subroutine computes the I-th eigenvalue of a symmetric rank-one
modification of a 2-by-2 diagonal matrix
diag( D )  +  RHO * Z * transpose(Z) .
The diagonal elements in the array D are assumed to satisfy
D(i) &lt; D(j)  for  i &lt; j .
We also assume RHO &gt; 0 and that the Euclidean norm of the vector
Z is one.</p></td></tr>
			   <tr><td><a href='../interface/laed6.html'>laed6</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of
z(1)        z(2)        z(3)
f(x) =   rho + --------- + ---------- + ---------
d(1)-x      d(2)-x      d(3)-x
It is assumed that
if ORGATI = .true. the root is between d(2) and d(3);
otherwise it is between d(1) and d(2)
This routine will be called by DLAED4 when necessary. In most cases,
the root sought is the smallest in magnitude, though it might not be
in some extremely rare situations.</p></td></tr>
			   <tr><td><a href='../interface/laed7.html'>laed7</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix after modification by a rank-one symmetric matrix. This
routine is used only for the eigenproblem which requires all
eigenvalues and optionally eigenvectors of a dense or banded
Hermitian matrix that has been reduced to tridiagonal form.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>H ) Q</em><em>H(in) = Q(out) * D(out) * Q</em><em>H(out)
where Z = Q</em>*Hu, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine SLAED2.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine SLAED4 (as called by SLAED3).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../interface/laed8.html'>laed8</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny element in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../interface/laed9.html'>laed9</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>values in D, Z, and RHO, between KSTART and KSTOP.  It makes the
appropriate calls to DLAED4 and then stores the new matrix of
eigenvectors for use in calculating the next level of Z vectors.</p></td></tr>
			   <tr><td><a href='../interface/laeda.html'>laeda</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>CURLVLth step of the merge process with TLVLS steps for the CURPBMth
problem.</p></td></tr>
			   <tr><td><a href='../interface/laein.html'>laein</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>corresponding to the eigenvalue W of a complex upper Hessenberg
matrix H.</p></td></tr>
			   <tr><td><a href='../interface/laesy.html'>laesy</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>( ( A, B );( B, C ) )
provided the norm of the matrix of eigenvectors is larger than
some threshold value.
RT1 is the eigenvalue of larger absolute value, and RT2 of
smaller absolute value.  If the eigenvectors are computed, then
on return ( CS1, SN1 ) is the unit eigenvector for RT1, hence
[  CS1     SN1   ] . [ A  B ] . [ CS1    -SN1   ] = [ RT1  0  ]
[ -SN1     CS1   ]   [ B  C ]   [ SN1     CS1   ]   [  0  RT2 ]</p></td></tr>
			   <tr><td><a href='../interface/laexc.html'>laexc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>an upper quasi-triangular matrix T by an orthogonal similarity
transformation.
T must be in Schur canonical form, that is, block upper triangular
with 1-by-1 and 2-by-2 diagonal blocks; each 2-by-2 diagonal block
has its diagonal elements equal and its off-diagonal elements of
opposite sign.</p></td></tr>
			   <tr><td><a href='../interface/lagtf.html'>lagtf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal matrix and lambda is a scalar, as
T - lambda*I = PLU,
where P is a permutation matrix, L is a unit lower tridiagonal matrix
with at most one non-zero sub-diagonal elements per column and U is
an upper triangular matrix with at most two non-zero super-diagonal
elements per column.
The factorization is obtained by Gaussian elimination with partial
pivoting and implicit row scaling.
The parameter LAMBDA is included in the routine so that LAGTF may
be used, in conjunction with DLAGTS, to obtain eigenvectors of T by
inverse iteration.</p></td></tr>
			   <tr><td><a href='../interface/lagtm.html'>lagtm</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>B := alpha * A * X + beta * B
where A is a tridiagonal matrix of order N, B and X are N by NRHS
matrices, and alpha and beta are real scalars, each of which may be
0., 1., or -1.</p></td></tr>
			   <tr><td><a href='../interface/lagts.html'>lagts</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>(T - lambda<em>I)</em>x = y   or   (T - lambda<em>I)</em><em>T</em>x = y,
where T is an n by n tridiagonal matrix, for x, following the
factorization of (T - lambda<em>I) as
(T - lambda</em>I) = P<em>L</em>U ,
by routine DLAGTF. The choice of equation to be solved is
controlled by the argument JOB, and in each case there is an option
to perturb zero or very small diagonal elements of U, this option
being intended for use in applications such as inverse iteration.</p></td></tr>
			   <tr><td><a href='../interface/lahef.html'>lahef</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the Bunch-Kaufman diagonal pivoting method. The
partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I      0     )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0      I     )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**H denotes the conjugate transpose of U.
LAHEF is an auxiliary routine called by CHETRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../interface/lahef_aa.html'>lahef_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../interface/lahef_rk.html'>lahef_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
LAHEF_RK is an auxiliary routine called by CHETRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../interface/lahef_rook.html'>lahef_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting
method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I      0     )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0      I     )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**H denotes the conjugate transpose of U.
LAHEF_ROOK is an auxiliary routine called by CHETRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../interface/lahqr.html'>lahqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvalues and Schur decomposition already computed by CHSEQR, by
dealing with the Hessenberg submatrix in rows and columns ILO to
IHI.</p></td></tr>
			   <tr><td><a href='../interface/laic1.html'>laic1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>its simplest version:
Let x, twonorm(x) = 1, be an approximate singular vector of an j-by-j
lower triangular matrix L, such that
twonorm(L<em>x) = sest
Then LAIC1 computes sestpr, s, c such that
the vector
[ s</em>x ]
xhat = [  c  ]
is an approximate singular vector of
[ L      0  ]
Lhat = [ w<strong>H gamma ]
in the sense that
twonorm(Lhat*xhat) = sestpr.
Depending on JOB, an estimate for the largest or smallest singular
value is computed.
Note that [s c]</strong>H and sestpr<strong>2 is an eigenpair of the system
diag(sest*sest, 0) + [alpha  gamma] * [ conjg(alpha) ]
[ conjg(gamma) ]
where  alpha =  x</strong>H*w.</p></td></tr>
			   <tr><td><a href='../interface/laisnan.html'>laisnan</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This routine is not for general use.  It exists solely to avoid
over-optimization in DISNAN.
LAISNAN: checks for NaNs by comparing its two arguments for
inequality.  NaN is the only floating-point value where NaN != NaN
returns .TRUE.  To check for NaNs, pass the same variable as both
arguments.
A compiler must assume that the two arguments are
not the same variable, and the test will not be optimized away.
Interprocedural or whole-program optimization may delete this
test.  The ISNAN functions will be replaced by the correct
Fortran 03 intrinsic once the intrinsic is widely available.</p></td></tr>
			   <tr><td><a href='../interface/lals0.html'>lals0</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>right singular vector matrix of a diagonal matrix appended by a row
to the right hand side matrix B in solving the least squares problem
using the divide-and-conquer SVD approach.
For the left singular vector matrix, three types of orthogonal
matrices are involved:
(1L) Givens rotations: the number of such rotations is GIVPTR; the
pairs of columns/rows they were applied to are stored in GIVCOL;
and the C- and S-values of these rotations are stored in GIVNUM.
(2L) Permutation. The (NL+1)-st row of B is to be moved to the first
row, and for J=2:N, PERM(J)-th row of B is to be moved to the
J-th row.
(3L) The left singular vector matrix of the remaining matrix.
For the right singular vector matrix, four types of orthogonal
matrices are involved:
(1R) The right singular vector matrix of the remaining matrix.
(2R) If SQRE = 1, one extra Givens rotation to generate the right
null space.
(3R) The inverse transformation of (2L).
(4R) The inverse transformation of (1L).</p></td></tr>
			   <tr><td><a href='../interface/lalsa.html'>lalsa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>by computing the SVD of the coefficient matrix in compact form (The
singular vectors are computed as products of simple orthorgonal
matrices.).
If ICOMPQ = 0, LALSA applies the inverse of the left singular vector
matrix of an upper bidiagonal matrix to the right hand side; and if
ICOMPQ = 1, LALSA applies the right singular vector matrix to the
right hand side. The singular vector matrices were generated in
compact form by LALSA.</p></td></tr>
			   <tr><td><a href='../interface/lalsd.html'>lalsd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>squares problem of finding X to minimize the Euclidean norm of each
column of A*X-B, where A is N-by-N upper bidiagonal, and X and B
are N-by-NRHS. The solution X overwrites B.
The singular values of A smaller than RCOND times the largest
singular value are treated as zero in solving the least squares
problem; in this case a minimum norm solution is returned.
The actual singular values are returned in D in ascending order.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/lamrg.html'>lamrg</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of A (which is composed of two independently sorted sets) into a
single set which is sorted in ascending order.</p></td></tr>
			   <tr><td><a href='../interface/lamswlq.html'>lamswlq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of blocked
elementary reflectors computed by short wide LQ
factorization (CLASWLQ)</p></td></tr>
			   <tr><td><a href='../interface/lamtsqr.html'>lamtsqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (CLATSQR)</p></td></tr>
			   <tr><td><a href='../interface/laneg.html'>laneg</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>encountered while factoring tridiagonal T - sigma I = L D L^T.
This implementation works directly on the factors without forming
the tridiagonal matrix T.  The Sturm count is also the number of
eigenvalues of T less than sigma.
This routine is called from DLARRB.
The current routine does not use the PIVMIN parameter but rather
requires IEEE-754 propagation of Infinities and NaNs.  This
routine also has no input range restrictions but does require
default exception handling such that x/0 produces Inf when x is
non-zero, and Inf/Inf produces NaN.  For more information, see:
Marques, Riedy, and Voemel, "Benefits of IEEE-754 Features in
Modern Symmetric Tridiagonal Eigensolvers," SIAM Journal on
Scientific Computing, v28, n5, 2006.  DOI 10.1137/050641624
(Tech report version in LAWN 172 with the same title.)</p></td></tr>
			   <tr><td><a href='../interface/langb.html'>langb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n band matrix  A,  with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../interface/lange.html'>lange</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex matrix A.</p></td></tr>
			   <tr><td><a href='../interface/langt.html'>langt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../interface/lanhb.html'>lanhb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n hermitian band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../interface/lanhe.html'>lanhe</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex hermitian matrix A.</p></td></tr>
			   <tr><td><a href='../interface/lanhf.html'>lanhf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex Hermitian matrix A in RFP format.</p></td></tr>
			   <tr><td><a href='../interface/lanhp.html'>lanhp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex hermitian matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/lanhs.html'>lanhs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
Hessenberg matrix A.</p></td></tr>
			   <tr><td><a href='../interface/lanht.html'>lanht</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex Hermitian tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../interface/lansb.html'>lansb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n symmetric band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../interface/lansf.html'>lansf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the infinity norm, or the element of largest absolute value of a
real symmetric matrix A in RFP format.</p></td></tr>
			   <tr><td><a href='../interface/lansp.html'>lansp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex symmetric matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/lanst.html'>lanst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../interface/lansy.html'>lansy</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../interface/lantb.html'>lantb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n triangular band matrix A,  with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../interface/lantp.html'>lantp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
triangular matrix A, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/lantr.html'>lantr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
trapezoidal or triangular matrix A.</p></td></tr>
			   <tr><td><a href='../interface/laorhr_col_getrfnp.html'>laorhr_col_getrfnp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>pivoting of a real general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is
at least one in absolute value (so that division-by-zero not
not possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine DORHR_COL. In DORHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the blocked right-looking version of the algorithm,
calling Level 3 BLAS to update the submatrix. To factorize a block,
this routine calls the recursive routine LAORHR_COL_GETRFNP2.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.</p></td></tr>
			   <tr><td><a href='../interface/laorhr_col_getrfnp2.html'>laorhr_col_getrfnp2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>pivoting of a real general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is at
least one in absolute value (so that division-by-zero not
possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine DORHR_COL. In DORHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the recursive version of the LU factorization algorithm.
Denote A - S by B. The algorithm divides the matrix B into four
submatrices:
[  B11 | B12  ]  where B11 is n1 by n1,
B = [ -----|----- ]        B21 is (m-n1) by n1,
[  B21 | B22  ]        B12 is n1 by n2,
B22 is (m-n1) by n2,
with n1 = min(m,n)/2, n2 = n-n1.
The subroutine calls itself to factor B11, solves for B21,
solves for B12, updates B22, then calls itself to factor B22.
For more details on the recursive LU algorithm, see [2].
LAORHR_COL_GETRFNP2 is called to factorize a block by the blocked
routine DLAORHR_COL_GETRFNP, which uses blocked code calling
Level 3 BLAS to update the submatrix. However, LAORHR_COL_GETRFNP2
is self-sufficient and can be used without DLAORHR_COL_GETRFNP.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.
[2] "Recursion leads to automatic variable blocking for dense linear
algebra algorithms", F. Gustavson, IBM J. of Res. and Dev.,
vol. 41, no. 6, pp. 737-755, 1997.</p></td></tr>
			   <tr><td><a href='../interface/lapll.html'>lapll</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Given two column vectors X and Y, let
A = ( X Y ).
The subroutine first computes the QR factorization of A = Q*R,
and then computes the SVD of the 2-by-2 upper triangular matrix R.
The smaller singular value of R is returned in SSMIN, which is used
as the measurement of the linear dependency of the vectors X and Y.</p></td></tr>
			   <tr><td><a href='../interface/lapmr.html'>lapmr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>by the permutation K(1),K(2),...,K(M) of the integers 1,...,M.
If FORWRD = .TRUE.,  forward permutation:
X(K(I),<em>) is moved X(I,</em>) for I = 1,2,...,M.
If FORWRD = .FALSE., backward permutation:
X(I,<em>) is moved to X(K(I),</em>) for I = 1,2,...,M.</p></td></tr>
			   <tr><td><a href='../interface/lapmt.html'>lapmt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>by the permutation K(1),K(2),...,K(N) of the integers 1,...,N.
If FORWRD = .TRUE.,  forward permutation:
X(<em>,K(J)) is moved X(</em>,J) for J = 1,2,...,N.
If FORWRD = .FALSE., backward permutation:
X(<em>,J) is moved to X(</em>,K(J)) for J = 1,2,...,N.</p></td></tr>
			   <tr><td><a href='../interface/laqgb.html'>laqgb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>subdiagonals and KU superdiagonals using the row and scaling factors
in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../interface/laqge.html'>laqge</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>column scaling factors in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../interface/laqhb.html'>laqhb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../interface/laqhe.html'>laqhe</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../interface/laqhp.html'>laqhp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../interface/laqps.html'>laqps</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a complex M-by-N matrix A by using Blas-3.  It tries to factorize
NB columns from A starting from the row OFFSET+1, and updates all
of the matrix with Blas-3 xGEMM.
In some cases, due to catastrophic cancellations, it cannot
factorize NB columns.  Hence, the actual number of factorized
columns is returned in KB.
Block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../interface/laqr0.html'>laqr0</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>H</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../interface/laqr1.html'>laqr1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Given a 2-by-2 or 3-by-3 matrix H, LAQR1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (H - s1</em>I)<em>(H - s2</em>I)
scaling to avoid overflows and most underflows.
This is useful for starting double implicit shift bulges
in the QR algorithm.</p></td></tr>
			   <tr><td><a href='../interface/laqr4.html'>laqr4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>It is a complete implementation of the small bulge multi-shift
QR algorithm.  It may be called by CLAQR0 and, for large enough
deflation window size, it may be called by CLAQR3.  This
subroutine is identical to CLAQR0 except that it calls CLAQR2
instead of CLAQR3.
LAQR4 computes the eigenvalues of a Hessenberg matrix H
and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>H</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../interface/laqr5.html'>laqr5</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>single small-bulge multi-shift QR sweep.</p></td></tr>
			   <tr><td><a href='../interface/laqsb.html'>laqsb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../interface/laqsp.html'>laqsp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../interface/laqsy.html'>laqsy</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../interface/laqtr.html'>laqtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(T)<em>p = scale</em>c,               if LREAL = .TRUE.
or the complex quasi-triangular systems
op(T + iB)<em>(p+iq) = scale</em>(c+id),  if LREAL = .FALSE.
in real arithmetic, where T is upper quasi-triangular.
If LREAL = .FALSE., then the first diagonal block of T must be
1 by 1, B is the specially structured matrix
B = [ b(1) b(2) ... b(n) ]
[       w            ]
[           w        ]
[              .     ]
[                 w  ]
op(A) = A or A<strong>T, A</strong>T denotes the transpose of
matrix A.
On input, X = [ c ].  On output, X = [ p ].
[ d ]                  [ q ]
This subroutine is designed for the condition number estimation
in routine DTRSNA.</p></td></tr>
			   <tr><td><a href='../interface/laqz0.html'>laqz0</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>H,  B = Q1<em>T</em>Z1</strong>H,
as computed by CGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>H,  T = Q<em>P</em>Z</strong>H,
where Q and Z are unitary matrices, P and S are an upper triangular
matrices.
Optionally, the unitary matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
unitary matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the unitary matrices from CGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the unitary factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>H,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>H.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.
Ref: B. Kagstrom, D. Kressner, "Multishift Variants of the QZ
Algorithm with Aggressive Early Deflation", SIAM J. Numer.
Anal., 29(2006), pp. 199--227.
Ref: T. Steel, D. Camps, K. Meerbergen, R. Vandebril "A multishift,
multipole rational QZ method with agressive early deflation"</p></td></tr>
			   <tr><td><a href='../interface/laqz1.html'>laqz1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>LAQZ1: chases a 1x1 shift bulge in a matrix pencil down a single position</p></td></tr>
			   <tr><td><a href='../interface/laqz4.html'>laqz4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>LAQZ4: Executes a single multishift QZ sweep</p></td></tr>
			   <tr><td><a href='../interface/lar1v.html'>lar1v</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>the sumbmatrix in rows B1 through BN of the tridiagonal matrix
L D L<strong>T - sigma I. When sigma is close to an eigenvalue, the
computed vector is an accurate eigenvector. Usually, r corresponds
to the index where the eigenvector is largest in magnitude.
The following steps accomplish this computation :
(a) Stationary qd transform,  L D L</strong>T - sigma I = L(+) D(+) L(+)<strong>T,
(b) Progressive qd transform, L D L</strong>T - sigma I = U(-) D(-) U(-)<strong>T,
(c) Computation of the diagonal elements of the inverse of
L D L</strong>T - sigma I by combining the above transforms, and choosing
r as the index where the diagonal of the inverse is (one of the)
largest in magnitude.
(d) Computation of the (scaled) r-th column of the inverse using the
twisted factorization obtained by combining the top part of the
the stationary and the bottom part of the progressive transform.</p></td></tr>
			   <tr><td><a href='../interface/lar2v.html'>lar2v</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>from both sides to a sequence of 2-by-2 complex Hermitian matrices,
defined by the elements of the vectors x, y and z. For i = 1,2,...,n
(       x(i)  z(i) ) :=
( conjg(z(i)) y(i) )
(  c(i) conjg(s(i)) ) (       x(i)  z(i) ) ( c(i) -conjg(s(i)) )
( -s(i)       c(i)  ) ( conjg(z(i)) y(i) ) ( s(i)        c(i)  )</p></td></tr>
			   <tr><td><a href='../interface/larcm.html'>larcm</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>C := A * B,
where A is M by M and real; B is M by N and complex;
C is M by N and complex.</p></td></tr>
			   <tr><td><a href='../interface/larf.html'>larf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v<strong>H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix.
To apply H</strong>H (the conjugate transpose of H), supply conjg(tau) instead
tau.</p></td></tr>
			   <tr><td><a href='../interface/larfb.html'>larfb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>complex M-by-N matrix C, from either the left or the right.</p></td></tr>
			   <tr><td><a href='../interface/larfb_gett.html'>larfb_gett</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>left to a complex (K+M)-by-N  "triangular-pentagonal" matrix
composed of two block matrices: an upper trapezoidal K-by-N matrix A
stored in the array A, and a rectangular M-by-(N-K) matrix B, stored
in the array B. The block reflector H is stored in a compact
WY-representation, where the elementary reflectors are in the
arrays A, B and T. See Further Details section.</p></td></tr>
			   <tr><td><a href='../interface/larfg.html'>larfg</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>that
H<strong>H * ( alpha ) = ( beta ),   H</strong>H * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, with beta real, and x is an
(n-1)-element complex vector. H is represented in the form
H = I - tau * ( 1 ) * ( 1 v**H ) ,
( v )
where tau is a complex scalar and v is a complex (n-1)-element
vector. Note that H is not hermitian.
If the elements of x are all zero and alpha is real, then tau = 0
and H is taken to be the unit matrix.
Otherwise  1 &lt;= real(tau) &lt;= 2  and  abs(tau-1) &lt;= 1 .</p></td></tr>
			   <tr><td><a href='../interface/larfgp.html'>larfgp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>that
H<strong>H * ( alpha ) = ( beta ),   H</strong>H * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, beta is real and non-negative, and
x is an (n-1)-element complex vector.  H is represented in the form
H = I - tau * ( 1 ) * ( 1 v**H ) ,
( v )
where tau is a complex scalar and v is a complex (n-1)-element
vector. Note that H is not hermitian.
If the elements of x are all zero and alpha is real, then tau = 0
and H is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../interface/larft.html'>larft</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of order n, which is defined as a product of k elementary reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>H
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>H * T * V</p></td></tr>
			   <tr><td><a href='../interface/larfy.html'>larfy</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to an n x n Hermitian matrix C, from both the left and the right.
H is represented in the form
H = I - tau * v * v'
where  tau  is a scalar and  v  is a vector.
If  tau  is  zero, then  H  is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../interface/largv.html'>largv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>cosines, determined by elements of the complex vectors x and y.
For i = 1,2,...,n
(        c(i)   s(i) ) ( x(i) ) = ( r(i) )
( -conjg(s(i))  c(i) ) ( y(i) ) = (   0  )
where c(i)<strong>2 + ABS(s(i))</strong>2 = 1
The following conventions are used (these are the same as in CLARTG,
but differ from the BLAS1 routine CROTG):
If y(i)=0, then c(i)=1 and s(i)=0.
If x(i)=0, then c(i)=0 and s(i) is chosen so that r(i) is real.</p></td></tr>
			   <tr><td><a href='../interface/larnv.html'>larnv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>normal distribution.</p></td></tr>
			   <tr><td><a href='../interface/larra.html'>larra</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Compute the splitting points with threshold SPLTOL.
LARRA: sets any "small" off-diagonal elements to zero.</p></td></tr>
			   <tr><td><a href='../interface/larrb.html'>larrb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Given the relatively robust representation(RRR) L D L^T, LARRB:
does "limited" bisection to refine the eigenvalues of L D L^T,
W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial
guesses for these eigenvalues are input in W, the corresponding estimate
of the error in these guesses and their gaps are input in WERR
and WGAP, respectively. During bisection, intervals
[left, right] are maintained by storing their mid-points and
semi-widths in the arrays W and WERR respectively.</p></td></tr>
			   <tr><td><a href='../interface/larrc.html'>larrc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Find the number of eigenvalues of the symmetric tridiagonal matrix T
that are in the interval (VL,VU] if JOBT = 'T', and of L D L^T
if JOBT = 'L'.</p></td></tr>
			   <tr><td><a href='../interface/larrd.html'>larrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix T to suitable accuracy. This is an auxiliary code to be
called from DSTEMR.
The user may ask for all eigenvalues, all eigenvalues
in the half-open interval (VL, VU], or the IL-th through IU-th
eigenvalues.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../interface/larre.html'>larre</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>To find the desired eigenvalues of a given real symmetric
tridiagonal matrix T, LARRE: sets any "small" off-diagonal
elements to zero, and for each unreduced block T_i, it finds
(a) a suitable shift at one end of the block's spectrum,
(b) the base representation, T_i - sigma_i I = L_i D_i L_i^T, and
(c) eigenvalues of each L_i D_i L_i^T.
The representations and eigenvalues found are then used by
DSTEMR to compute the eigenvectors of T.
The accuracy varies depending on whether bisection is used to
find a few eigenvalues or the dqds algorithm (subroutine DLASQ2) to
conpute all and then discard any unwanted one.
As an added benefit, LARRE also outputs the n
Gerschgorin intervals for the matrices L_i D_i L_i^T.</p></td></tr>
			   <tr><td><a href='../interface/larrf.html'>larrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Given the initial representation L D L^T and its cluster of close
eigenvalues (in a relative measure), W( CLSTRT ), W( CLSTRT+1 ), ...
W( CLEND ), LARRF: finds a new relatively robust representation
L D L^T - SIGMA I = L(+) D(+) L(+)^T such that at least one of the
eigenvalues of L(+) D(+) L(+)^T is relatively isolated.</p></td></tr>
			   <tr><td><a href='../interface/larrj.html'>larrj</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Given the initial eigenvalue approximations of T, LARRJ:
does  bisection to refine the eigenvalues of T,
W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial
guesses for these eigenvalues are input in W, the corresponding estimate
of the error in these guesses in WERR. During bisection, intervals
[left, right] are maintained by storing their mid-points and
semi-widths in the arrays W and WERR respectively.</p></td></tr>
			   <tr><td><a href='../interface/larrk.html'>larrk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix T to suitable accuracy. This is an auxiliary code to be
called from DSTEMR.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../interface/larrr.html'>larrr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Perform tests to decide whether the symmetric tridiagonal matrix T
warrants expensive computations which guarantee high relative accuracy
in the eigenvalues.</p></td></tr>
			   <tr><td><a href='../interface/larrv.html'>larrv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>T = L D L<strong>T given L, D and APPROXIMATIONS to the eigenvalues of L D L</strong>T.
The input eigenvalues should have been computed by SLARRE.</p></td></tr>
			   <tr><td><a href='../interface/lartg.html'>lartg</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>!</p><a href="../interface/lartg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/lartgp.html'>lartgp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>[  CS  SN  ]  .  [ F ]  =  [ R ]   where CS<strong>2 + SN</strong>2 = 1.
[ -SN  CS  ]     [ G ]     [ 0 ]
This is a slower, more accurate version of the Level 1 BLAS routine DROTG,
with the following other differences:
F and G are unchanged on return.
If G=0, then CS=(+/-)1 and SN=0.
If F=0 and (G .ne. 0), then CS=0 and SN=(+/-)1.
The sign is chosen so that R &gt;= 0.</p></td></tr>
			   <tr><td><a href='../interface/lartgs.html'>lartgs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Golub-Reinsch-style implicit QR iteration for the bidiagonal SVD
problem. X and Y are the top-row entries, and SIGMA is the shift.
The computed CS and SN define a plane rotation satisfying
[  CS  SN  ]  .  [ X^2 - SIGMA ]  =  [ R ],
[ -SN  CS  ]     [    X * Y    ]     [ 0 ]
with R nonnegative.  If X^2 - SIGMA and X * Y are 0, then the
rotation is by PI/2.</p></td></tr>
			   <tr><td><a href='../interface/lartv.html'>lartv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to elements of the complex vectors x and y. For i = 1,2,...,n
( x(i) ) := (        c(i)   s(i) ) ( x(i) )
( y(i) )    ( -conjg(s(i))  c(i) ) ( y(i) )</p></td></tr>
			   <tr><td><a href='../interface/laruv.html'>laruv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>distribution (n &lt;= 128).
This is an auxiliary routine called by DLARNV and ZLARNV.</p></td></tr>
			   <tr><td><a href='../interface/larz.html'>larz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>M-by-N matrix C, from either the left or the right. H is represented
in the form
H = I - tau * v * v<strong>H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix.
To apply H</strong>H (the conjugate transpose of H), supply conjg(tau) instead
tau.
H is a product of k elementary reflectors as returned by CTZRZF.</p></td></tr>
			   <tr><td><a href='../interface/larzb.html'>larzb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to a complex distributed M-by-N  C from the left or the right.
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../interface/larzt.html'>larzt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>H of order &gt; n, which is defined as a product of k elementary
reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>H
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>H * T * V
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../interface/lascl.html'>lascl</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>CTO/CFROM.  This is done without over/underflow as long as the final
result CTO*A(I,J)/CFROM does not over/underflow. TYPE specifies that
A may be full, upper triangular, lower triangular, upper Hessenberg,
or banded.</p></td></tr>
			   <tr><td><a href='../interface/lasd0.html'>lasd0</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Using a divide and conquer approach, LASD0: computes the singular
value decomposition (SVD) of a real upper bidiagonal N-by-M
matrix B with diagonal D and offdiagonal E, where M = N + SQRE.
The algorithm computes orthogonal matrices U and VT such that
B = U * S * VT. The singular values S are overwritten on D.
A related subroutine, DLASDA, computes only the singular values,
and optionally, the singular vectors in compact form.</p></td></tr>
			   <tr><td><a href='../interface/lasd1.html'>lasd1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>where N = NL + NR + 1 and M = N + SQRE. LASD1 is called from DLASD0.
A related subroutine DLASD7 handles the case in which the singular
values (and the singular vectors in factored form) are desired.
LASD1 computes the SVD as follows:
( D1(in)    0    0       0 )
B = U(in) * (   Z1<strong>T   a   Z2</strong>T    b ) * VT(in)
(   0       0   D2(in)   0 )
= U(out) * ( D(out) 0) * VT(out)
where Z<strong>T = (Z1</strong>T a Z2<strong>T b) = u</strong>T VT**T, and u is a vector of dimension M
with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros
elsewhere; and the entry b is empty if SQRE = 0.
The left singular vectors of the original matrix are stored in U, and
the transpose of the right singular vectors are stored in VT, and the
singular values are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple singular values or when there are zeros in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine DLASD2.
The second stage consists of calculating the updated
singular values. This is done by finding the square roots of the
roots of the secular equation via the routine DLASD4 (as called
by DLASD3). This routine also calculates the singular vectors of
the current problem.
The final stage consists of computing the updated singular vectors
directly using the updated singular values.  The singular vectors
for the current problem are multiplied with the singular vectors
from the overall problem.</p></td></tr>
			   <tr><td><a href='../interface/lasd4.html'>lasd4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This subroutine computes the square root of the I-th updated
eigenvalue of a positive symmetric rank-one modification to
a positive diagonal matrix whose entries are given as the squares
of the corresponding entries in the array d, and that
0 &lt;= D(i) &lt; D(j)  for  i &lt; j
and that RHO &gt; 0. This is arranged by the calling routine, and is
no loss in generality.  The rank-one modified system is thus
diag( D ) * diag( D ) +  RHO * Z * Z_transpose.
where we assume the Euclidean norm of Z is 1.
The method consists of approximating the rational functions in the
secular equation by simpler interpolating rational functions.</p></td></tr>
			   <tr><td><a href='../interface/lasd5.html'>lasd5</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This subroutine computes the square root of the I-th eigenvalue
of a positive symmetric rank-one modification of a 2-by-2 diagonal
matrix
diag( D ) * diag( D ) +  RHO * Z * transpose(Z) .
The diagonal entries in the array D are assumed to satisfy
0 &lt;= D(i) &lt; D(j)  for  i &lt; j .
We also assume RHO &gt; 0 and that the Euclidean norm of the vector
Z is one.</p></td></tr>
			   <tr><td><a href='../interface/lasd6.html'>lasd6</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>obtained by merging two smaller ones by appending a row. This
routine is used only for the problem which requires all singular
values and optionally singular vector matrices in factored form.
B is an N-by-M matrix with N = NL + NR + 1 and M = N + SQRE.
A related subroutine, DLASD1, handles the case in which all singular
values and singular vectors of the bidiagonal matrix are desired.
LASD6 computes the SVD as follows:
( D1(in)    0    0       0 )
B = U(in) * (   Z1<strong>T   a   Z2</strong>T    b ) * VT(in)
(   0       0   D2(in)   0 )
= U(out) * ( D(out) 0) * VT(out)
where Z<strong>T = (Z1</strong>T a Z2<strong>T b) = u</strong>T VT**T, and u is a vector of dimension M
with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros
elsewhere; and the entry b is empty if SQRE = 0.
The singular values of B can be computed using D1, D2, the first
components of all the right singular vectors of the lower block, and
the last components of all the right singular vectors of the upper
block. These components are stored and updated in VF and VL,
respectively, in LASD6. Hence U and VT are not explicitly
referenced.
The singular values are stored in D. The algorithm consists of two
stages:
The first stage consists of deflating the size of the problem
when there are multiple singular values or if there is a zero
in the Z vector. For each such occurrence the dimension of the
secular equation problem is reduced by one. This stage is
performed by the routine DLASD7.
The second stage consists of calculating the updated
singular values. This is done by finding the roots of the
secular equation via the routine DLASD4 (as called by DLASD8).
This routine also updates VF and VL and computes the distances
between the updated singular values and the old singular
values.
LASD6 is called from DLASDA.</p></td></tr>
			   <tr><td><a href='../interface/lasd7.html'>lasd7</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>sorted set. Then it tries to deflate the size of the problem. There
are two ways in which deflation can occur:  when two or more singular
values are close together or if there is a tiny entry in the Z
vector. For each such occurrence the order of the related
secular equation problem is reduced by one.
LASD7 is called from DLASD6.</p></td></tr>
			   <tr><td><a href='../interface/lasd8.html'>lasd8</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>as defined by the values in DSIGMA and Z. It makes the appropriate
calls to DLASD4, and stores, for each  element in D, the distance
to its two nearest poles (elements in DSIGMA). It also updates
the arrays VF and VL, the first and last components of all the
right singular vectors of the original bidiagonal matrix.
LASD8 is called from DLASD6.</p></td></tr>
			   <tr><td><a href='../interface/lasda.html'>lasda</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Using a divide and conquer approach, LASDA: computes the singular
value decomposition (SVD) of a real upper bidiagonal N-by-M matrix
B with diagonal D and offdiagonal E, where M = N + SQRE. The
algorithm computes the singular values in the SVD B = U * S * VT.
The orthogonal matrices U and VT are optionally computed in
compact form.
A related subroutine, DLASD0, computes the singular values and
the singular vectors in explicit form.</p></td></tr>
			   <tr><td><a href='../interface/lasdq.html'>lasdq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>(upper or lower) bidiagonal matrix with diagonal D and offdiagonal
E, accumulating the transformations if desired. Letting B denote
the input bidiagonal matrix, the algorithm computes orthogonal
matrices Q and P such that B = Q * S * P<strong>T (P</strong>T denotes the transpose
of P). The singular values S are overwritten on D.
The input matrix U  is changed to U  * Q  if desired.
The input matrix VT is changed to P<strong>T * VT if desired.
The input matrix C  is changed to Q</strong>T * C  if desired.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3, for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../interface/laset.html'>laset</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>ALPHA on the offdiagonals.</p></td></tr>
			   <tr><td><a href='../interface/lasq1.html'>lasq1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix with diagonal D and off-diagonal E. The singular values
are computed to high relative accuracy, in the absence of
denormalization, underflow and overflow. The algorithm was first
presented in
"Accurate singular values and differential qd algorithms" by K. V.
Fernando and B. N. Parlett, Numer. Math., Vol-67, No. 2, pp. 191-230,
1994,
and the present implementation is described in "An implementation of
the dqds Algorithm (Positive Case)", LAPACK Working Note.</p></td></tr>
			   <tr><td><a href='../interface/lasq4.html'>lasq4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using values of d from the previous transform.</p></td></tr>
			   <tr><td><a href='../interface/lasq5.html'>lasq5</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>version for IEEE machines another for non IEEE machines.</p></td></tr>
			   <tr><td><a href='../interface/lasq6.html'>lasq6</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>ping-pong form, with protection against underflow and overflow.</p></td></tr>
			   <tr><td><a href='../interface/lasr.html'>lasr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A, from either the left or the right.
When SIDE = 'L', the transformation takes the form
A := P<em>A
and when SIDE = 'R', the transformation takes the form
A := A</em>P<strong>T
where P is an orthogonal matrix consisting of a sequence of z plane
rotations, with z = M when SIDE = 'L' and z = N when SIDE = 'R',
and P</strong>T is the transpose of P.
When DIRECT = 'F' (Forward sequence), then
P = P(z-1) * ... * P(2) * P(1)
and when DIRECT = 'B' (Backward sequence), then
P = P(1) * P(2) * ... * P(z-1)
where P(k) is a plane rotation matrix defined by the 2-by-2 rotation
R(k) = (  c(k)  s(k) )
= ( -s(k)  c(k) ).
When PIVOT = 'V' (Variable pivot), the rotation is performed
for the plane (k,k+1), i.e., P(k) has the form
P(k) = (  1                                            )
(       ...                                     )
(              1                                )
(                   c(k)  s(k)                  )
(                  -s(k)  c(k)                  )
(                                1              )
(                                     ...       )
(                                            1  )
where R(k) appears as a rank-2 modification to the identity matrix in
rows and columns k and k+1.
When PIVOT = 'T' (Top pivot), the rotation is performed for the
plane (1,k+1), so P(k) has the form
P(k) = (  c(k)                    s(k)                 )
(         1                                     )
(              ...                              )
(                     1                         )
( -s(k)                    c(k)                 )
(                                 1             )
(                                      ...      )
(                                             1 )
where R(k) appears in rows and columns 1 and k+1.
Similarly, when PIVOT = 'B' (Bottom pivot), the rotation is
performed for the plane (k,z), giving P(k) the form
P(k) = ( 1                                             )
(      ...                                      )
(             1                                 )
(                  c(k)                    s(k) )
(                         1                     )
(                              ...              )
(                                     1         )
(                 -s(k)                    c(k) )
where R(k) appears in rows and columns k and z.  The rotations are
performed without ever forming P(k) explicitly.</p></td></tr>
			   <tr><td><a href='../interface/lasrt.html'>lasrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Sort the numbers in D in increasing order (if ID = 'I') or
in decreasing order (if ID = 'D' ).
Use Quick Sort, reverting to Insertion sort on arrays of
size &lt;= 20. Dimension of STACK limits N to about 2**32.</p></td></tr>
			   <tr><td><a href='../interface/lassq.html'>lassq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>!</p><a href="../interface/lassq.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/laswlq.html'>laswlq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex M-by-N matrix A for M &lt;= N:
A = ( L 0 ) *  Q,
where:
Q is a n-by-N orthogonal matrix, stored on exit in an implicit
form in the elements above the diagonal of the array A and in
the elements of the array T;
L is a lower-triangular M-by-M matrix stored on exit in
the elements on and below the diagonal of the array A.
0 is a M-by-(N-M) zero matrix, if M &lt; N, and is not stored.</p></td></tr>
			   <tr><td><a href='../interface/laswp.html'>laswp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>One row interchange is initiated for each of rows K1 through K2 of A.</p></td></tr>
			   <tr><td><a href='../interface/lasyf.html'>lasyf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A using the Bunch-Kaufman diagonal pivoting method. The partial
factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) ( D    0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) ( 0   A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**T denotes the transpose of U.
LASYF is an auxiliary routine called by CSYTRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../interface/lasyf_aa.html'>lasyf_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>DLATRF_AA factorizes a panel of a complex symmetric matrix A using
the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../interface/lasyf_rk.html'>lasyf_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
LASYF_RK is an auxiliary routine called by CSYTRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../interface/lasyf_rook.html'>lasyf_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
LASYF_ROOK is an auxiliary routine called by CSYTRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../interface/latbs.html'>latbs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow, where A is an upper or lower
triangular band matrix.  Here A</strong>T denotes the transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine CTBSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../interface/latdf.html'>latdf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>by solving for x in Z * x = b, where b is chosen such that the norm
of x is as large as possible. It is assumed that LU decomposition
of Z has been computed by CGETC2. On entry RHS = f holds the
contribution from earlier solved sub-systems, and on return RHS = x.
The factorization of Z returned by CGETC2 has the form
Z = P * L * U * Q, where P and Q are permutation matrices. L is lower
triangular with unit diagonal elements and U is upper triangular.</p></td></tr>
			   <tr><td><a href='../interface/latps.html'>latps</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow, where A is an upper or lower
triangular matrix stored in packed form.  Here A</strong>T denotes the
transpose of A, A*<em>H denotes the conjugate transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine CTPSV is called. If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A</em>x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../interface/latrd.html'>latrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian tridiagonal form by a unitary similarity
transformation Q**H * A * Q, and returns the matrices V and W which are
needed to apply the transformation to the unreduced part of A.
If UPLO = 'U', LATRD reduces the last NB rows and columns of a
matrix, of which the upper triangle is supplied;
if UPLO = 'L', LATRD reduces the first NB rows and columns of a
matrix, of which the lower triangle is supplied.
This is an auxiliary routine called by CHETRD.</p></td></tr>
			   <tr><td><a href='../interface/latrs.html'>latrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow.  Here A is an upper or lower
triangular matrix, A</strong>T denotes the transpose of A, A*<em>H denotes the
conjugate transpose of A, x and b are n-element vectors, and s is a
scaling factor, usually less than or equal to 1, chosen so that the
components of x will be less than the overflow threshold.  If the
unscaled problem will not cause overflow, the Level 2 BLAS routine
CTRSV is called. If the matrix A is singular (A(j,j) = 0 for some j),
then s is set to 0 and a non-trivial solution to A</em>x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../interface/latrz.html'>latrz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>[ A1 A2 ] = [ A(1:M,1:M) A(1:M,N-L+1:N) ] as ( R  0 ) * Z by means
of unitary transformations, where  Z is an (M+L)-by-(M+L) unitary
matrix and, R and A1 are M-by-M upper triangular matrices.</p></td></tr>
			   <tr><td><a href='../interface/latsqr.html'>latsqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex M-by-N matrix A for M &gt;= N:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix, stored on exit in an implicit
form in the elements below the diagonal of the array A and in
the elements of the array T;
R is an upper-triangular N-by-N matrix, stored on exit in
the elements on and above the diagonal of the array A.
0 is a (M-N)-by-N zero matrix, and is not stored.</p></td></tr>
			   <tr><td><a href='../interface/launhr_col_getrfnp.html'>launhr_col_getrfnp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>pivoting of a complex general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is
at least one in absolute value (so that division-by-zero not
not possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine CUNHR_COL. In CUNHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the blocked right-looking version of the algorithm,
calling Level 3 BLAS to update the submatrix. To factorize a block,
this routine calls the recursive routine LAUNHR_COL_GETRFNP2.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.</p></td></tr>
			   <tr><td><a href='../interface/launhr_col_getrfnp2.html'>launhr_col_getrfnp2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>pivoting of a complex general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is at
least one in absolute value (so that division-by-zero not
possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine CUNHR_COL. In CUNHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the recursive version of the LU factorization algorithm.
Denote A - S by B. The algorithm divides the matrix B into four
submatrices:
[  B11 | B12  ]  where B11 is n1 by n1,
B = [ -----|----- ]        B21 is (m-n1) by n1,
[  B21 | B22  ]        B12 is n1 by n2,
B22 is (m-n1) by n2,
with n1 = min(m,n)/2, n2 = n-n1.
The subroutine calls itself to factor B11, solves for B21,
solves for B12, updates B22, then calls itself to factor B22.
For more details on the recursive LU algorithm, see [2].
LAUNHR_COL_GETRFNP2 is called to factorize a block by the blocked
routine CLAUNHR_COL_GETRFNP, which uses blocked code calling
Level 3 BLAS to update the submatrix. However, LAUNHR_COL_GETRFNP2
is self-sufficient and can be used without CLAUNHR_COL_GETRFNP.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.
[2] "Recursion leads to automatic variable blocking for dense linear
algebra algorithms", F. Gustavson, IBM J. of Res. and Dev.,
vol. 41, no. 6, pp. 737-755, 1997.</p></td></tr>
			   <tr><td><a href='../interface/lauum.html'>lauum</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the blocked form of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/legendre.html'>legendre</a></td><td><a href='../module/stdlib_specialfunctions.html'>stdlib_specialfunctions</a></td><td>Interface</td><td><p>Legendre polynomial</p></td></tr>
			   <tr><td><a href='../interface/len.html'>len</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the length of the character sequence represented by the string.</p><a href="../interface/len.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/len_trim.html'>len_trim</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the length of the character sequence without trailing spaces
represented by the string.</p><a href="../interface/len_trim.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/lge.html'>lge</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Lexically compare the order of two character sequences being greater equal,
The left-hand side, the right-hand side or both character sequences can
be represented by a string.</p><a href="../interface/lge.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/lgt.html'>lgt</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Lexically compare the order of two character sequences being greater,
The left-hand side, the right-hand side or both character sequences can
be represented by a string.</p><a href="../interface/lgt.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/linspace.html'>linspace</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Create rank 1 array of linearly spaced elements
 If the number of elements is not specified, create an array with size 100. If n is a negative value,
 return an array with size 0. If n = 1, return an array whose only element is end
(<a href="../page/specs/stdlib_math.html#linspace-create-a-linearly-spaced-rank-one-array">Specification</a>)</p><a href="../interface/linspace.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/lle.html'>lle</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Lexically compare the order of two character sequences being less equal,
The left-hand side, the right-hand side or both character sequences can
be represented by a string.</p><a href="../interface/lle.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/llt.html'>llt</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Lexically compare the order of two character sequences being less,
The left-hand side, the right-hand side or both character sequences can
be represented by a string.</p><a href="../interface/llt.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/load_npy.html'>load_npy</a></td><td><a href='../module/stdlib_io_npy.html'>stdlib_io_npy</a></td><td>Interface</td><td><p>Load multidimensional array in npy format
(<a href="../page/specs/stdlib_io.html#load_npy">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/loadtxt.html'>loadtxt</a></td><td><a href='../module/stdlib_io.html'>stdlib_io</a></td><td>Interface</td><td><p>Loads a 2D array from a text file
(<a href="../page/specs/stdlib_io.html#description">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/log_factorial.html'>log_factorial</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Logarithm of factorial n!, integer variable</p></td></tr>
			   <tr><td><a href='../interface/log_gamma.html'>log_gamma</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Logarithm of gamma function</p></td></tr>
			   <tr><td><a href='../interface/log_lower_incomplete_gamma.html'>log_lower_incomplete_gamma</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Logarithm of lower incomplete gamma function</p></td></tr>
			   <tr><td><a href='../interface/log_upper_incomplete_gamma.html'>log_upper_incomplete_gamma</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Logarithm of upper incomplete gamma function</p></td></tr>
			   <tr><td><a href='../interface/logspace.html'>logspace</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Create rank 1 array of logarithmically spaced elements from base<strong>start to base</strong>end.
 If the number of elements is not specified, create an array with size 50. If n is a negative value,
 return an array with size 0. If n = 1, return an array whose only element is base**end. If no base
 is specified, logspace will default to using a base of 10</p><a href="../interface/logspace.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/lower_incomplete_gamma.html'>lower_incomplete_gamma</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Lower incomplete gamma function</p></td></tr>
			   <tr><td><a href='../interface/mean.html'>mean</a></td><td><a href='../module/stdlib_stats.html'>stdlib_stats</a></td><td>Interface</td><td><p>Mean of array elements
(<a href="../page/specs/stdlib_stats.html#mean-mean-of-array-elements">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/median.html'>median</a></td><td><a href='../module/stdlib_stats.html'>stdlib_stats</a></td><td>Interface</td><td><p>Median of array elements
(<a href="../page/specs/stdlib_stats.html#median-median-of-array-elements">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/meshgrid.html'>meshgrid</a></td><td><a href='../module/stdlib_math.html'>stdlib_math</a></td><td>Interface</td><td><p>Computes a list of coordinate matrices from coordinate vectors.
(<a href="../page/specs/stdlib_math.html#meshgrid">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/moment.html'>moment</a></td><td><a href='../module/stdlib_stats.html'>stdlib_stats</a></td><td>Interface</td><td><p>Central moment of array elements
(<a href="../page/specs/stdlib_stats.html#moment-central-moments-of-array-elements">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/move.html'>move</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Moves the allocated character scalar from 'from' to 'to'
<a href="../page/specs/stdlib_string_type.html#move">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/new_nmhash32_seed.html'>new_nmhash32_seed</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>(<a href="../page/specs/stdlib_hash_procedures.html#new_nmhash32_seed-returns-a-valid-input-seed-for-nmhash32">Specification</a></p></td></tr>
			   <tr><td><a href='../interface/new_nmhash32x_seed.html'>new_nmhash32x_seed</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>(<a href="../page/specs/stdlib_hash_procedures.html#new_nmhash32x_seed-returns-a-valid-input-seed-for-nmhash32x">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/new_pengy_hash_seed.html'>new_pengy_hash_seed</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/new_spooky_hash_seed.html'>new_spooky_hash_seed</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/new_water_hash_seed.html'>new_water_hash_seed</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>(<a href="file:///home/jvandenp/stdlib/API-doc/page/specs/stdlib_hash_procedures.html#new_water_hash_seed-returns-a-valid-input-seed-for-water_hash">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/nmhash32.html'>nmhash32</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>NMHASH32 interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#nmhash32-calculates-a-hash-code-from-a-key-and-a-seed">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/nmhash32x.html'>nmhash32x</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>NMHASH32X interfaces
(<a href="file:///home/jvandenp/stdlib/API-doc/page/specs/stdlib_hash_procedures.html#nmhash32x-calculates-a-hash-code-from-a-key-and-a-seed">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/nrm2.html'>nrm2</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>!</p><a href="../interface/nrm2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/odd_random_integer.html'>odd_random_integer</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Subroutine</td><td><p>Returns a 64 bit pseudo random integer, <code>harvest</code>, distributed uniformly over
the odd integers of the 64 bit kind.
(<a href="../page/specs/stdlib_hash_procedures.html#odd_random_integer-returns-odd-integer">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/odd_random_integer~2.html'>odd_random_integer</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Subroutine</td><td><p>Returns a 32 bit pseudo random integer, <code>harvest</code>, distributed uniformly over
the odd integers of the <code>int32</code> kind.
(<a href="../page/specs/stdlib_hash_procedures.html#odd_random_integer-returns-an-odd-integer">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/open.html'>open</a></td><td><a href='../module/stdlib_io.html'>stdlib_io</a></td><td>Function</td><td><p>Opens a file
 (<a href="../page/specs/stdlib_io.html#description_1">Specification</a>)</p><a href="../proc/open.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28%2B%29.html'>operator(+)</a></td><td><a href='../module/stdlib_ansi.html'>stdlib_ansi</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/operator%28SLASHSLASH%29.html'>operator(//)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Concatenate two character sequences, the left-hand side, the right-hand side
or both character sequences can be represented by a string.</p><a href="../interface/operator%28SLASHSLASH%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28SLASHSLASH%29~2.html'>operator(//)</a></td><td><a href='../module/stdlib_stringlist_type.html'>stdlib_stringlist_type</a></td><td>Interface</td><td><p>Concatenates stringlist with the input entity
Returns a new stringlist
<a href="../page/specs/stdlib_stringlist_type.html#append-operator">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/operator%28SLASHSLASH%29~3.html'>operator(//)</a></td><td><a href='../module/stdlib_ansi.html'>stdlib_ansi</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/operator%28SLASH%3D%29.html'>operator(/=)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Compare two character sequences for inequality, the left-hand side,
the right-hand side or both character sequences can be represented by
a string.</p><a href="../interface/operator%28SLASH%3D%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28SLASH%3D%29~2.html'>operator(/=)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Returns <code>.true.</code> if not all bits in <code>set1</code> and <code>set2</code> have the same value,
 <code>.false.</code>  otherwise. The sets must have the same number of bits
 otherwise the result is undefined.
(<a href="../page/specs/stdlib_bitsets.html#-compare-two-bitsets-to-determine-whether-any-bits-differ-in-value">Specification</a>)</p><a href="../interface/operator%28SLASH%3D%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28SLASH%3D%29~3.html'>operator(/=)</a></td><td><a href='../module/stdlib_stringlist_type.html'>stdlib_stringlist_type</a></td><td>Interface</td><td><p>Compares stringlist for inequality with the input entity
Returns a logical
<a href="../page/specs/stdlib_stringlist_type.html#inequality-operator">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/operator%28lt%29.html'>operator(<)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Compare two character sequences for being less, the left-hand side,
the right-hand side or both character sequences can be represented by
a string.</p><a href="../interface/operator%28lt%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28lt%29~2.html'>operator(<)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Returns <code>.true.</code> if the bits in <code>set1</code> and <code>set2</code> differ and the
 highest order different bit is set to 0 in <code>set1</code> and to 1 in <code>set2</code>,
 <code>.false.</code>  otherwise. The sets must have the same number of bits
 otherwise the result is undefined.
(<a href="../page/specs/stdlib_bitsets.html#lt-compare-two-bitsets-to-determine-whether-the-first-is-less-than-the-other">Specification</a>)</p><a href="../interface/operator%28lt%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28lt%3D%29.html'>operator(<=)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Compare two character sequences for being less than, the left-hand side,
the right-hand side or both character sequences can be represented by
a string.</p><a href="../interface/operator%28lt%3D%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28lt%3D%29~2.html'>operator(<=)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Returns <code>.true.</code> if the bits in <code>set1</code> and <code>set2</code> are the same or the
 highest order different bit is set to 0 in <code>set1</code> and to 1 in <code>set2</code>,
 <code>.false.</code>  otherwise. The sets must have the same number of bits
 otherwise the result is undefined.
(<a href="../page/specs/stdlib_bitsets.html#lt-compare-two-bitsets-to-determine-whether-the-first-is-less-than-or-equal-to-the-other">Specification</a>)</p><a href="../interface/operator%28lt%3D%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28%3D%3D%29.html'>operator(==)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Compare two character sequences for equality, the left-hand side,
the right-hand side or both character sequences can be represented by
a string.</p><a href="../interface/operator%28%3D%3D%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28%3D%3D%29~2.html'>operator(==)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Returns <code>.true.</code> if all bits in <code>set1</code> and <code>set2</code> have the same value,
 <code>.false.</code>  otherwise. The sets must have the same number of bits
 otherwise the result is undefined.
(<a href="../page/specs/stdlib_bitsets.html#-compare-two-bitsets-to-determine-whether-the-bits-have-the-same-value">Specification</a>)</p><a href="../interface/operator%28%3D%3D%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28%3D%3D%29~3.html'>operator(==)</a></td><td><a href='../module/stdlib_stringlist_type.html'>stdlib_stringlist_type</a></td><td>Interface</td><td><p>Compares stringlist for equality with the input entity
Returns a logical
<a href="../page/specs/stdlib_stringlist_type.html#equality-operator">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/operator%28%3D%3D%29~4.html'>operator(==)</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/operator%28gt%29.html'>operator(>)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Compare two character sequences for being greater, the left-hand side,
the right-hand side or both character sequences can be represented by
a string.</p><a href="../interface/operator%28gt%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28gt%29~2.html'>operator(>)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Returns <code>.true.</code> if the bits in <code>set1</code> and <code>set2</code> differ and the
 highest order different bit is set to 1 in <code>set1</code> and to 0 in <code>set2</code>,
 <code>.false.</code>  otherwise. The sets must have the same number of bits
 otherwise the result is undefined.
(<a href="../page/specs/stdlib_bitsets.html#gt-compare-two-bitsets-to-determine-whether-the-first-is-greater-than-the-other">Specification</a>)</p><a href="../interface/operator%28gt%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28gt%3D%29.html'>operator(>=)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Compare two character sequences for being greater than, the left-hand side,
the right-hand side or both character sequences can be represented by
a string.</p><a href="../interface/operator%28gt%3D%29.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/operator%28gt%3D%29~2.html'>operator(>=)</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Returns <code>.true.</code> if the bits in <code>set1</code> and <code>set2</code> are the same or the
 highest order different bit is set to 1 in <code>set1</code> and to 0 in <code>set2</code>,
 <code>.false.</code>  otherwise. The sets must have the same number of bits
 otherwise the result is undefined.
 (<a href="../page/specs/stdlib_bitsets.html#gt-compare-two-bitsets-to-determine-whether-the-first-is-greater-than-or-equal-to-the-second">Specification</a>)</p><a href="../interface/operator%28gt%3D%29~2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/opgtr.html'>opgtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>product of n-1 elementary reflectors H(i) of order n, as returned by
DSPTRD using packed storage:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../interface/opmtr.html'>opmtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by DSPTRD using packed
storage:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/optval.html'>optval</a></td><td><a href='../module/stdlib_optval.html'>stdlib_optval</a></td><td>Interface</td><td><p>Fallback value for optional arguments
(<a href="../page/specs/stdlib_optval.html#description">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/or.html'>or</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Sets the bits in <code>set1</code> to the bitwise <code>or</code> of the original bits in <code>set1</code>
 and <code>set2</code>. The sets must have the same number of bits otherwise
 the result is undefined.
 (<a href="../page/specs/stdlib_bitsets.html#or-bitwise-or-of-the-bits-of-two-bitsets">Specification</a>)</p><a href="../interface/or.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/orbdb.html'>orbdb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>partitioned orthogonal matrix X:
[ B11 | B12 0  0 ]
[ X11 | X12 ]   [ P1 |    ] [  0  |  0 -I  0 ] [ Q1 |    ]**T
X = [-----------] = [---------] [----------------] [---------]   .
[ X21 | X22 ]   [    | P2 ] [ B21 | B22 0  0 ] [    | Q2 ]
[  0  |  0  0  I ]
X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is
not the case, then X must be transposed and/or permuted. This can be
done in constant time using the TRANS and SIGNS options. See DORCSD
for details.)
The orthogonal matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by-
(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are
represented implicitly by Householder vectors.
B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/orbdb1.html'>orbdb1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P,
M-P, or M-Q. Routines DORBDB2, DORBDB3, and DORBDB4 handle cases in
which Q is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/orbdb2.html'>orbdb2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P,
Q, or M-Q. Routines DORBDB1, DORBDB3, and DORBDB4 handle cases in
which P is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are P-by-P bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/orbdb3.html'>orbdb3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P,
Q, or M-Q. Routines DORBDB1, DORBDB2, and DORBDB4 handle cases in
which M-P is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/orbdb4.html'>orbdb4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P,
M-P, or Q. Routines DORBDB1, DORBDB2, and DORBDB3 handle cases in
which M-Q is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/orbdb5.html'>orbdb5</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then some other vector from the orthogonal complement
is returned. This vector is chosen in an arbitrary but deterministic
way.</p></td></tr>
			   <tr><td><a href='../interface/orbdb6.html'>orbdb6</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then the zero vector is returned.</p></td></tr>
			   <tr><td><a href='../interface/orcsd.html'>orcsd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>orthogonal matrix X:
[  I  0  0 |  0  0  0 ]
[  0  C  0 |  0 -S  0 ]
[ X11 | X12 ]   [ U1 |    ] [  0  0  0 |  0  0 -I ] [ V1 |    ]**T
X = [-----------] = [---------] [---------------------] [---------]   .
[ X21 | X22 ]   [    | U2 ] [  0  0  0 |  I  0  0 ] [    | V2 ]
[  0  S  0 |  0  C  0 ]
[  0  0  I |  0  0  0 ]
X11 is P-by-Q. The orthogonal matrices U1, U2, V1, and V2 are P-by-P,
(M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are
R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in
which R = MIN(P,M-P,Q,M-Q).</p></td></tr>
			   <tr><td><a href='../interface/orcsd2by1.html'>orcsd2by1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>orthonormal columns that has been partitioned into a 2-by-1 block
structure:
[  I1 0  0 ]
[  0  C  0 ]
[ X11 ]   [ U1 |    ] [  0  0  0 ]
X = [-----] = [---------] [----------] V1**T .
[ X21 ]   [    | U2 ] [  0  0  0 ]
[  0  S  0 ]
[  0  0  I2]
X11 is P-by-Q. The orthogonal matrices U1, U2, and V1 are P-by-P,
(M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R
nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which
R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a
K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0).</p></td></tr>
			   <tr><td><a href='../interface/ord_sort.html'>ord_sort</a></td><td><a href='../module/stdlib_sorting.html'>stdlib_sorting</a></td><td>Interface</td><td><p>The generic subroutine interface implementing the <code>ORD_SORT</code> algorithm,
a translation to Fortran 2008, of the <code>"Rust" sort</code> algorithm found in
<code>slice.rs</code>
https://github.com/rust-lang/rust/blob/90eb44a5897c39e3dff9c7e48e3973671dcd9496/src/liballoc/slice.rs#L2159
<code>ORD_SORT</code> is a hybrid stable comparison algorithm combining <code>merge sort</code>,
and <code>insertion sort</code>.
(<a href="../page/specs/stdlib_sorting.html#ord_sort-sorts-an-input-array">Specification</a>)</p><a href="../interface/ord_sort.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/org2l.html'>org2l</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the last n columns of a product of k elementary
reflectors of order m
Q  =  H(k) . . . H(2) H(1)
as returned by DGEQLF.</p></td></tr>
			   <tr><td><a href='../interface/org2r.html'>org2r</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the first n columns of a product of k elementary
reflectors of order m
Q  =  H(1) H(2) . . . H(k)
as returned by DGEQRF.</p></td></tr>
			   <tr><td><a href='../interface/orgbr.html'>orgbr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>determined by DGEBRD when reducing a real matrix A to bidiagonal
form: A = Q * B * P<strong>T.  Q and P</strong>T are defined as products of
elementary reflectors H(i) or G(i) respectively.
If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q
is of order M:
if m &gt;= k, Q = H(1) H(2) . . . H(k) and ORGBR returns the first n
columns of Q, where m &gt;= n &gt;= k;
if m &lt; k, Q = H(1) H(2) . . . H(m-1) and ORGBR returns Q as an
M-by-M matrix.
If VECT = 'P', A is assumed to have been a K-by-N matrix, and P<strong>T
is of order N:
if k &lt; n, P</strong>T = G(k) . . . G(2) G(1) and ORGBR returns the first m
rows of P<strong>T, where n &gt;= m &gt;= k;
if k &gt;= n, P</strong>T = G(n-1) . . . G(2) G(1) and ORGBR returns P**T as
an N-by-N matrix.</p></td></tr>
			   <tr><td><a href='../interface/orghr.html'>orghr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>product of IHI-ILO elementary reflectors of order N, as returned by
DGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../interface/orglq.html'>orglq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the first M rows of a product of K elementary
reflectors of order N
Q  =  H(k) . . . H(2) H(1)
as returned by DGELQF.</p></td></tr>
			   <tr><td><a href='../interface/orgql.html'>orgql</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the last N columns of a product of K elementary
reflectors of order M
Q  =  H(k) . . . H(2) H(1)
as returned by DGEQLF.</p></td></tr>
			   <tr><td><a href='../interface/orgqr.html'>orgqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the first N columns of a product of K elementary
reflectors of order M
Q  =  H(1) H(2) . . . H(k)
as returned by DGEQRF.</p></td></tr>
			   <tr><td><a href='../interface/orgrq.html'>orgrq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the last M rows of a product of K elementary
reflectors of order N
Q  =  H(1) H(2) . . . H(k)
as returned by DGERQF.</p></td></tr>
			   <tr><td><a href='../interface/orgtr.html'>orgtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>product of n-1 elementary reflectors of order N, as returned by
DSYTRD:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../interface/orgtsqr.html'>orgtsqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which are the first N columns of a product of real orthogonal
matrices of order M which are returned by DLATSQR
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
See the documentation for DLATSQR.</p></td></tr>
			   <tr><td><a href='../interface/orgtsqr_row.html'>orgtsqr_row</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>orthonormal columns from the output of DLATSQR. These N orthonormal
columns are the first N columns of a product of complex unitary
matrices Q(k)_in of order M, which are returned by DLATSQR in
a special format.
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
The input matrices Q(k)_in are stored in row and column blocks in A.
See the documentation of DLATSQR for more details on the format of
Q(k)_in, where each Q(k)_in is represented by block Householder
transformations. This routine calls an auxiliary routine DLARFB_GETT,
where the computation is performed on each individual block. The
algorithm first sweeps NB-sized column blocks from the right to left
starting in the bottom row block and continues to the top row block
(hence _ROW in the routine name). This sweep is in reverse order of
the order in which DLATSQR generates the output blocks.</p></td></tr>
			   <tr><td><a href='../interface/orhr_col.html'>orhr_col</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>as input, stored in A, and performs Householder Reconstruction (HR),
i.e. reconstructs Householder vectors V(i) implicitly representing
another M-by-N matrix Q_out, with the property that Q_in = Q_out*S,
where S is an N-by-N diagonal matrix with diagonal entries
equal to +1 or -1. The Householder vectors (columns V(i) of V) are
stored in A on output, and the diagonal entries of S are stored in D.
Block reflectors are also returned in T
(same output format as DGEQRT).</p></td></tr>
			   <tr><td><a href='../interface/orm2l.html'>orm2l</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T * C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGEQLF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/orm2r.html'>orm2r</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGEQRF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/ormbr.html'>ormbr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>If VECT = 'Q', ORMBR: overwrites the general real M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
If VECT = 'P', ORMBR overwrites the general real M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      P * C          C * P
TRANS = 'T':      P<strong>T * C       C * P</strong>T
Here Q and P<strong>T are the orthogonal matrices determined by DGEBRD when
reducing a real matrix A to bidiagonal form: A = Q * B * P</strong>T. Q and
P<strong>T are defined as products of elementary reflectors H(i) and G(i)
respectively.
Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the
order of the orthogonal matrix Q or P</strong>T that is applied.
If VECT = 'Q', A is assumed to have been an NQ-by-K matrix:
if nq &gt;= k, Q = H(1) H(2) . . . H(k);
if nq &lt; k, Q = H(1) H(2) . . . H(nq-1).
If VECT = 'P', A is assumed to have been a K-by-NQ matrix:
if k &lt; nq, P = G(1) G(2) . . . G(k);
if k &gt;= nq, P = G(1) G(2) . . . G(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/ormhr.html'>ormhr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
IHI-ILO elementary reflectors, as returned by DGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../interface/ormlq.html'>ormlq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGELQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/ormql.html'>ormql</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGEQLF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/ormqr.html'>ormqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGEQRF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/ormrq.html'>ormrq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGERQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/ormrz.html'>ormrz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DTZRZF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/ormtr.html'>ormtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by DSYTRD:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/outer_product.html'>outer_product</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Computes the outer product of two vectors, returning a rank-2 array
(<a href="../page/specs/stdlib_linalg.html#
outer_product-computes-the-outer-product-of-two-vectors">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/padl.html'>padl</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Left pad the input string
<a href="../page/specs/stdlib_strings.html#padl">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/padr.html'>padr</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Right pad the input string
<a href="../page/specs/stdlib_strings.html#padr">Specifications</a></p></td></tr>
			   <tr><td><a href='../proc/parse_mode.html'>parse_mode</a></td><td><a href='../module/stdlib_io.html'>stdlib_io</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../interface/pbcon.html'>pbcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex Hermitian positive definite band matrix using
the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by
CPBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/pbequ.html'>pbequ</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian positive definite band matrix A and reduce its condition
number (with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../interface/pbrfs.html'>pbrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and banded, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../interface/pbstf.html'>pbstf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian positive definite band matrix A.
This routine is designed to be used in conjunction with CHBGST.
The factorization has the form  A = S*<em>H</em>S  where S is a band matrix
of the same bandwidth as A and the following structure:
S = ( U    )
( M  L )
where U is upper triangular of order m = (n+kd)/2, and L is lower
triangular of order n-m.</p></td></tr>
			   <tr><td><a href='../interface/pbsv.html'>pbsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite band matrix and X
and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H * U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular band matrix, and L is a lower
triangular band matrix, with the same number of superdiagonals or
subdiagonals as A.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/pbtrf.html'>pbtrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../interface/pbtrs.html'>pbtrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite band matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPBTRF.</p></td></tr>
			   <tr><td><a href='../interface/pdf_exp.html'>pdf_exp</a></td><td><a href='../module/stdlib_stats_distribution_exponential.html'>stdlib_stats_distribution_exponential</a></td><td>Interface</td><td><p>Version experimental</p><a href="../interface/pdf_exp.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/pdf_normal.html'>pdf_normal</a></td><td><a href='../module/stdlib_stats_distribution_normal.html'>stdlib_stats_distribution_normal</a></td><td>Interface</td><td><p>Normal Distribution Probability Density Function
(<a href="../page/specs/stdlib_stats_distribution_normal.html#
pdf_normal-normal-distribution-probability-density-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/pdf_uniform.html'>pdf_uniform</a></td><td><a href='../module/stdlib_stats_distribution_uniform.html'>stdlib_stats_distribution_uniform</a></td><td>Interface</td><td><p>Get uniform distribution probability density (pdf) for integer, real and
complex variables.
(<a href="../page/specs/stdlib_stats_distribution_uniform.html#
pdf_uniform-uniform-probability-density-function">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/pengy_hash.html'>pengy_hash</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td><p>PENGY_HASH interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#pengy_hash-maps-a-character-string-or-integer-vector-to-an-integer">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/pftrf.html'>pftrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/pftri.html'>pftri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by CPFTRF.</p></td></tr>
			   <tr><td><a href='../interface/pftrs.html'>pftrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPFTRF.</p></td></tr>
			   <tr><td><a href='../interface/pocon.html'>pocon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex Hermitian positive definite matrix using the
Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPOTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/poequ.html'>poequ</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../interface/poequb.html'>poequb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.
This routine differs from CPOEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled diagonal entries are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../interface/porfs.html'>porfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is Hermitian positive definite,
and provides error bounds and backward error estimates for the
solution.</p></td></tr>
			   <tr><td><a href='../interface/posv.html'>posv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix and X and B
are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H* U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and  L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/potrf.html'>potrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/potrf2.html'>potrf2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A using the recursive algorithm.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = n/2
[  A21 | A22  ]       n2 = n-n1
The subroutine calls itself to factor A11. Update and scale A21
or A12, update A22 then calls itself to factor A22.</p></td></tr>
			   <tr><td><a href='../interface/potri.html'>potri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by CPOTRF.</p></td></tr>
			   <tr><td><a href='../interface/potrs.html'>potrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPOTRF.</p></td></tr>
			   <tr><td><a href='../interface/ppcon.html'>ppcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex Hermitian positive definite packed matrix using
the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by
CPPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/ppequ.html'>ppequ</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Hermitian positive definite matrix A in packed storage and reduce
its condition number (with respect to the two-norm).  S contains the
scale factors, S(i)=1/sqrt(A(i,i)), chosen so that the scaled matrix
B with elements B(i,j)=S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.
This choice of S puts the condition number of B within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../interface/pprfs.html'>pprfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../interface/ppsv.html'>ppsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H * U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/pptrf.html'>pptrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A stored in packed format.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../interface/pptri.html'>pptri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by CPPTRF.</p></td></tr>
			   <tr><td><a href='../interface/pptrs.html'>pptrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite matrix A in packed storage using the Cholesky
factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPPTRF.</p></td></tr>
			   <tr><td><a href='../interface/pstrf.html'>pstrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>pivoting of a complex Hermitian positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>H * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/ptcon.html'>ptcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex Hermitian positive definite tridiagonal matrix
using the factorization A = L<em>D</em>L<strong>H or A = U</strong>H<em>D</em>U computed by
CPTTRF.
Norm(inv(A)) is computed by a direct method, and the reciprocal of
the condition number is computed as
RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/pteqr.html'>pteqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric positive definite tridiagonal matrix by first factoring the
matrix using SPTTRF and then calling CBDSQR to compute the singular
values of the bidiagonal factor.
This routine computes the eigenvalues of the positive definite
tridiagonal matrix to high relative accuracy.  This means that if the
eigenvalues range over many orders of magnitude in size, then the
small eigenvalues and corresponding eigenvectors will be computed
more accurately than, for example, with the standard QR method.
The eigenvectors of a full or band positive definite Hermitian matrix
can also be found if CHETRD, CHPTRD, or CHBTRD has been used to
reduce this matrix to tridiagonal form.  (The reduction to
tridiagonal form, however, may preclude the possibility of obtaining
high relative accuracy in the small eigenvalues of the original
matrix, if these eigenvalues range over many orders of magnitude.)</p></td></tr>
			   <tr><td><a href='../interface/ptrfs.html'>ptrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and tridiagonal, and provides error bounds and backward error
estimates for the solution.</p></td></tr>
			   <tr><td><a href='../interface/ptsv.html'>ptsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A<em>X = B, where A is an N-by-N Hermitian positive definite tridiagonal
matrix, and X and B are N-by-NRHS matrices.
A is factored as A = L</em>D<em>L</em>*H, and the factored form of A is then
used to solve the system of equations.</p></td></tr>
			   <tr><td><a href='../interface/pttrf.html'>pttrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>positive definite tridiagonal matrix A.  The factorization may also
be regarded as having the form A = U<em><em>H </em>D</em>U.</p></td></tr>
			   <tr><td><a href='../interface/pttrs.html'>pttrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B
using the factorization A = U<strong>H<em>D</em>U or A = L<em>D</em>L</strong>H computed by CPTTRF.
D is a diagonal matrix specified in the vector D, U (or L) is a unit
bidiagonal matrix whose superdiagonal (subdiagonal) is specified in
the vector E, and X and B are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../interface/radix_sort.html'>radix_sort</a></td><td><a href='../module/stdlib_sorting.html'>stdlib_sorting</a></td><td>Interface</td><td><p>The generic subroutine interface implementing the LSD radix sort algorithm,
see https://en.wikipedia.org/wiki/Radix_sort for more details.
It is always O(N) in sorting random data, but need a O(N) buffer.
(<a href="../page/specs/stdlib_sorting.html#radix_sort-sorts-an-input-array">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/random_seed.html'>random_seed</a></td><td><a href='../module/stdlib_random.html'>stdlib_random</a></td><td>Interface</td><td><p>Version experimental</p><a href="../interface/random_seed.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/read%28formatted%29.html'>read(formatted)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Read a character sequence from a connected unformatted unit into the string.</p></td></tr>
			   <tr><td><a href='../interface/read%28unformatted%29.html'>read(unformatted)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Read a character sequence from a connected unformatted unit into the string.</p></td></tr>
			   <tr><td><a href='../interface/regularized_gamma_p.html'>regularized_gamma_p</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Regularized (normalized) lower incomplete gamma function, P</p></td></tr>
			   <tr><td><a href='../interface/regularized_gamma_q.html'>regularized_gamma_q</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Regularized (normalized) upper incomplete gamma function, Q</p></td></tr>
			   <tr><td><a href='../interface/repeat.html'>repeat</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Repeats the character sequence hold by the string by the number of
specified copies.</p><a href="../interface/repeat.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/replace_all.html'>replace_all</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Replaces all the occurrences of substring 'pattern' in the input 'string'
with the replacement 'replacement'
Version: experimental</p></td></tr>
			   <tr><td><a href='../interface/reverse.html'>reverse</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Reverses the character sequence hold by the input string</p><a href="../interface/reverse.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/reverse.html'>reverse</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Reverse the character order in the input character variable
(<a href="../page/specs/stdlib_ascii.html#reverse">Specification</a>)</p><a href="../proc/reverse.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/rot.html'>rot</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>ROT: applies a plane rotation.</p></td></tr>
			   <tr><td><a href='../interface/rot~2.html'>rot</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>sin (S) is complex, and the vectors CX and CY are complex.</p></td></tr>
			   <tr><td><a href='../interface/rotg.html'>rotg</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>!</p><a href="../interface/rotg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/rotm.html'>rotm</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>APPLY THE MODIFIED GIVENS TRANSFORMATION, H, TO THE 2 BY N MATRIX
(DX<strong>T) , WHERE </strong>T INDICATES TRANSPOSE. THE ELEMENTS OF DX ARE IN
(DY<em><em>T)
DX(LX+I</em>INCX), I = 0 TO N-1, WHERE LX = 1 IF INCX &gt;= 0, ELSE
LX = (-INCX)</em>N, AND SIMILARLY FOR SY USING LY AND INCY.
WITH DPARAM(1)=DFLAG, H HAS ONE OF THE FOLLOWING FORMS..
DFLAG=-1._dp     DFLAG=0._dp        DFLAG=1._dp     DFLAG=-2.D0
(DH11  DH12)    (1._dp  DH12)    (DH11  1._dp)    (1._dp  0._dp)
H=(          )    (          )    (          )    (          )
(DH21  DH22),   (DH21  1._dp),   (-1._dp DH22),   (0._dp  1._dp).
SEE ROTMG FOR A DESCRIPTION OF DATA STORAGE IN DPARAM.</p></td></tr>
			   <tr><td><a href='../interface/rotmg.html'>rotmg</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>CONSTRUCT THE MODIFIED GIVENS TRANSFORMATION MATRIX H WHICH ZEROS
THE SECOND COMPONENT OF THE 2-VECTOR  (SQRT(DD1)<em>DX1,SQRT(DD2)    DY2)</em>*T.
WITH DPARAM(1)=DFLAG, H HAS ONE OF THE FOLLOWING FORMS..
DFLAG=-1._dp     DFLAG=0._dp        DFLAG=1._dp     DFLAG=-2.D0
(DH11  DH12)    (1._dp  DH12)    (DH11  1._dp)    (1._dp  0._dp)
H=(          )    (          )    (          )    (          )
(DH21  DH22),   (DH21  1._dp),   (-1._dp DH22),   (0._dp  1._dp).
LOCATIONS 2-4 OF DPARAM CONTAIN DH11, DH21, DH12, AND DH22
RESPECTIVELY. (VALUES OF 1._dp, -1._dp, OR 0._dp IMPLIED BY THE
VALUE OF DPARAM(1) ARE NOT STORED IN DPARAM.)
THE VALUES OF GAMSQ AND RGAMSQ SET IN THE DATA STATEMENT MAY BE
INEXACT.  THIS IS OK AS THEY ARE ONLY USED FOR TESTING THE SIZE
OF DD1 AND DD2.  ALL ACTUAL SCALING OF DATA IS DONE USING GAM.</p></td></tr>
			   <tr><td><a href='../interface/rscl.html'>rscl</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>This is done without overflow or underflow as long as
the final result x/a does not overflow or underflow.</p></td></tr>
			   <tr><td><a href='../interface/rvs_exp.html'>rvs_exp</a></td><td><a href='../module/stdlib_stats_distribution_exponential.html'>stdlib_stats_distribution_exponential</a></td><td>Interface</td><td><p>Version experimental</p><a href="../interface/rvs_exp.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/rvs_normal.html'>rvs_normal</a></td><td><a href='../module/stdlib_stats_distribution_normal.html'>stdlib_stats_distribution_normal</a></td><td>Interface</td><td><p>Normal Distribution Random Variates
(<a href="../page/specs/stdlib_stats_distribution_normal.html#
rvs_normal-normal-distribution-random-variates">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/rvs_uniform.html'>rvs_uniform</a></td><td><a href='../module/stdlib_stats_distribution_uniform.html'>stdlib_stats_distribution_uniform</a></td><td>Interface</td><td><p>Get uniformly distributed random variate for integer, real and complex
variables.
(<a href="../page/specs/stdlib_stats_distribution_uniform.html#
rvs_uniform-uniform-distribution-random-variates">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/save_npy.html'>save_npy</a></td><td><a href='../module/stdlib_io_npy.html'>stdlib_io_npy</a></td><td>Interface</td><td><p>Save multidimensional array in npy format
(<a href="../page/specs/stdlib_io.html#save_npy">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/savetxt.html'>savetxt</a></td><td><a href='../module/stdlib_io.html'>stdlib_io</a></td><td>Interface</td><td><p>Saves a 2D array into a text file
(<a href="../page/specs/stdlib_io.html#description_2">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/sb2st_kernels.html'>sb2st_kernels</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>subroutine.</p></td></tr>
			   <tr><td><a href='../interface/sbev.html'>sbev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a real symmetric band matrix A.</p></td></tr>
			   <tr><td><a href='../interface/sbevd.html'>sbevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a real symmetric band matrix A. If eigenvectors are desired, it uses
a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/sbgst.html'>sbgst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenproblem  A<em>x = lambda</em>B<em>x  to standard form  C</em>y = lambda<em>y,
such that C has the same bandwidth as A.
B must have been previously factorized as S</em><em>T</em>S by DPBSTF, using a
split Cholesky factorization. A is overwritten by C = X<strong>T<em>A</em>X, where
X = S</strong>(-1)*Q and Q is an orthogonal matrix chosen to preserve the
bandwidth of A.</p></td></tr>
			   <tr><td><a href='../interface/sbgv.html'>sbgv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be symmetric
and banded, and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../interface/sbgvd.html'>sbgvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of the
form A<em>x=(lambda)</em>B*x.  Here A and B are assumed to be symmetric and
banded, and B is also positive definite.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/sbmv.html'>sbmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric band matrix, with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../interface/sbtrd.html'>sbtrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal form T by an orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/scal.html'>scal</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>SCAL: scales a vector by a constant.</p></td></tr>
			   <tr><td><a href='../interface/scan.html'>scan</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Scan a <em>string</em> for the presence of a <em>set</em> of characters. Scans a <em>string</em> for
any of the characters in a <em>set</em> of characters.</p><a href="../interface/scan.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/sdot.html'>sdot</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>Compute the inner product of two vectors with extended
precision accumulation and result.
Returns D.P. dot product accumulated in D.P., for S.P. SX and SY
SDOT: = sum for I = 0 to N-1 of  SX(LX+I<em>INCX) * SY(LY+I</em>INCY),
where LX = 1 if INCX &gt;= 0, else LX = 1+(1-N)*INCX, and LY is
defined in a similar way using INCY.</p></td></tr>
			   <tr><td><a href='../proc/seeded_nmhash32_hasher.html'>seeded_nmhash32_hasher</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Function</td><td><p>Hashes a key with the NMHASH32 hash algorithm
(<a href="../page/specs/stdlib_hashmaps.html#seeded_nmhash32_hasher-calculates-a-hash-code-from-a-key">Specifications</a>)</p><a href="../proc/seeded_nmhash32_hasher.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/seeded_nmhash32x_hasher.html'>seeded_nmhash32x_hasher</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Function</td><td><p>Hashes a key with the NMHASH32X hash algorithm
(<a href="../page/specs/stdlib_hashmaps.html#seeded_nmhash32x_hasher-calculates-a-hash-code-from-a-key">Specifications</a>)
Arguments:
    key  - the key to be hashed
    seed - the seed (unused) for the hashing algorithm</p></td></tr>
			   <tr><td><a href='../proc/seeded_water_hasher.html'>seeded_water_hasher</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Function</td><td><p>Hashes a key with the waterhash algorithm
(<a href="../page/specs/stdlib_hashmaps.html#seeded_water_hasher-calculates-a-hash-code-from-a-key">Specifications</a>)</p><a href="../proc/seeded_water_hasher.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/select.html'>select</a></td><td><a href='../module/stdlib_selection.html'>stdlib_selection</a></td><td>Interface</td><td><p>(<a href="..//page/specs/stdlib_selection.html#select-find-the-k-th-smallest-value-in-an-input-array">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/set.html'>set</a></td><td><a href='../module/stdlib_hashmap_wrappers.html'>stdlib_hashmap_wrappers</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/sfrk.html'>sfrk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Level 3 BLAS like routine for C in RFP Format.
SFRK: performs one of the symmetric rank--k operations
C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where alpha and beta are real scalars, C is an n--by--n symmetric
matrix and A is an n--by--k matrix in the first case and a k--by--n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../interface/shuffle.html'>shuffle</a></td><td><a href='../module/stdlib_stats_distribution_uniform.html'>stdlib_stats_distribution_uniform</a></td><td>Interface</td><td><p>Fisher-Yates shuffle algorithm for a rank one array of integer, real and
complex variables.
(<a href="../page/specs/stdlib_stats_distribution_uniform.html#
shuffle-using-fisher-yates-algorithm-to-generate-a-random-permutation-of-a-list">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/simps.html'>simps</a></td><td><a href='../module/stdlib_quadrature.html'>stdlib_quadrature</a></td><td>Interface</td><td><p>Integrates sampled values using Simpson's rule
(<a href="../page/specs/stdlib_quadrature.html#description_3">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/simps_weights.html'>simps_weights</a></td><td><a href='../module/stdlib_quadrature.html'>stdlib_quadrature</a></td><td>Interface</td><td><p>Integrates sampled values using trapezoidal rule weights for given abscissas
(<a href="../page/specs/stdlib_quadrature.html#description_3">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/slice.html'>slice</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Extracts characters from the input string to return a new string</p><a href="../interface/slice.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/sort.html'>sort</a></td><td><a href='../module/stdlib_sorting.html'>stdlib_sorting</a></td><td>Interface</td><td><p>The generic subroutine interface implementing the <code>SORT</code> algorithm, based
on the <code>introsort</code> of David Musser.
(<a href="../page/specs/stdlib_sorting.html#sort-sorts-an-input-array">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/sort_index.html'>sort_index</a></td><td><a href='../module/stdlib_sorting.html'>stdlib_sorting</a></td><td>Interface</td><td><p>The generic subroutine interface implementing the <code>SORT_INDEX</code> algorithm,
based on the <code>"Rust" sort</code> algorithm found in <code>slice.rs</code>
https://github.com/rust-lang/rust/blob/90eb44a5897c39e3dff9c7e48e3973671dcd9496/src/liballoc/slice.rs#L2159
but modified to return an array of indices that would provide a stable
sort of the rank one <code>ARRAY</code> input.
(<a href="../page/specs/stdlib_sorting.html#sort_index-creates-an-array-of-sorting-indices-for-an-input-array-while-also-sorting-the-array">Specification</a>)</p><a href="../interface/sort_index.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/spcon.html'>spcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex symmetric packed matrix A using the
factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/spev.html'>spev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>real symmetric matrix A in packed storage.</p></td></tr>
			   <tr><td><a href='../interface/spevd.html'>spevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real symmetric matrix A in packed storage. If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/spgst.html'>spgst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to standard form, using packed storage.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T</em>A<em>L.
B must have been previously factorized as U</em><em>T</em>U or L<em>L</em>*T by DPPTRF.</p></td></tr>
			   <tr><td><a href='../interface/spgv.html'>spgv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be symmetric, stored in packed format,
and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../interface/spgvd.html'>spgvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be symmetric, stored in packed format, and B is also
positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/spmv.html'>spmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/spmv~2.html'>spmv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/spooky_hash.html'>spooky_hash</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td><p>SPOOKY_HASH interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#spooky_hash-maps-a-character-string-or-integer-vector-to-an-integer">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/spookyhash_128.html'>spookyHash_128</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/spr.html'>spr</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>x**T + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/spr~2.html'>spr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a complex scalar, x is an n element vector and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/spr2.html'>spr2</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y<strong>T + alpha<em>y</em>x</strong>T + A,
where alpha is a scalar, x and y are n element vectors and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/sprfs.html'>sprfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is symmetric indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../interface/spsv.html'>spsv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is symmetric and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/sptrd.html'>sptrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric tridiagonal form T by an orthogonal similarity
transformation: Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/sptrf.html'>sptrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>stored in packed format using the Bunch-Kaufman diagonal pivoting
method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../interface/sptri.html'>sptri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSPTRF.</p></td></tr>
			   <tr><td><a href='../interface/sptrs.html'>sptrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSPTRF.</p></td></tr>
			   <tr><td><a href='../interface/srot.html'>srot</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>and the vectors cx and cy are complex.
jack dongarra, linpack, 3/11/78.</p></td></tr>
			   <tr><td><a href='../interface/sscal.html'>sscal</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>SSCAL: scales a complex vector by a real constant.</p></td></tr>
			   <tr><td><a href='../interface/starts_with.html'>starts_with</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Check whether a string starts with substring or not</p><a href="../interface/starts_with.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_caxpy.html'>stdlib_caxpy</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_cbbcsd.html'>stdlib_cbbcsd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>bidiagonal-block form,
[ B11 | B12 0  0 ]
[  0  |  0 -I  0 ]
X = [----------------]
[ B21 | B22 0  0 ]
[  0  |  0  0  I ]
[  C | -S  0  0 ]
[ U1 |    ] [  0 |  0 -I  0 ] [ V1 |    ]**H
= [---------] [---------------] [---------]   .
[    | U2 ] [  S |  C  0  0 ] [    | V2 ]
[  0 |  0  0  I ]
X is M-by-M, its top-left block is P-by-Q, and Q must be no larger
than P, M-P, or M-Q. (If Q is not the smallest index, then X must be
transposed and/or permuted. This can be done in constant time using
the TRANS and SIGNS options. See CUNCSD for details.)
The bidiagonal matrices B11, B12, B21, and B22 are represented
implicitly by angles THETA(1:Q) and PHI(1:Q-1).
The unitary matrices U1, U2, V1T, and V2T are input/output.
The input matrices are pre- or post-multiplied by the appropriate
singular vector matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cbdsqr.html'>stdlib_cbdsqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>left singular vectors from the singular value decomposition (SVD) of
a real N-by-N (upper or lower) bidiagonal matrix B using the implicit
zero-shift QR algorithm.  The SVD of B has the form
B = Q * S * P<strong>H
where S is the diagonal matrix of singular values, Q is an orthogonal
matrix of left singular vectors, and P is an orthogonal matrix of
right singular vectors.  If left singular vectors are requested, this
subroutine actually returns U*Q instead of Q, and, if right singular
vectors are requested, this subroutine returns P</strong>H<em>VT instead of
P</em><em>H, for given complex input matrices U and VT.  When U and VT are
the unitary matrices that reduce a general matrix A to bidiagonal
form: A = U</em>B<em>VT, as computed by CGEBRD, then
A = (U</em>Q) * S * (P<strong>H*VT)
is the SVD of A.  Optionally, the subroutine may also compute Q</strong>H*C
for a given complex input matrix C.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3 (or SIAM J. Sci. Statist. Comput. vol. 11,
no. 5, pp. 873-912, Sept 1990) and
"Accurate singular values and differential qd algorithms," by
B. Parlett and V. Fernando, Technical Report CPAM-554, Mathematics
Department, University of California at Berkeley, July 1992
for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ccopy.html'>stdlib_ccopy</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_cdotc.html'>stdlib_cdotc</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Function</td><td><p>CDOTC = X^H * Y</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cdotu.html'>stdlib_cdotu</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Function</td><td><p>CDOTU = X^T * Y</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbbrd.html'>stdlib_cgbbrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>bidiagonal form B by a unitary transformation: Q<strong>H * A * P = B.
The routine computes B, and optionally forms Q or P</strong>H, or computes
Q*<em>H</em>C for a given matrix C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbcon.html'>stdlib_cgbcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>general band matrix A, in either the 1-norm or the infinity-norm,
using the LU factorization computed by CGBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbequ.html'>stdlib_cgbequ</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N band matrix A and reduce its condition number.  R returns the
row scale factors and C the column scale factors, chosen to try to
make the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbequb.html'>stdlib_cgbequb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from CGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbmv.html'>stdlib_cgbmv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<strong>T<em>x + beta</em>y,   or
y := alpha*A</strong>H<em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n band matrix, with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbrfs.html'>stdlib_cgbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is banded, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbsv.html'>stdlib_cgbsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B, where A is a band matrix of order N with KL subdiagonals
and KU superdiagonals, and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as A = L * U, where L is a product of permutation
and unit lower triangular matrices with KL subdiagonals, and U is
upper triangular with KL+KU superdiagonals.  The factored form of A
is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbsvx.html'>stdlib_cgbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B, A<strong>T * X = B, or A</strong>H * X = B,
where A is a band matrix of order N with KL subdiagonals and KU
superdiagonals, and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbtf2.html'>stdlib_cgbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A using partial pivoting with row interchanges.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbtrf.html'>stdlib_cgbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgbtrs.html'>stdlib_cgbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B
with a general band matrix A using the LU factorization computed
by CGBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgebak.html'>stdlib_cgebak</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix by backward transformation on the computed eigenvectors of the
balanced matrix output by CGEBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgebal.html'>stdlib_cgebal</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>permuting A by a similarity transformation to isolate eigenvalues
in the first 1 to ILO-1 and last IHI+1 to N elements on the
diagonal; and second, applying a diagonal similarity transformation
to rows and columns ILO to IHI to make the rows and columns as
close in norm as possible.  Both steps are optional.
Balancing may reduce the 1-norm of the matrix, and improve the
accuracy of the computed eigenvalues and/or eigenvectors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgebd2.html'>stdlib_cgebd2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>real bidiagonal form B by a unitary transformation: Q**H * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgebrd.html'>stdlib_cgebrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>bidiagonal form B by a unitary transformation: Q**H * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgecon.html'>stdlib_cgecon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>complex matrix A, in either the 1-norm or the infinity-norm, using
the LU factorization computed by CGETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeequ.html'>stdlib_cgeequ</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeequb.html'>stdlib_cgeequb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from CGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgees.html'>stdlib_cgees</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues, the Schur form T, and, optionally, the matrix of Schur
vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z**H).
Optionally, it also orders the eigenvalues on the diagonal of the
Schur form so that selected eigenvalues are at the top left.
The leading columns of Z then form an orthonormal basis for the
invariant subspace corresponding to the selected eigenvalues.
A complex matrix is in Schur form if it is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeesx.html'>stdlib_cgeesx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues, the Schur form T, and, optionally, the matrix of Schur
vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z**H).
Optionally, it also orders the eigenvalues on the diagonal of the
Schur form so that selected eigenvalues are at the top left;
computes a reciprocal condition number for the average of the
selected eigenvalues (RCONDE); and computes a reciprocal condition
number for the right invariant subspace corresponding to the
selected eigenvalues (RCONDV).  The leading columns of Z form an
orthonormal basis for this invariant subspace.
For further explanation of the reciprocal condition numbers RCONDE
and RCONDV, see Section 4.10_sp of the LAPACK Users' Guide (where
these quantities are called s and sep respectively).
A complex matrix is in Schur form if it is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeev.html'>stdlib_cgeev</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)**H denotes the conjugate transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeevx.html'>stdlib_cgeevx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
Optionally also, it computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
SCALE, and ABNRM), reciprocal condition numbers for the eigenvalues
(RCONDE), and reciprocal condition numbers for the right
eigenvectors (RCONDV).
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)<strong>H denotes the conjugate transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.
Balancing a matrix means permuting the rows and columns to make it
more nearly upper triangular, and applying a diagonal similarity
transformation D * A * D</strong>(-1), where D is a diagonal matrix, to
make its rows and columns closer in norm and the condition numbers
of its eigenvalues and eigenvectors smaller.  The computed
reciprocal condition numbers correspond to the balanced matrix.
Permuting rows and columns will not change the condition numbers
(in exact arithmetic) but diagonal scaling will.  For further
explanation of balancing, see section 4.10.2_sp of the LAPACK
Users' Guide.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgehd2.html'>stdlib_cgehd2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>by a unitary similarity transformation:  Q**H * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgehrd.html'>stdlib_cgehrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>an unitary similarity transformation:  Q**H * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgejsv.html'>stdlib_cgejsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix [A], where M &gt;= N. The SVD of [A] is written as
[A] = [U] * [SIGMA] * [V]^*,
where [SIGMA] is an N-by-N (M-by-N) matrix which is zero except for its N
diagonal elements, [U] is an M-by-N (or M-by-M) unitary matrix, and
[V] is an N-by-N unitary matrix. The diagonal elements of [SIGMA] are
the singular values of [A]. The columns of [U] and [V] are the left and
the right singular vectors of [A], respectively. The matrices [U] and [V]
are computed and stored in the arrays U and V, respectively. The diagonal
of [SIGMA] is computed and stored in the array SVA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelq.html'>stdlib_cgelq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelq2.html'>stdlib_cgelq2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a n-by-n orthogonal matrix;
L is a lower-triangular m-by-m matrix;
0 is a m-by-(n-m) zero matrix, if m &lt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelqf.html'>stdlib_cgelqf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelqt.html'>stdlib_cgelqt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelqt3.html'>stdlib_cgelqt3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgels.html'>stdlib_cgels</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, or its conjugate-transpose, using a QR
or LQ factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'C' and m &gt;= n:  find the minimum norm solution of
an underdetermined system A</em><em>H * X = B.
4. If TRANS = 'C' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*H * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelsd.html'>stdlib_cgelsd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>squares problem:
minimize 2-norm(| b - A*x |)
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The problem is solved in three steps:
(1) Reduce the coefficient matrix A to bidiagonal form with
Householder transformations, reducing the original problem
into a "bidiagonal least squares problem" (BLS)
(2) Solve the BLS using a divide and conquer approach.
(3) Apply back all the Householder transformations to solve
the original least squares problem.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelss.html'>stdlib_cgelss</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>least squares problem:
Minimize 2-norm(| b - A*x |).
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix
X.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgelsy.html'>stdlib_cgelsy</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>squares problem:
minimize || A * X - B ||
using a complete orthogonal factorization of A.  A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The routine first computes a QR factorization with column pivoting:
A * P = Q * [ R11 R12 ]
[  0  R22 ]
with R11 defined as the largest leading submatrix whose estimated
condition number is less than 1/RCOND.  The order of R11, RANK,
is the effective rank of A.
Then, R22 is considered to be negligible, and R12 is annihilated
by unitary transformations from the right, arriving at the
complete orthogonal factorization:
A * P = Q * [ T11 0 ] * Z
[  0  0 ]
The minimum-norm solution is then
X = P * Z<strong>H [ inv(T11)*Q1</strong>H*B ]
[        0         ]
where Q1 consists of the first RANK columns of Q.
This routine is basically identical to the original xGELSX except
three differences:
o The permutation of matrix B (the right hand side) is faster and
more simple.
o The call to the subroutine xGEQPF has been substituted by the
the call to the subroutine xGEQP3. This subroutine is a Blas-3
version of the QR factorization with column pivoting.
o Matrix B (the right hand side) is updated with Blas-3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgemlq.html'>stdlib_cgemlq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by short wide
LQ factorization (CGELQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgemlqt.html'>stdlib_cgemlqt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'C':   Q<strong>H C            C Q</strong>H
where Q is a complex unitary matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**H
generated using the compact WY representation as returned by CGELQT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgemm.html'>stdlib_cgemm</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>op( A )</em>op( B ) + beta<em>C,
where  op( X ) is one of
op( X ) = X   or   op( X ) = X</em><em>T   or   op( X ) = X</em>*H,
alpha and beta are scalars, and A, B and C are matrices, with op( A )
an m by k matrix,  op( B )  a  k by n matrix and  C an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgemqr.html'>stdlib_cgemqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (CGEQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgemqrt.html'>stdlib_cgemqrt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'C':    Q<strong>H C            C Q</strong>H
where Q is a complex orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**H
generated using the compact WY representation as returned by CGEQRT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgemv.html'>stdlib_cgemv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<strong>T<em>x + beta</em>y,   or
y := alpha*A</strong>H<em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeql2.html'>stdlib_cgeql2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqlf.html'>stdlib_cgeqlf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqp3.html'>stdlib_cgeqp3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A:  A<em>P = Q</em>R  using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqr.html'>stdlib_cgeqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqr2.html'>stdlib_cgeqr2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqr2p.html'>stdlib_cgeqr2p</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix with nonnegative diagonal
entries;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqrf.html'>stdlib_cgeqrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqrfp.html'>stdlib_cgeqrfp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CGEQR2P computes a QR factorization of a complex M-by-N matrix A:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix with nonnegative diagonal
entries;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqrt.html'>stdlib_cgeqrt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqrt2.html'>stdlib_cgeqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeqrt3.html'>stdlib_cgeqrt3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgerc.html'>stdlib_cgerc</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y**H + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgerfs.html'>stdlib_cgerfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations and provides error bounds and backward error estimates for
the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgerq2.html'>stdlib_cgerq2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgerqf.html'>stdlib_cgerqf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgeru.html'>stdlib_cgeru</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y**T + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesc2.html'>stdlib_cgesc2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = scale* RHS
with a general N-by-N matrix A using the LU factorization with
complete pivoting computed by CGETC2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesdd.html'>stdlib_cgesdd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors, by using divide-and-conquer method. The SVD is written
A = U * SIGMA * conjugate-transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M unitary matrix, and
V is an N-by-N unitary matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns VT = V**H, not V.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesv.html'>stdlib_cgesv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as
A = P * L * U,
where P is a permutation matrix, L is unit lower triangular, and U is
upper triangular.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesvd.html'>stdlib_cgesvd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors. The SVD is written
A = U * SIGMA * conjugate-transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M unitary matrix, and
V is an N-by-N unitary matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns V**H, not V.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesvdq.html'>stdlib_cgesvdq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N unitary matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesvj.html'>stdlib_cgesvj</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N unitary matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgesvx.html'>stdlib_cgesvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>system of linear equations
A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetc2.html'>stdlib_cgetc2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>n-by-n matrix A. The factorization has the form A = P * L * U * Q,
where P and Q are permutation matrices, L is lower triangular with
unit diagonal elements and U is upper triangular.
This is a level 1 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetf2.html'>stdlib_cgetf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetrf.html'>stdlib_cgetrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetrf2.html'>stdlib_cgetrf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = min(m,n)/2
[  A21 | A22  ]       n2 = n-n1
[ A11 ]
The subroutine calls itself to factor [ --- ],
[ A12 ]
[ A12 ]
do the swaps on [ --- ], solve A12, update A22,
[ A22 ]
then calls itself to factor A22 and do the swaps on A21.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetri.html'>stdlib_cgetri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>computed by CGETRF.
This method inverts U and then computes inv(A) by solving the system
inv(A)*L = inv(U) for inv(A).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetrs.html'>stdlib_cgetrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B
with a general N-by-N matrix A using the LU factorization computed
by CGETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetsls.html'>stdlib_cgetsls</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, using a tall skinny QR or short wide LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'C' and m &gt;= n:  find the minimum norm solution of
an undetermined system A</em><em>T * X = B.
4. If TRANS = 'C' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgetsqrhrt.html'>stdlib_cgetsqrhrt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex M-by-N matrix A with M &gt;= N,
A = Q * R.
The routine uses internally a NB1-sized column blocked and MB1-sized
row blocked TSQR-factorization and perfors the reconstruction
of the Householder vectors from the TSQR output. The routine also
converts the R_tsqr factor from the TSQR-factorization output into
the R factor that corresponds to the Householder QR-factorization,
A = Q_tsqr * R_tsqr = Q * R.
The output Q and R factors are stored in the same format as in CGEQRT
(Q is in blocked compact WY-representation). See the documentation
of CGEQRT for more details on the format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggbak.html'>stdlib_cggbak</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalue problem A<em>x = lambda</em>B*x, by backward transformation on
the computed eigenvectors of the balanced pair of matrices output by
CGGBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggbal.html'>stdlib_cggbal</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>involves, first, permuting A and B by similarity transformations to
isolate eigenvalues in the first 1 to ILO$-$1 and last IHI+1 to N
elements on the diagonal; and second, applying a diagonal similarity
transformation to rows and columns ILO to IHI to make the rows
and columns as close in norm as possible. Both steps are optional.
Balancing may reduce the 1-norm of the matrices, and improve the
accuracy of the computed eigenvalues and/or eigenvectors in the
generalized eigenvalue problem A<em>x = lambda</em>B*x.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgges.html'>stdlib_cgges</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the generalized complex Schur
form (S, T), and optionally left and/or right Schur vectors (VSL
and VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>H, (VSL)<em>T</em>(VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T. The leading
columns of VSL and VSR then form an unitary basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
CGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0, and even for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if S
and T are upper triangular and, in addition, the diagonal elements
of T are non-negative real numbers.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgges3.html'>stdlib_cgges3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the generalized complex Schur
form (S, T), and optionally left and/or right Schur vectors (VSL
and VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>H, (VSL)<em>T</em>(VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T. The leading
columns of VSL and VSR then form an unitary basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
CGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0, and even for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if S
and T are upper triangular and, in addition, the diagonal elements
of T are non-negative real numbers.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggesx.html'>stdlib_cggesx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the complex Schur form (S,T),
and, optionally, the left and/or right matrices of Schur vectors (VSL
and VSR).  This gives the generalized Schur factorization
(A,B) = ( (VSL) S (VSR)<strong>H, (VSL) T (VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T; computes
a reciprocal condition number for the average of the selected
eigenvalues (RCONDE); and computes a reciprocal condition number for
the right and left deflating subspaces corresponding to the selected
eigenvalues (RCONDV). The leading columns of VSL and VSR then form
an orthonormal basis for the corresponding left and right eigenspaces
(deflating subspaces).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if T is
upper triangular with non-negative diagonal and S is upper
triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggev.html'>stdlib_cggev</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right generalized eigenvector v(j) corresponding to the
generalized eigenvalue lambda(j) of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left generalized eigenvector u(j) corresponding to the
generalized eigenvalues lambda(j) of (A,B) satisfies
u(j)</em><em>H * A = lambda(j) * u(j)</em><em>H * B
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggev3.html'>stdlib_cggev3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right generalized eigenvector v(j) corresponding to the
generalized eigenvalue lambda(j) of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left generalized eigenvector u(j) corresponding to the
generalized eigenvalues lambda(j) of (A,B) satisfies
u(j)</em><em>H * A = lambda(j) * u(j)</em><em>H * B
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggevx.html'>stdlib_cggevx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(A,B) the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
Optionally, it also computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
LSCALE, RSCALE, ABNRM, and BBNRM), reciprocal condition numbers for
the eigenvalues (RCONDE), and reciprocal condition numbers for the
right eigenvectors (RCONDV).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j) .
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B.
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggglm.html'>stdlib_cggglm</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>minimize || y ||_2   subject to   d = A<em>x + B</em>y
x
where A is an N-by-M matrix, B is an N-by-P matrix, and d is a
given N-vector. It is assumed that M &lt;= N &lt;= M+P, and
rank(A) = M    and    rank( A B ) = N.
Under these assumptions, the constrained equation is always
consistent, and there is a unique solution x and a minimal 2-norm
solution y, which is obtained using a generalized QR factorization
of the matrices (A, B) given by
A = Q<em>(R),   B = Q</em>T<em>Z.
(0)
In particular, if matrix B is square nonsingular, then the problem
GLM is equivalent to the following weighted linear least squares
problem
minimize || inv(B)</em>(d-A*x) ||_2
x
where inv(B) denotes the inverse of B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgghd3.html'>stdlib_cgghd3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hessenberg form using unitary transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the unitary matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>H</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>H</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>H*x.
The unitary matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>H = (Q1<em>Q) * H * (Z1</em>Z)<strong>H
Q1 * B * Z1</strong>H = (Q1<em>Q) * T * (Z1</em>Z)<em><em>H
If Q1 is the unitary matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then CGGHD3 reduces the original
problem to generalized Hessenberg form.
This is a blocked variant of CGGHRD, using matrix-matrix
multiplications for parts of the computation to enhance performance.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgghrd.html'>stdlib_cgghrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hessenberg form using unitary transformations, where A is a
general matrix and B is upper triangular.  The form of the generalized
eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the unitary matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>H</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>H</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>H*x.
The unitary matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>H = (Q1<em>Q) * H * (Z1</em>Z)<strong>H
Q1 * B * Z1</strong>H = (Q1<em>Q) * T * (Z1</em>Z)<em><em>H
If Q1 is the unitary matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then CGGHRD reduces the original
problem to generalized Hessenberg form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgglse.html'>stdlib_cgglse</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>minimize || c - A<em>x ||_2   subject to   B</em>x = d
where A is an M-by-N matrix, B is a P-by-N matrix, c is a given
M-vector, and d is a given P-vector. It is assumed that
P &lt;= N &lt;= M+P, and
rank(B) = P and  rank( (A) ) = N.
( (B) )
These conditions ensure that the LSE problem has a unique solution,
which is obtained using a generalized RQ factorization of the
matrices (B, A) given by
B = (0 R)<em>Q,   A = Z</em>T*Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggqrf.html'>stdlib_cggqrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>and an N-by-P matrix B:
A = Q<em>R,        B = Q</em>T<em>Z,
where Q is an N-by-N unitary matrix, Z is a P-by-P unitary matrix,
and R and T assume one of the forms:
if N &gt;= M,  R = ( R11 ) M  ,   or if N &lt; M,  R = ( R11  R12 ) N,
(  0  ) N-M                         N   M-N
M
where R11 is upper triangular, and
if N &lt;= P,  T = ( 0  T12 ) N,   or if N &gt; P,  T = ( T11 ) N-P,
P-N  N                           ( T21 ) P
P
where T12 or T21 is upper triangular.
In particular, if B is square and nonsingular, the GQR factorization
of A and B implicitly gives the QR factorization of inv(B)</em>A:
inv(B)<em>A = Z</em><em>H * (inv(T)</em>R)
where inv(B) denotes the inverse of the matrix B, and Z' denotes the
conjugate transpose of matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cggrqf.html'>stdlib_cggrqf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>and a P-by-N matrix B:
A = R<em>Q,        B = Z</em>T<em>Q,
where Q is an N-by-N unitary matrix, Z is a P-by-P unitary
matrix, and R and T assume one of the forms:
if M &lt;= N,  R = ( 0  R12 ) M,   or if M &gt; N,  R = ( R11 ) M-N,
N-M  M                           ( R21 ) N
N
where R12 or R21 is upper triangular, and
if P &gt;= N,  T = ( T11 ) N  ,   or if P &lt; N,  T = ( T11  T12 ) P,
(  0  ) P-N                         P   N-P
N
where T11 is upper triangular.
In particular, if B is square and nonsingular, the GRQ factorization
of A and B implicitly gives the RQ factorization of A</em>inv(B):
A<em>inv(B) = (R</em>inv(T))<em>Z</em><em>H
where inv(B) denotes the inverse of the matrix B, and Z</em>*H denotes the
conjugate transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgsvj0.html'>stdlib_cgsvj0</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as CGESVJ does, but
it does not check convergence (stopping criterion). Few tuning
parameters (marked by [TP]) are available for the implementer.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgsvj1.html'>stdlib_cgsvj1</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as CGESVJ does, but
it targets only particular pivots and it does not check convergence
(stopping criterion). Few tuning parameters (marked by [TP]) are
available for the implementer.
Further Details
~~~~~~~~~~~~~~~
CGSVJ1 applies few sweeps of Jacobi rotations in the column space of
the input M-by-N matrix A. The pivot pairs are taken from the (1,2)
off-diagonal block in the corresponding N-by-N Gram matrix A^T * A. The
block-entries (tiles) of the (1,2) off-diagonal block are marked by the
[x]'s in the following scheme:
| *  *  * [x] [x] [x]|
| *  *  * [x] [x] [x]|    Row-cycling in the nblr-by-nblc [x] blocks.
| *  *  * [x] [x] [x]|    Row-cyclic pivoting inside each [x] block.
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
In terms of the columns of A, the first N1 columns are rotated 'against'
the remaining N-N1 columns, trying to increase the angle between the
corresponding subspaces. The off-diagonal block is N1-by(N-N1) and it is
tiled using quadratic tiles of side KBL. Here, KBL is a tuning parameter.
The number of sweeps is given in NSWEEP and the orthogonality threshold
is given in TOL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgtcon.html'>stdlib_cgtcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>tridiagonal matrix A using the LU factorization as computed by
CGTTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgtrfs.html'>stdlib_cgtrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is tridiagonal, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgtsv.html'>stdlib_cgtsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A<em>X = B,
where A is an N-by-N tridiagonal matrix, by Gaussian elimination with
partial pivoting.
Note that the equation  A</em><em>T </em>X = B  may be solved by interchanging the
order of the arguments DU and DL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgtsvx.html'>stdlib_cgtsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B, A<strong>T * X = B, or A</strong>H * X = B,
where A is a tridiagonal matrix of order N and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgttrf.html'>stdlib_cgttrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using elimination with partial pivoting and row interchanges.
The factorization has the form
A = L * U
where L is a product of permutation and unit lower bidiagonal
matrices and U is upper triangular with nonzeros in only the main
diagonal and first two superdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgttrs.html'>stdlib_cgttrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
with a tridiagonal matrix A using the LU factorization computed
by CGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cgtts2.html'>stdlib_cgtts2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
with a tridiagonal matrix A using the LU factorization computed
by CGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chb2st_kernels.html'>stdlib_chb2st_kernels</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>subroutine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbev.html'>stdlib_chbev</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex Hermitian band matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbevd.html'>stdlib_chbevd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex Hermitian band matrix A.  If eigenvectors are desired, it
uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbevx.html'>stdlib_chbevx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex Hermitian band matrix A.  Eigenvalues and eigenvectors
can be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbgst.html'>stdlib_chbgst</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenproblem  A<em>x = lambda</em>B<em>x  to standard form  C</em>y = lambda<em>y,
such that C has the same bandwidth as A.
B must have been previously factorized as S</em><em>H</em>S by CPBSTF, using a
split Cholesky factorization. A is overwritten by C = X<strong>H<em>A</em>X, where
X = S</strong>(-1)*Q and Q is a unitary matrix chosen to preserve the
bandwidth of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbgv.html'>stdlib_chbgv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbgvd.html'>stdlib_chbgvd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbgvx.html'>stdlib_chbgvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.  Eigenvalues and
eigenvectors can be selected by specifying either all eigenvalues,
a range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbmv.html'>stdlib_chbmv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian band matrix, with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chbtrd.html'>stdlib_chbtrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_checon.html'>stdlib_checon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_checon_rook.html'>stdlib_checon_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cheequb.html'>stdlib_cheequb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cheev.html'>stdlib_cheev</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>complex Hermitian matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cheevd.html'>stdlib_cheevd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>complex Hermitian matrix A.  If eigenvectors are desired, it uses a
divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cheevr.html'>stdlib_cheevr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex Hermitian matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.
CHEEVR first reduces the matrix A to tridiagonal form T with a call
to CHETRD.  Then, whenever possible, CHEEVR calls CSTEMR to compute
the eigenspectrum using Relatively Robust Representations.  CSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see CSTEMR's documentation and:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Note 1 : CHEEVR calls CSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
CHEEVR calls SSTEBZ and CSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of CSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cheevx.html'>stdlib_cheevx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex Hermitian matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chegs2.html'>stdlib_chegs2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenproblem to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H </em>A<em>L.
B must have been previously factorized as U</em><em>H </em>U or L<em>L</em>*H by ZPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chegst.html'>stdlib_chegst</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenproblem to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H</em>A<em>L.
B must have been previously factorized as U</em><em>H</em>U or L<em>L</em>*H by CPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chegv.html'>stdlib_chegv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be Hermitian and B is also
positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chegvd.html'>stdlib_chegvd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian and B is also positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chegvx.html'>stdlib_chegvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian and B is also positive definite.
Eigenvalues and eigenvectors can be selected by specifying either a
range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chemm.html'>stdlib_chemm</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where alpha and beta are scalars, A is an hermitian matrix and  B and
C are m by n matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chemv.html'>stdlib_chemv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cher.html'>stdlib_cher</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cher2.html'>stdlib_cher2</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>H + conjg( alpha )<em>y</em>x</strong>H + A,
where alpha is a scalar, x and y are n element vectors and A is an n
by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cher2k.html'>stdlib_cher2k</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B<strong>H + conjg( alpha )<em>B</em>A</strong>H + beta<em>C,
or
C := alpha</em>A<strong>H<em>B + conjg( alpha )</em>B</strong>H<em>A + beta</em>C,
where  alpha and beta  are scalars with  beta  real,  C is an  n by n
hermitian matrix and  A and B  are  n by k matrices in the first case
and  k by n  matrices in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cherfs.html'>stdlib_cherfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cherk.html'>stdlib_cherk</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>A<strong>H + beta<em>C,
or
C := alpha</em>A</strong>H<em>A + beta</em>C,
where  alpha and beta  are  real scalars,  C is an  n by n  hermitian
matrix and  A  is an  n by k  matrix in the  first case and a  k by n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chesv.html'>stdlib_chesv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>H,  if UPLO = 'U', or
A = L * D * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chesv_aa.html'>stdlib_chesv_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>H * T * U,  if UPLO = 'U', or
A = L * T * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is Hermitian and tridiagonal. The factored form
of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chesv_rk.html'>stdlib_chesv_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations A * X = B, where A is an N-by-N Hermitian matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
CHETRF_RK is called to compute the factorization of a complex
Hermitian matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine CHETRS_3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chesv_rook.html'>stdlib_chesv_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
The bounded Bunch-Kaufman ("rook") diagonal pivoting method is used
to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
CHETRF_ROOK is called to compute the factorization of a complex
Hermition matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling CHETRS_ROOK (uses BLAS 2).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chesvx.html'>stdlib_chesvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>solution to a complex system of linear equations A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cheswapr.html'>stdlib_cheswapr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetd2.html'>stdlib_chetd2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetf2.html'>stdlib_chetf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**H is the conjugate transpose of U, and D is
Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetf2_rk.html'>stdlib_chetf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetf2_rook.html'>stdlib_chetf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**H is the conjugate transpose of U, and D is
Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrd.html'>stdlib_chetrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrd_hb2st.html'>stdlib_chetrd_hb2st</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrd_he2hb.html'>stdlib_chetrd_he2hb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>band-diagonal form AB by a unitary similarity transformation:
Q**H * A * Q = AB.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrf.html'>stdlib_chetrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrf_aa.html'>stdlib_chetrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>H<em>T</em>U  or  A = L<em>T</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a hermitian tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrf_rk.html'>stdlib_chetrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrf_rook.html'>stdlib_chetrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetri.html'>stdlib_chetri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by
CHETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetri_rook.html'>stdlib_chetri_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by
CHETRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrs.html'>stdlib_chetrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrs2.html'>stdlib_chetrs2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF and converted by CSYCONV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrs_3.html'>stdlib_chetrs_3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization computed
by CHETRF_RK or CHETRF_BK:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrs_aa.html'>stdlib_chetrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>hermitian matrix A using the factorization A = U<strong>H<em>T</em>U or
A = L<em>T</em>L</strong>H computed by CHETRF_AA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chetrs_rook.html'>stdlib_chetrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chfrk.html'>stdlib_chfrk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for C in RFP Format.
CHFRK: performs one of the Hermitian rank--k operations
C := alpha<em>A</em>A<strong>H + beta<em>C,
or
C := alpha</em>A</strong>H<em>A + beta</em>C,
where alpha and beta are real scalars, C is an n--by--n Hermitian
matrix and A is an n--by--k matrix in the first case and a k--by--n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chgeqz.html'>stdlib_chgeqz</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the single-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a complex matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>H,  B = Q1<em>T</em>Z1</strong>H,
as computed by CGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>H,  T = Q<em>P</em>Z</strong>H,
where Q and Z are unitary matrices and S and P are upper triangular.
Optionally, the unitary matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
unitary matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the unitary matrices from CGGHRD that reduced
the matrix pair (A,B) to generalized Hessenberg form, then the output
matrices Q1<em>Q and Z1</em>Z are the unitary factors from the generalized
Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>H,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>H.
To avoid overflow, eigenvalues of the matrix pair (H,T)
(equivalently, of (A,B)) are computed as a pair of complex values
(alpha,beta).  If beta is nonzero, lambda = alpha / beta is an
eigenvalue of the generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
The values of alpha and beta for the i-th eigenvalue can be read
directly from the generalized Schur form:  alpha = S(i,i),
beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chla_transtype.html'>stdlib_chla_transtype</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This subroutine translates from a BLAST-specified integer constant to
the character string specifying a transposition operation.
CHLA_TRANSTYPE: returns an CHARACTER*1.  If CHLA_TRANSTYPE: is 'X',
then input is not an integer indicating a transposition operator.
Otherwise CHLA_TRANSTYPE returns the constant value corresponding to
TRANS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpcon.html'>stdlib_chpcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian packed matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpev.html'>stdlib_chpev</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>complex Hermitian matrix in packed storage.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpevd.html'>stdlib_chpevd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex Hermitian matrix A in packed storage.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpevx.html'>stdlib_chpevx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex Hermitian matrix A in packed storage.
Eigenvalues/vectors can be selected by specifying either a range of
values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpgst.html'>stdlib_chpgst</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenproblem to standard form, using packed storage.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H</em>A<em>L.
B must have been previously factorized as U</em><em>H</em>U or L<em>L</em>*H by CPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpgv.html'>stdlib_chpgv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be Hermitian, stored in packed format,
and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpgvd.html'>stdlib_chpgvd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian, stored in packed format, and B is also
positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpgvx.html'>stdlib_chpgvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian, stored in packed format, and B is also
positive definite.  Eigenvalues and eigenvectors can be selected by
specifying either a range of values or a range of indices for the
desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpmv.html'>stdlib_chpmv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpr.html'>stdlib_chpr</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpr2.html'>stdlib_chpr2</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>H + conjg( alpha )<em>y</em>x</strong>H + A,
where alpha is a scalar, x and y are n element vectors and A is an
n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chprfs.html'>stdlib_chprfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpsv.html'>stdlib_chpsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>H,  if UPLO = 'U', or
A = L * D * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is Hermitian and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chpsvx.html'>stdlib_chpsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = L<em>D</em>L**H to compute the solution to a complex system of linear
equations A * X = B, where A is an N-by-N Hermitian matrix stored
in packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chptrd.html'>stdlib_chptrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>real symmetric tridiagonal form T by a unitary similarity
transformation: Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chptrf.html'>stdlib_chptrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chptri.html'>stdlib_chptri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chptrs.html'>stdlib_chptrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by CHPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chsein.html'>stdlib_chsein</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvectors of a complex upper Hessenberg matrix H.
The right eigenvector x and the left eigenvector y of the matrix H
corresponding to an eigenvalue w are defined by:
H * x = w * x,     y<strong>h * H = w * y</strong>h
where y**h denotes the conjugate transpose of the vector y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_chseqr.html'>stdlib_chseqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>T</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_gbamv.html'>stdlib_cla_gbamv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_gbrcond_c.html'>stdlib_cla_gbrcond_c</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_gbrpvgrw.html'>stdlib_cla_gbrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_geamv.html'>stdlib_cla_geamv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_gercond_c.html'>stdlib_cla_gercond_c</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_gerpvgrw.html'>stdlib_cla_gerpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_heamv.html'>stdlib_cla_heamv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CLA_SYAMV  performs the matrix-vector operation
y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_hercond_c.html'>stdlib_cla_hercond_c</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_herpvgrw.html'>stdlib_cla_herpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_lin_berr.html'>stdlib_cla_lin_berr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>the formula
max(i) ( abs(R(i)) / ( abs(op(A_s))*abs(Y) + abs(B_s) )(i) )
where abs(Z) is the componentwise absolute value of the matrix
or vector Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_porcond_c.html'>stdlib_cla_porcond_c</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_porpvgrw.html'>stdlib_cla_porpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_syamv.html'>stdlib_cla_syamv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_syrcond_c.html'>stdlib_cla_syrcond_c</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a REAL vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_syrpvgrw.html'>stdlib_cla_syrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cla_wwaddw.html'>stdlib_cla_wwaddw</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>This works for all extant IBM's hex and binary floating point
arithmetic, but not for decimal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clabrd.html'>stdlib_clabrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>m by n matrix A to upper or lower real bidiagonal form by a unitary
transformation Q**H * A * P, and returns the matrices X and Y which
are needed to apply the transformation to the unreduced part of A.
If m &gt;= n, A is reduced to upper bidiagonal form; if m &lt; n, to lower
bidiagonal form.
This is an auxiliary routine called by CGEBRD</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clacgv.html'>stdlib_clacgv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_clacn2.html'>stdlib_clacn2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clacon.html'>stdlib_clacon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clacp2.html'>stdlib_clacp2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>complex matrix B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clacpy.html'>stdlib_clacpy</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clacrm.html'>stdlib_clacrm</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>C := A * B,
where A is M by N and complex; B is N by N and real;
C is M by N and complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clacrt.html'>stdlib_clacrt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>(  c  s )( x )  ==&gt; ( x )
( -s  c )( y )      ( y )
where c and s are complex and the vectors x and y are complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cladiv.html'>stdlib_cladiv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>will not overflow on an intermediary step unless the results
overflows.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claed0.html'>stdlib_claed0</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Using the divide and conquer method, CLAED0: computes all eigenvalues
of a symmetric tridiagonal matrix which is one diagonal block of
those from reducing a dense or band Hermitian matrix and
corresponding eigenvectors of the dense or band matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claed7.html'>stdlib_claed7</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix after modification by a rank-one symmetric matrix. This
routine is used only for the eigenproblem which requires all
eigenvalues and optionally eigenvectors of a dense or banded
Hermitian matrix that has been reduced to tridiagonal form.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>H ) Q</em><em>H(in) = Q(out) * D(out) * Q</em><em>H(out)
where Z = Q</em>*Hu, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine SLAED2.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine SLAED4 (as called by SLAED3).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claed8.html'>stdlib_claed8</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny element in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claein.html'>stdlib_claein</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>corresponding to the eigenvalue W of a complex upper Hessenberg
matrix H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claesy.html'>stdlib_claesy</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>( ( A, B );( B, C ) )
provided the norm of the matrix of eigenvectors is larger than
some threshold value.
RT1 is the eigenvalue of larger absolute value, and RT2 of
smaller absolute value.  If the eigenvectors are computed, then
on return ( CS1, SN1 ) is the unit eigenvector for RT1, hence
[  CS1     SN1   ] . [ A  B ] . [ CS1    -SN1   ] = [ RT1  0  ]
[ -SN1     CS1   ]   [ B  C ]   [ SN1     CS1   ]   [  0  RT2 ]</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claev2.html'>stdlib_claev2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>[  A         B  ]
[  CONJG(B)  C  ].
On return, RT1 is the eigenvalue of larger absolute value, RT2 is the
eigenvalue of smaller absolute value, and (CS1,SN1) is the unit right
eigenvector for RT1, giving the decomposition
[ CS1  CONJG(SN1) ] [    A     B ] [ CS1 -CONJG(SN1) ] = [ RT1  0  ]
[-SN1     CS1     ] [ CONJG(B) C ] [ SN1     CS1     ]   [  0  RT2 ].</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clag2z.html'>stdlib_clag2z</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Note that while it is possible to overflow while converting
from double to single, it is not possible to overflow when
converting from single to double.
This is an auxiliary routine so there is no argument checking.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clags2.html'>stdlib_clags2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>that if ( UPPER ) then
U<strong>H <em>A</em>Q = U</strong>H <em>( A1 A2 )</em>Q = ( x  0  )
( 0  A3 )     ( x  x  )
and
V<strong>H<em>B</em>Q = V</strong>H <em>( B1 B2 )</em>Q = ( x  0  )
( 0  B3 )     ( x  x  )
or if ( .NOT.UPPER ) then
U<strong>H <em>A</em>Q = U</strong>H <em>( A1 0  )</em>Q = ( x  x  )
( A2 A3 )     ( 0  x  )
and
V<strong>H <em>B</em>Q = V</strong>H <em>( B1 0  )</em>Q = ( x  x  )
( B2 B3 )     ( 0  x  )
where
U = (   CSU    SNU ), V = (  CSV    SNV ),
( -SNU<strong>H  CSU )      ( -SNV</strong>H CSV )
Q = (   CSQ    SNQ )
( -SNQ**H  CSQ )
The rows of the transformed A and B are parallel. Moreover, if the
input 2-by-2 matrix A is not zero, then the transformed (1,1) entry
of A is not zero. If the input matrices A and B are both not zero,
then the transformed (2,2) element of B is not zero, except when the
first rows of input A and B are parallel and the second rows are
zero.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clagtm.html'>stdlib_clagtm</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>B := alpha * A * X + beta * B
where A is a tridiagonal matrix of order N, B and X are N by NRHS
matrices, and alpha and beta are real scalars, each of which may be
0., 1., or -1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clahef.html'>stdlib_clahef</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the Bunch-Kaufman diagonal pivoting method. The
partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I      0     )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0      I     )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**H denotes the conjugate transpose of U.
CLAHEF is an auxiliary routine called by CHETRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clahef_aa.html'>stdlib_clahef_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clahef_rk.html'>stdlib_clahef_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
CLAHEF_RK is an auxiliary routine called by CHETRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clahef_rook.html'>stdlib_clahef_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting
method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I      0     )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0      I     )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**H denotes the conjugate transpose of U.
CLAHEF_ROOK is an auxiliary routine called by CHETRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clahqr.html'>stdlib_clahqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues and Schur decomposition already computed by CHSEQR, by
dealing with the Hessenberg submatrix in rows and columns ILO to
IHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clahr2.html'>stdlib_clahr2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A so that elements below the k-th subdiagonal are zero. The
reduction is performed by an unitary similarity transformation
Q<strong>H * A * Q. The routine returns the matrices V and T which determine
Q as a block reflector I - V<em>T</em>v</strong>H, and also the matrix Y = A * V * T.
This is an auxiliary routine called by CGEHRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claic1.html'>stdlib_claic1</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>its simplest version:
Let x, twonorm(x) = 1, be an approximate singular vector of an j-by-j
lower triangular matrix L, such that
twonorm(L<em>x) = sest
Then CLAIC1 computes sestpr, s, c such that
the vector
[ s</em>x ]
xhat = [  c  ]
is an approximate singular vector of
[ L      0  ]
Lhat = [ w<strong>H gamma ]
in the sense that
twonorm(Lhat*xhat) = sestpr.
Depending on JOB, an estimate for the largest or smallest singular
value is computed.
Note that [s c]</strong>H and sestpr<strong>2 is an eigenpair of the system
diag(sest*sest, 0) + [alpha  gamma] * [ conjg(alpha) ]
[ conjg(gamma) ]
where  alpha =  x</strong>H*w.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clals0.html'>stdlib_clals0</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>right singular vector matrix of a diagonal matrix appended by a row
to the right hand side matrix B in solving the least squares problem
using the divide-and-conquer SVD approach.
For the left singular vector matrix, three types of orthogonal
matrices are involved:
(1L) Givens rotations: the number of such rotations is GIVPTR; the
pairs of columns/rows they were applied to are stored in GIVCOL;
and the C- and S-values of these rotations are stored in GIVNUM.
(2L) Permutation. The (NL+1)-st row of B is to be moved to the first
row, and for J=2:N, PERM(J)-th row of B is to be moved to the
J-th row.
(3L) The left singular vector matrix of the remaining matrix.
For the right singular vector matrix, four types of orthogonal
matrices are involved:
(1R) The right singular vector matrix of the remaining matrix.
(2R) If SQRE = 1, one extra Givens rotation to generate the right
null space.
(3R) The inverse transformation of (2L).
(4R) The inverse transformation of (1L).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clalsa.html'>stdlib_clalsa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>by computing the SVD of the coefficient matrix in compact form (The
singular vectors are computed as products of simple orthorgonal
matrices.).
If ICOMPQ = 0, CLALSA applies the inverse of the left singular vector
matrix of an upper bidiagonal matrix to the right hand side; and if
ICOMPQ = 1, CLALSA applies the right singular vector matrix to the
right hand side. The singular vector matrices were generated in
compact form by CLALSA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clalsd.html'>stdlib_clalsd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>squares problem of finding X to minimize the Euclidean norm of each
column of A*X-B, where A is N-by-N upper bidiagonal, and X and B
are N-by-NRHS. The solution X overwrites B.
The singular values of A smaller than RCOND times the largest
singular value are treated as zero in solving the least squares
problem; in this case a minimum norm solution is returned.
The actual singular values are returned in D in ascending order.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clamswlq.html'>stdlib_clamswlq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of blocked
elementary reflectors computed by short wide LQ
factorization (CLASWLQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clamtsqr.html'>stdlib_clamtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (CLATSQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clangb.html'>stdlib_clangb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n band matrix  A,  with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clange.html'>stdlib_clange</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clangt.html'>stdlib_clangt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clanhb.html'>stdlib_clanhb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n hermitian band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clanhe.html'>stdlib_clanhe</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex hermitian matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clanhf.html'>stdlib_clanhf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex Hermitian matrix A in RFP format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clanhp.html'>stdlib_clanhp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex hermitian matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clanhs.html'>stdlib_clanhs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
Hessenberg matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clanht.html'>stdlib_clanht</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex Hermitian tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clansb.html'>stdlib_clansb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n symmetric band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clansp.html'>stdlib_clansp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex symmetric matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clansy.html'>stdlib_clansy</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clantb.html'>stdlib_clantb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n triangular band matrix A,  with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clantp.html'>stdlib_clantp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
triangular matrix A, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clantr.html'>stdlib_clantr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
trapezoidal or triangular matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clapll.html'>stdlib_clapll</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Given two column vectors X and Y, let
A = ( X Y ).
The subroutine first computes the QR factorization of A = Q*R,
and then computes the SVD of the 2-by-2 upper triangular matrix R.
The smaller singular value of R is returned in SSMIN, which is used
as the measurement of the linear dependency of the vectors X and Y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clapmr.html'>stdlib_clapmr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(M) of the integers 1,...,M.
If FORWRD = .TRUE.,  forward permutation:
X(K(I),<em>) is moved X(I,</em>) for I = 1,2,...,M.
If FORWRD = .FALSE., backward permutation:
X(I,<em>) is moved to X(K(I),</em>) for I = 1,2,...,M.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clapmt.html'>stdlib_clapmt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(N) of the integers 1,...,N.
If FORWRD = .TRUE.,  forward permutation:
X(<em>,K(J)) is moved X(</em>,J) for J = 1,2,...,N.
If FORWRD = .FALSE., backward permutation:
X(<em>,J) is moved to X(</em>,K(J)) for J = 1,2,...,N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqgb.html'>stdlib_claqgb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>subdiagonals and KU superdiagonals using the row and scaling factors
in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqge.html'>stdlib_claqge</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>column scaling factors in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqhb.html'>stdlib_claqhb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqhe.html'>stdlib_claqhe</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqhp.html'>stdlib_claqhp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqp2.html'>stdlib_claqp2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>the block A(OFFSET+1:M,1:N).
The block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqps.html'>stdlib_claqps</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a complex M-by-N matrix A by using Blas-3.  It tries to factorize
NB columns from A starting from the row OFFSET+1, and updates all
of the matrix with Blas-3 xGEMM.
In some cases, due to catastrophic cancellations, it cannot
factorize NB columns.  Hence, the actual number of factorized
columns is returned in KB.
Block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqr0.html'>stdlib_claqr0</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>H</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqr1.html'>stdlib_claqr1</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Given a 2-by-2 or 3-by-3 matrix H, CLAQR1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (H - s1</em>I)<em>(H - s2</em>I)
scaling to avoid overflows and most underflows.
This is useful for starting double implicit shift bulges
in the QR algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqr2.html'>stdlib_claqr2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>recursion by calling CLAHQR instead of CLAQR4.
Aggressive early deflation:
This subroutine accepts as input an upper Hessenberg matrix
H and performs an unitary similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an unitary similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqr3.html'>stdlib_claqr3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Aggressive early deflation:
CLAQR3: accepts as input an upper Hessenberg matrix
H and performs an unitary similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an unitary similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqr4.html'>stdlib_claqr4</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>It is a complete implementation of the small bulge multi-shift
QR algorithm.  It may be called by CLAQR0 and, for large enough
deflation window size, it may be called by CLAQR3.  This
subroutine is identical to CLAQR0 except that it calls CLAQR2
instead of CLAQR3.
CLAQR4 computes the eigenvalues of a Hessenberg matrix H
and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>H</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqr5.html'>stdlib_claqr5</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>single small-bulge multi-shift QR sweep.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqsb.html'>stdlib_claqsb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqsp.html'>stdlib_claqsp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqsy.html'>stdlib_claqsy</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqz0.html'>stdlib_claqz0</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>H,  B = Q1<em>T</em>Z1</strong>H,
as computed by CGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>H,  T = Q<em>P</em>Z</strong>H,
where Q and Z are unitary matrices, P and S are an upper triangular
matrices.
Optionally, the unitary matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
unitary matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the unitary matrices from CGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the unitary factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>H,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>H.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.
Ref: B. Kagstrom, D. Kressner, "Multishift Variants of the QZ
Algorithm with Aggressive Early Deflation", SIAM J. Numer.
Anal., 29(2006), pp. 199--227.
Ref: T. Steel, D. Camps, K. Meerbergen, R. Vandebril "A multishift,
multipole rational QZ method with agressive early deflation"</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqz1.html'>stdlib_claqz1</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CLAQZ1: chases a 1x1 shift bulge in a matrix pencil down a single position</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqz2.html'>stdlib_claqz2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CLAQZ2: performs AED</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claqz3.html'>stdlib_claqz3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CLAQZ3: Executes a single multishift QZ sweep</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clar1v.html'>stdlib_clar1v</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>the sumbmatrix in rows B1 through BN of the tridiagonal matrix
L D L<strong>T - sigma I. When sigma is close to an eigenvalue, the
computed vector is an accurate eigenvector. Usually, r corresponds
to the index where the eigenvector is largest in magnitude.
The following steps accomplish this computation :
(a) Stationary qd transform,  L D L</strong>T - sigma I = L(+) D(+) L(+)<strong>T,
(b) Progressive qd transform, L D L</strong>T - sigma I = U(-) D(-) U(-)<strong>T,
(c) Computation of the diagonal elements of the inverse of
L D L</strong>T - sigma I by combining the above transforms, and choosing
r as the index where the diagonal of the inverse is (one of the)
largest in magnitude.
(d) Computation of the (scaled) r-th column of the inverse using the
twisted factorization obtained by combining the top part of the
the stationary and the bottom part of the progressive transform.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clar2v.html'>stdlib_clar2v</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>from both sides to a sequence of 2-by-2 complex Hermitian matrices,
defined by the elements of the vectors x, y and z. For i = 1,2,...,n
(       x(i)  z(i) ) :=
( conjg(z(i)) y(i) )
(  c(i) conjg(s(i)) ) (       x(i)  z(i) ) ( c(i) -conjg(s(i)) )
( -s(i)       c(i)  ) ( conjg(z(i)) y(i) ) ( s(i)        c(i)  )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarcm.html'>stdlib_clarcm</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>C := A * B,
where A is M by M and real; B is M by N and complex;
C is M by N and complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarf.html'>stdlib_clarf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v<strong>H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix.
To apply H</strong>H (the conjugate transpose of H), supply conjg(tau) instead
tau.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarfb.html'>stdlib_clarfb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>complex M-by-N matrix C, from either the left or the right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarfb_gett.html'>stdlib_clarfb_gett</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>left to a complex (K+M)-by-N  "triangular-pentagonal" matrix
composed of two block matrices: an upper trapezoidal K-by-N matrix A
stored in the array A, and a rectangular M-by-(N-K) matrix B, stored
in the array B. The block reflector H is stored in a compact
WY-representation, where the elementary reflectors are in the
arrays A, B and T. See Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarfg.html'>stdlib_clarfg</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>that
H<strong>H * ( alpha ) = ( beta ),   H</strong>H * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, with beta real, and x is an
(n-1)-element complex vector. H is represented in the form
H = I - tau * ( 1 ) * ( 1 v**H ) ,
( v )
where tau is a complex scalar and v is a complex (n-1)-element
vector. Note that H is not hermitian.
If the elements of x are all zero and alpha is real, then tau = 0
and H is taken to be the unit matrix.
Otherwise  1 &lt;= real(tau) &lt;= 2  and  abs(tau-1) &lt;= 1 .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarfgp.html'>stdlib_clarfgp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>that
H<strong>H * ( alpha ) = ( beta ),   H</strong>H * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, beta is real and non-negative, and
x is an (n-1)-element complex vector.  H is represented in the form
H = I - tau * ( 1 ) * ( 1 v**H ) ,
( v )
where tau is a complex scalar and v is a complex (n-1)-element
vector. Note that H is not hermitian.
If the elements of x are all zero and alpha is real, then tau = 0
and H is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarft.html'>stdlib_clarft</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of order n, which is defined as a product of k elementary reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>H
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>H * T * V</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarfx.html'>stdlib_clarfx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v**H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix
This version uses inline code if H has order &lt; 11.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarfy.html'>stdlib_clarfy</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to an n x n Hermitian matrix C, from both the left and the right.
H is represented in the form
H = I - tau * v * v'
where  tau  is a scalar and  v  is a vector.
If  tau  is  zero, then  H  is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clargv.html'>stdlib_clargv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>cosines, determined by elements of the complex vectors x and y.
For i = 1,2,...,n
(        c(i)   s(i) ) ( x(i) ) = ( r(i) )
( -conjg(s(i))  c(i) ) ( y(i) ) = (   0  )
where c(i)<strong>2 + ABS(s(i))</strong>2 = 1
The following conventions are used (these are the same as in CLARTG,
but differ from the BLAS1 routine CROTG):
If y(i)=0, then c(i)=1 and s(i)=0.
If x(i)=0, then c(i)=0 and s(i) is chosen so that r(i) is real.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarnv.html'>stdlib_clarnv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>normal distribution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarrv.html'>stdlib_clarrv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>T = L D L<strong>T given L, D and APPROXIMATIONS to the eigenvalues of L D L</strong>T.
The input eigenvalues should have been computed by SLARRE.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clartg.html'>stdlib_clartg</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_clartg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_clartv.html'>stdlib_clartv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to elements of the complex vectors x and y. For i = 1,2,...,n
( x(i) ) := (        c(i)   s(i) ) ( x(i) )
( y(i) )    ( -conjg(s(i))  c(i) ) ( y(i) )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarz.html'>stdlib_clarz</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>M-by-N matrix C, from either the left or the right. H is represented
in the form
H = I - tau * v * v<strong>H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix.
To apply H</strong>H (the conjugate transpose of H), supply conjg(tau) instead
tau.
H is a product of k elementary reflectors as returned by CTZRZF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarzb.html'>stdlib_clarzb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to a complex distributed M-by-N  C from the left or the right.
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clarzt.html'>stdlib_clarzt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>H of order &gt; n, which is defined as a product of k elementary
reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>H
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>H * T * V
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clascl.html'>stdlib_clascl</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CTO/CFROM.  This is done without over/underflow as long as the final
result CTO*A(I,J)/CFROM does not over/underflow. TYPE specifies that
A may be full, upper triangular, lower triangular, upper Hessenberg,
or banded.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claset.html'>stdlib_claset</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>ALPHA on the offdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clasr.html'>stdlib_clasr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A, from either the left or the right.
When SIDE = 'L', the transformation takes the form
A := P<em>A
and when SIDE = 'R', the transformation takes the form
A := A</em>P<strong>T
where P is an orthogonal matrix consisting of a sequence of z plane
rotations, with z = M when SIDE = 'L' and z = N when SIDE = 'R',
and P</strong>T is the transpose of P.
When DIRECT = 'F' (Forward sequence), then
P = P(z-1) * ... * P(2) * P(1)
and when DIRECT = 'B' (Backward sequence), then
P = P(1) * P(2) * ... * P(z-1)
where P(k) is a plane rotation matrix defined by the 2-by-2 rotation
R(k) = (  c(k)  s(k) )
= ( -s(k)  c(k) ).
When PIVOT = 'V' (Variable pivot), the rotation is performed
for the plane (k,k+1), i.e., P(k) has the form
P(k) = (  1                                            )
(       ...                                     )
(              1                                )
(                   c(k)  s(k)                  )
(                  -s(k)  c(k)                  )
(                                1              )
(                                     ...       )
(                                            1  )
where R(k) appears as a rank-2 modification to the identity matrix in
rows and columns k and k+1.
When PIVOT = 'T' (Top pivot), the rotation is performed for the
plane (1,k+1), so P(k) has the form
P(k) = (  c(k)                    s(k)                 )
(         1                                     )
(              ...                              )
(                     1                         )
( -s(k)                    c(k)                 )
(                                 1             )
(                                      ...      )
(                                             1 )
where R(k) appears in rows and columns 1 and k+1.
Similarly, when PIVOT = 'B' (Bottom pivot), the rotation is
performed for the plane (k,z), giving P(k) the form
P(k) = ( 1                                             )
(      ...                                      )
(             1                                 )
(                  c(k)                    s(k) )
(                         1                     )
(                              ...              )
(                                     1         )
(                 -s(k)                    c(k) )
where R(k) appears in rows and columns k and z.  The rotations are
performed without ever forming P(k) explicitly.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_classq.html'>stdlib_classq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_classq.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_claswlq.html'>stdlib_claswlq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex M-by-N matrix A for M &lt;= N:
A = ( L 0 ) *  Q,
where:
Q is a n-by-N orthogonal matrix, stored on exit in an implicit
form in the elements above the diagonal of the array A and in
the elements of the array T;
L is a lower-triangular M-by-M matrix stored on exit in
the elements on and below the diagonal of the array A.
0 is a M-by-(N-M) zero matrix, if M &lt; N, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claswp.html'>stdlib_claswp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>One row interchange is initiated for each of rows K1 through K2 of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clasyf.html'>stdlib_clasyf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A using the Bunch-Kaufman diagonal pivoting method. The partial
factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) ( D    0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) ( 0   A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**T denotes the transpose of U.
CLASYF is an auxiliary routine called by CSYTRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clasyf_aa.html'>stdlib_clasyf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>DLATRF_AA factorizes a panel of a complex symmetric matrix A using
the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clasyf_rk.html'>stdlib_clasyf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
CLASYF_RK is an auxiliary routine called by CSYTRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clasyf_rook.html'>stdlib_clasyf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
CLASYF_ROOK is an auxiliary routine called by CSYTRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatbs.html'>stdlib_clatbs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow, where A is an upper or lower
triangular band matrix.  Here A</strong>T denotes the transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine CTBSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatdf.html'>stdlib_clatdf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>by solving for x in Z * x = b, where b is chosen such that the norm
of x is as large as possible. It is assumed that LU decomposition
of Z has been computed by CGETC2. On entry RHS = f holds the
contribution from earlier solved sub-systems, and on return RHS = x.
The factorization of Z returned by CGETC2 has the form
Z = P * L * U * Q, where P and Q are permutation matrices. L is lower
triangular with unit diagonal elements and U is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatps.html'>stdlib_clatps</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow, where A is an upper or lower
triangular matrix stored in packed form.  Here A</strong>T denotes the
transpose of A, A*<em>H denotes the conjugate transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine CTPSV is called. If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A</em>x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatrd.html'>stdlib_clatrd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian tridiagonal form by a unitary similarity
transformation Q**H * A * Q, and returns the matrices V and W which are
needed to apply the transformation to the unreduced part of A.
If UPLO = 'U', CLATRD reduces the last NB rows and columns of a
matrix, of which the upper triangle is supplied;
if UPLO = 'L', CLATRD reduces the first NB rows and columns of a
matrix, of which the lower triangle is supplied.
This is an auxiliary routine called by CHETRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatrs.html'>stdlib_clatrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow.  Here A is an upper or lower
triangular matrix, A</strong>T denotes the transpose of A, A*<em>H denotes the
conjugate transpose of A, x and b are n-element vectors, and s is a
scaling factor, usually less than or equal to 1, chosen so that the
components of x will be less than the overflow threshold.  If the
unscaled problem will not cause overflow, the Level 2 BLAS routine
CTRSV is called. If the matrix A is singular (A(j,j) = 0 for some j),
then s is set to 0 and a non-trivial solution to A</em>x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatrz.html'>stdlib_clatrz</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>[ A1 A2 ] = [ A(1:M,1:M) A(1:M,N-L+1:N) ] as ( R  0 ) * Z by means
of unitary transformations, where  Z is an (M+L)-by-(M+L) unitary
matrix and, R and A1 are M-by-M upper triangular matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clatsqr.html'>stdlib_clatsqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex M-by-N matrix A for M &gt;= N:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix, stored on exit in an implicit
form in the elements below the diagonal of the array A and in
the elements of the array T;
R is an upper-triangular N-by-N matrix, stored on exit in
the elements on and above the diagonal of the array A.
0 is a (M-N)-by-N zero matrix, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claunhr_col_getrfnp.html'>stdlib_claunhr_col_getrfnp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>pivoting of a complex general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is
at least one in absolute value (so that division-by-zero not
not possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine CUNHR_COL. In CUNHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the blocked right-looking version of the algorithm,
calling Level 3 BLAS to update the submatrix. To factorize a block,
this routine calls the recursive routine CLAUNHR_COL_GETRFNP2.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_claunhr_col_getrfnp2.html'>stdlib_claunhr_col_getrfnp2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>pivoting of a complex general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is at
least one in absolute value (so that division-by-zero not
possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine CUNHR_COL. In CUNHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the recursive version of the LU factorization algorithm.
Denote A - S by B. The algorithm divides the matrix B into four
submatrices:
[  B11 | B12  ]  where B11 is n1 by n1,
B = [ -----|----- ]        B21 is (m-n1) by n1,
[  B21 | B22  ]        B12 is n1 by n2,
B22 is (m-n1) by n2,
with n1 = min(m,n)/2, n2 = n-n1.
The subroutine calls itself to factor B11, solves for B21,
solves for B12, updates B22, then calls itself to factor B22.
For more details on the recursive LU algorithm, see [2].
CLAUNHR_COL_GETRFNP2 is called to factorize a block by the blocked
routine CLAUNHR_COL_GETRFNP, which uses blocked code calling
Level 3 BLAS to update the submatrix. However, CLAUNHR_COL_GETRFNP2
is self-sufficient and can be used without CLAUNHR_COL_GETRFNP.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.
[2] "Recursion leads to automatic variable blocking for dense linear
algebra algorithms", F. Gustavson, IBM J. of Res. and Dev.,
vol. 41, no. 6, pp. 737-755, 1997.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clauu2.html'>stdlib_clauu2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the unblocked form of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_clauum.html'>stdlib_clauum</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the blocked form of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbcon.html'>stdlib_cpbcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite band matrix using
the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by
CPBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbequ.html'>stdlib_cpbequ</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian positive definite band matrix A and reduce its condition
number (with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbrfs.html'>stdlib_cpbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and banded, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbstf.html'>stdlib_cpbstf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian positive definite band matrix A.
This routine is designed to be used in conjunction with CHBGST.
The factorization has the form  A = S*<em>H</em>S  where S is a band matrix
of the same bandwidth as A and the following structure:
S = ( U    )
( M  L )
where U is upper triangular of order m = (n+kd)/2, and L is lower
triangular of order n-m.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbsv.html'>stdlib_cpbsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite band matrix and X
and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H * U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular band matrix, and L is a lower
triangular band matrix, with the same number of superdiagonals or
subdiagonals as A.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbsvx.html'>stdlib_cpbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>compute the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N Hermitian positive definite band matrix and X
and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbtf2.html'>stdlib_cpbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>H * U ,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix, U**H is the conjugate transpose
of U, and L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbtrf.html'>stdlib_cpbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpbtrs.html'>stdlib_cpbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite band matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpftrf.html'>stdlib_cpftrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpftri.html'>stdlib_cpftri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by CPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpftrs.html'>stdlib_cpftrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpocon.html'>stdlib_cpocon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite matrix using the
Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPOTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpoequ.html'>stdlib_cpoequ</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpoequb.html'>stdlib_cpoequb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.
This routine differs from CPOEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled diagonal entries are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cporfs.html'>stdlib_cporfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite,
and provides error bounds and backward error estimates for the
solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cposv.html'>stdlib_cposv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix and X and B
are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H* U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and  L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cposvx.html'>stdlib_cposvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>compute the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N Hermitian positive definite matrix and X and B
are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpotf2.html'>stdlib_cpotf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U ,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpotrf.html'>stdlib_cpotrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpotrf2.html'>stdlib_cpotrf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A using the recursive algorithm.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = n/2
[  A21 | A22  ]       n2 = n-n1
The subroutine calls itself to factor A11. Update and scale A21
or A12, update A22 then calls itself to factor A22.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpotri.html'>stdlib_cpotri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by CPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpotrs.html'>stdlib_cpotrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cppcon.html'>stdlib_cppcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite packed matrix using
the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by
CPPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cppequ.html'>stdlib_cppequ</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Hermitian positive definite matrix A in packed storage and reduce
its condition number (with respect to the two-norm).  S contains the
scale factors, S(i)=1/sqrt(A(i,i)), chosen so that the scaled matrix
B with elements B(i,j)=S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.
This choice of S puts the condition number of B within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpprfs.html'>stdlib_cpprfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cppsv.html'>stdlib_cppsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H * U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cppsvx.html'>stdlib_cppsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>compute the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N Hermitian positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpptrf.html'>stdlib_cpptrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A stored in packed format.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpptri.html'>stdlib_cpptri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by CPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpptrs.html'>stdlib_cpptrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite matrix A in packed storage using the Cholesky
factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by CPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpstf2.html'>stdlib_cpstf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>pivoting of a complex Hermitian positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>H * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpstrf.html'>stdlib_cpstrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>pivoting of a complex Hermitian positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>H * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cptcon.html'>stdlib_cptcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite tridiagonal matrix
using the factorization A = L<em>D</em>L<strong>H or A = U</strong>H<em>D</em>U computed by
CPTTRF.
Norm(inv(A)) is computed by a direct method, and the reciprocal of
the condition number is computed as
RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpteqr.html'>stdlib_cpteqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric positive definite tridiagonal matrix by first factoring the
matrix using SPTTRF and then calling CBDSQR to compute the singular
values of the bidiagonal factor.
This routine computes the eigenvalues of the positive definite
tridiagonal matrix to high relative accuracy.  This means that if the
eigenvalues range over many orders of magnitude in size, then the
small eigenvalues and corresponding eigenvectors will be computed
more accurately than, for example, with the standard QR method.
The eigenvectors of a full or band positive definite Hermitian matrix
can also be found if CHETRD, CHPTRD, or CHBTRD has been used to
reduce this matrix to tridiagonal form.  (The reduction to
tridiagonal form, however, may preclude the possibility of obtaining
high relative accuracy in the small eigenvalues of the original
matrix, if these eigenvalues range over many orders of magnitude.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cptrfs.html'>stdlib_cptrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and tridiagonal, and provides error bounds and backward error
estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cptsv.html'>stdlib_cptsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A<em>X = B, where A is an N-by-N Hermitian positive definite tridiagonal
matrix, and X and B are N-by-NRHS matrices.
A is factored as A = L</em>D<em>L</em>*H, and the factored form of A is then
used to solve the system of equations.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cptsvx.html'>stdlib_cptsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to a complex system of linear equations A*X = B, where A is an
N-by-N Hermitian positive definite tridiagonal matrix and X and B
are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpttrf.html'>stdlib_cpttrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>positive definite tridiagonal matrix A.  The factorization may also
be regarded as having the form A = U<em><em>H </em>D</em>U.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cpttrs.html'>stdlib_cpttrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B
using the factorization A = U<strong>H<em>D</em>U or A = L<em>D</em>L</strong>H computed by CPTTRF.
D is a diagonal matrix specified in the vector D, U (or L) is a unit
bidiagonal matrix whose superdiagonal (subdiagonal) is specified in
the vector E, and X and B are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cptts2.html'>stdlib_cptts2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B
using the factorization A = U<strong>H<em>D</em>U or A = L<em>D</em>L</strong>H computed by CPTTRF.
D is a diagonal matrix specified in the vector D, U (or L) is a unit
bidiagonal matrix whose superdiagonal (subdiagonal) is specified in
the vector E, and X and B are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_crot.html'>stdlib_crot</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>sin (S) is complex, and the vectors CX and CY are complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_crotg.html'>stdlib_crotg</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_crotg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_cscal.html'>stdlib_cscal</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_cspcon.html'>stdlib_cspcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex symmetric packed matrix A using the
factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cspmv.html'>stdlib_cspmv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cspr.html'>stdlib_cspr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a complex scalar, x is an n element vector and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csprfs.html'>stdlib_csprfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cspsv.html'>stdlib_cspsv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is symmetric and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cspsvx.html'>stdlib_cspsvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = L<em>D</em>L**T to compute the solution to a complex system of linear
equations A * X = B, where A is an N-by-N symmetric matrix stored
in packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csptrf.html'>stdlib_csptrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>stored in packed format using the Bunch-Kaufman diagonal pivoting
method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csptri.html'>stdlib_csptri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csptrs.html'>stdlib_csptrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csrot.html'>stdlib_csrot</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>and the vectors cx and cy are complex.
jack dongarra, linpack, 3/11/78.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csrscl.html'>stdlib_csrscl</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1/a.  This is done without overflow or underflow as long as
the final result x/a does not overflow or underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csscal.html'>stdlib_csscal</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_cstedc.html'>stdlib_cstedc</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.
The eigenvectors of a full or band complex Hermitian matrix can also
be found if CHETRD or CHPTRD or CHBTRD has been used to reduce this
matrix to tridiagonal form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See SLAED3 for details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cstegr.html'>stdlib_cstegr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
CSTEGR is a compatibility wrapper around the improved CSTEMR routine.
See SSTEMR for further details.
One important change is that the ABSTOL parameter no longer provides any
benefit and hence is no longer used.
Note : CSTEGR and CSTEMR work only on machines which follow
IEEE-754 floating-point standard in their handling of infinities and
NaNs.  Normal execution may create these exceptiona values and hence
may abort due to a floating point exception in environments which
do not conform to the IEEE-754 standard.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cstein.html'>stdlib_cstein</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix T corresponding to specified eigenvalues, using inverse
iteration.
The maximum number of iterations allowed for each eigenvector is
specified by an internal parameter MAXITS (currently set to 5).
Although the eigenvectors are real, they are stored in a complex
array, which may be passed to CUNMTR or CUPMTR for back
transformation to the eigenvectors of a complex Hermitian matrix
which was reduced to tridiagonal form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cstemr.html'>stdlib_cstemr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
Depending on the number of desired eigenvalues, these are computed either
by bisection or the dqds algorithm. Numerically orthogonal eigenvectors are
computed by the use of various suitable L D L^T factorizations near clusters
of close eigenvalues (referred to as RRRs, Relatively Robust
Representations). An informal sketch of the algorithm follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
For more details, see:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Further Details
1.CSTEMR works only on machines which follow IEEE-754
floating-point standard in their handling of infinities and NaNs.
This permits the use of efficient inner loops avoiding a check for
zero divisors.
2. LAPACK routines can be used to reduce a complex Hermitean matrix to
real symmetric tridiagonal form.
(Any complex Hermitean tridiagonal matrix has real values on its diagonal
and potentially complex numbers on its off-diagonals. By applying a
similarity transform with an appropriate diagonal matrix
diag(1,e^{i \phy_1}, ... , e^{i \phy_{n-1}}), the complex Hermitean
matrix can be transformed into a real symmetric matrix and complex
arithmetic can be entirely avoided.)
While the eigenvectors of the real symmetric tridiagonal matrix are real,
the eigenvectors of original complex Hermitean matrix have complex entries
in general.
Since LAPACK drivers overwrite the matrix data with the eigenvectors,
CSTEMR accepts complex workspace to facilitate interoperability
with CUNMTR or CUPMTR.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csteqr.html'>stdlib_csteqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the implicit QL or QR method.
The eigenvectors of a full or band complex Hermitian matrix can also
be found if CHETRD or CHPTRD or CHBTRD has been used to reduce this
matrix to tridiagonal form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cswap.html'>stdlib_cswap</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_csycon.html'>stdlib_csycon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSYTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csycon_rook.html'>stdlib_csycon_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>1-norm) of a complex symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSYTRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyconv.html'>stdlib_csyconv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Get Non-diag elements of D (returned in workspace) and
apply or reverse permutation done in TRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyconvf.html'>stdlib_csyconvf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
CSYCONVF: converts the factorization output format used in
CSYTRF provided on entry in parameter A into the factorization
output format used in CSYTRF_RK (or CSYTRF_BK) that is stored
on exit in parameters A and E. It also converts in place details of
the intechanges stored in IPIV from the format used in CSYTRF into
the format used in CSYTRF_RK (or CSYTRF_BK).
If parameter WAY = 'R':
CSYCONVF performs the conversion in reverse direction, i.e.
converts the factorization output format used in CSYTRF_RK
(or CSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in CSYTRF that is stored
on exit in parameter A. It also converts in place details of
the intechanges stored in IPIV from the format used in CSYTRF_RK
(or CSYTRF_BK) into the format used in CSYTRF.
CSYCONVF can also convert in Hermitian matrix case, i.e. between
formats used in CHETRF and CHETRF_RK (or CHETRF_BK).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyconvf_rook.html'>stdlib_csyconvf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
CSYCONVF_ROOK: converts the factorization output format used in
CSYTRF_ROOK provided on entry in parameter A into the factorization
output format used in CSYTRF_RK (or CSYTRF_BK) that is stored
on exit in parameters A and E. IPIV format for CSYTRF_ROOK and
CSYTRF_RK (or CSYTRF_BK) is the same and is not converted.
If parameter WAY = 'R':
CSYCONVF_ROOK performs the conversion in reverse direction, i.e.
converts the factorization output format used in CSYTRF_RK
(or CSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in CSYTRF_ROOK that is stored
on exit in parameter A. IPIV format for CSYTRF_ROOK and
CSYTRF_RK (or CSYTRF_BK) is the same and is not converted.
CSYCONVF_ROOK can also convert in Hermitian matrix case, i.e. between
formats used in CHETRF_ROOK and CHETRF_RK (or CHETRF_BK).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyequb.html'>stdlib_csyequb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csymm.html'>stdlib_csymm</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where  alpha and beta are scalars, A is a symmetric matrix and  B and
C are m by n matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csymv.html'>stdlib_csymv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyr.html'>stdlib_csyr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a complex scalar, x is an n element vector and A is an
n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyr2k.html'>stdlib_csyr2k</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B<strong>T + alpha<em>B</em>A</strong>T + beta<em>C,
or
C := alpha</em>A<strong>T<em>B + alpha</em>B</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars,  C is an  n by n symmetric matrix
and  A and B  are  n by k  matrices  in the  first  case  and  k by n
matrices in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyrfs.html'>stdlib_csyrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyrk.html'>stdlib_csyrk</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars,  C is an  n by n symmetric matrix
and  A  is an  n by k  matrix in the first case and a  k by n  matrix
in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csysv.html'>stdlib_csysv</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csysv_aa.html'>stdlib_csysv_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>CSYSV computes the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>T * T * U,  if UPLO = 'U', or
A = L * T * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is symmetric tridiagonal. The factored
form of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csysv_rk.html'>stdlib_csysv_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations A * X = B, where A is an N-by-N symmetric matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
CSYTRF_RK is called to compute the factorization of a complex
symmetric matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine CSYTRS_3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csysv_rook.html'>stdlib_csysv_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
CSYTRF_ROOK is called to compute the factorization of a complex
symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling CSYTRS_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csysvx.html'>stdlib_csysvx</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>solution to a complex system of linear equations A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csyswapr.html'>stdlib_csyswapr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytf2.html'>stdlib_csytf2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytf2_rk.html'>stdlib_csytf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytf2_rook.html'>stdlib_csytf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrf.html'>stdlib_csytrf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrf_aa.html'>stdlib_csytrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>T<em>T</em>U  or  A = L<em>T</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a complex symmetric tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrf_rk.html'>stdlib_csytrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrf_rook.html'>stdlib_csytrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytri.html'>stdlib_csytri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by
CSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytri_rook.html'>stdlib_csytri_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T
computed by CSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrs.html'>stdlib_csytrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrs2.html'>stdlib_csytrs2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSYTRF and converted by CSYCONV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrs_3.html'>stdlib_csytrs_3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization computed
by CSYTRF_RK or CSYTRF_BK:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrs_aa.html'>stdlib_csytrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<strong>T<em>T</em>U or
A = L<em>T</em>L</strong>T computed by CSYTRF_AA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_csytrs_rook.html'>stdlib_csytrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctbcon.html'>stdlib_ctbcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>triangular band matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctbmv.html'>stdlib_ctbmv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular band matrix, with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctbrfs.html'>stdlib_ctbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular band
coefficient matrix.
The solution matrix X must be computed by CTBTRS or some other
means before entering this routine.  CTBRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctbsv.html'>stdlib_ctbsv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular band matrix, with ( k + 1 )
diagonals.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctbtrs.html'>stdlib_ctbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular band matrix of order N, and B is an
N-by-NRHS matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctfsm.html'>stdlib_ctfsm</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for A in RFP Format.
CTFSM: solves the matrix equation
op( A )<em>X = alpha</em>B  or  X<em>op( A ) = alpha</em>B
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**H.
A is in Rectangular Full Packed (RFP) Format.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctftri.html'>stdlib_ctftri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>format.
This is a Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctfttp.html'>stdlib_ctfttp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>format (TF) to standard packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctfttr.html'>stdlib_ctfttr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>format (TF) to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgevc.html'>stdlib_ctgevc</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a pair of complex matrices (S,P), where S and P are upper triangular.
Matrix pairs of this type are produced by the generalized Schur
factorization of a complex matrix pair (A,B):
A = Q<em>S</em>Z<strong>H,  B = Q<em>P</em>Z</strong>H
as computed by CGGHRD + CHGEQZ.
The right eigenvector x and the left eigenvector y of (S,P)
corresponding to an eigenvalue w are defined by:
S<em>x = w</em>P<em>x,  (y</em><em>H)</em>S = w<em>(y</em><em>H)</em>P,
where y<em><em>H denotes the conjugate tranpose of y.
The eigenvalues are not input to this routine, but are computed
directly from the diagonal elements of S and P.
This routine returns the matrices X and/or Y of right and left
eigenvectors of (S,P), or the products Z</em>X and/or Q</em>Y,
where Z and Q are input matrices.
If Q and Z are the unitary factors from the generalized Schur
factorization of a matrix pair (A,B), then Z<em>X and Q</em>Y
are the matrices of right and left eigenvectors of (A,B).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgex2.html'>stdlib_ctgex2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>in an upper triangular matrix pair (A, B) by an unitary equivalence
transformation.
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)<strong>H = Q(out) * A(out) * Z(out)</strong>H
Q(in) * B(in) * Z(in)<strong>H = Q(out) * B(out) * Z(out)</strong>H</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgexc.html'>stdlib_ctgexc</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix pair (A,B), using an unitary equivalence transformation
(A, B) := Q * (A, B) * Z<strong>H, so that the diagonal block of (A, B) with
row index IFST is moved to row ILST.
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)</strong>H = Q(out) * A(out) * Z(out)<strong>H
Q(in) * B(in) * Z(in)</strong>H = Q(out) * B(out) * Z(out)**H</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgsen.html'>stdlib_ctgsen</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix pair (A, B) (in terms of an unitary equivalence trans-
formation Q**H * (A, B) * Z), so that a selected cluster of eigenvalues
appears in the leading diagonal blocks of the pair (A,B). The leading
columns of Q and Z form unitary bases of the corresponding left and
right eigenspaces (deflating subspaces). (A, B) must be in
generalized Schur canonical form, that is, A and B are both upper
triangular.
CTGSEN also computes the generalized eigenvalues
w(j)= ALPHA(j) / BETA(j)
of the reordered matrix pair (A, B).
Optionally, the routine computes estimates of reciprocal condition
numbers for eigenvalues and eigenspaces. These are Difu[(A11,B11),
(A22,B22)] and Difl[(A11,B11), (A22,B22)], i.e. the separation(s)
between the matrix pairs (A11, B11) and (A22,B22) that correspond to
the selected cluster and the eigenvalues outside the cluster, resp.,
and norms of "projections" onto left and right eigenspaces w.r.t.
the selected cluster in the (1,1)-block.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgsja.html'>stdlib_ctgsja</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>of two complex upper triangular (or trapezoidal) matrices A and B.
On entry, it is assumed that matrices A and B have the following
forms, which may be obtained by the preprocessing subroutine CGGSVP
from a general M-by-N matrix A and P-by-N matrix B:
N-K-L  K    L
A =    K ( 0    A12  A13 ) if M-K-L &gt;= 0;
L ( 0     0   A23 )
M-K-L ( 0     0    0  )
N-K-L  K    L
A =  K ( 0    A12  A13 ) if M-K-L &lt; 0;
M-K ( 0     0   A23 )
N-K-L  K    L
B =  L ( 0     0   B13 )
P-L ( 0     0    0  )
where the K-by-K matrix A12 and L-by-L matrix B13 are nonsingular
upper triangular; A23 is L-by-L upper triangular if M-K-L &gt;= 0,
otherwise A23 is (M-K)-by-L upper trapezoidal.
On exit,
U<strong>H <em>A</em>Q = D1*( 0 R ),    V</strong>H <em>B</em>Q = D2<em>( 0 R ),
where U, V and Q are unitary matrices.
R is a nonsingular upper triangular matrix, and D1
and D2 are ``diagonal'' matrices, which are of the following
structures:
If M-K-L &gt;= 0,
K  L
D1 =     K ( I  0 )
L ( 0  C )
M-K-L ( 0  0 )
K  L
D2 = L   ( 0  S )
P-L ( 0  0 )
N-K-L  K    L
( 0 R ) = K (  0   R11  R12 ) K
L (  0    0   R22 ) L
where
C = diag( ALPHA(K+1), ... , ALPHA(K+L) ),
S = diag( BETA(K+1),  ... , BETA(K+L) ),
C</em><em>2 + S</em><em>2 = I.
R is stored in A(1:K+L,N-K-L+1:N) on exit.
If M-K-L &lt; 0,
K M-K K+L-M
D1 =   K ( I  0    0   )
M-K ( 0  C    0   )
K M-K K+L-M
D2 =   M-K ( 0  S    0   )
K+L-M ( 0  0    I   )
P-L ( 0  0    0   )
N-K-L  K   M-K  K+L-M
( 0 R ) =    K ( 0    R11  R12  R13  )
M-K ( 0     0   R22  R23  )
K+L-M ( 0     0    0   R33  )
where
C = diag( ALPHA(K+1), ... , ALPHA(M) ),
S = diag( BETA(K+1),  ... , BETA(M) ),
C</em><em>2 + S</em>*2 = I.
R = ( R11 R12 R13 ) is stored in A(1:M, N-K-L+1:N) and R33 is stored
(  0  R22 R23 )
in B(M-K+1:L,N+M-K-L+1:N) on exit.
The computation of the unitary transformation matrices U, V or Q
is optional.  These matrices may either be formed explicitly, or they
may be postmultiplied into input matrices U1, V1, or Q1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgsna.html'>stdlib_ctgsna</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues and/or eigenvectors of a matrix pair (A, B).
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgsy2.html'>stdlib_ctgsy2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * R - L * B = scale *  C               (1)
D * R - L * E = scale * F
using Level 1 and 2 BLAS, where R and L are unknown M-by-N matrices,
(A, D), (B, E) and (C, F) are given matrix pairs of size M-by-M,
N-by-N and M-by-N, respectively. A, B, D and E are upper triangular
(i.e., (A,D) and (B,E) in generalized Schur form).
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output
scaling factor chosen to avoid overflow.
In matrix notation solving equation (1) corresponds to solve
Zx = scale * b, where Z is defined as
Z = [ kron(In, A)  -kron(B<strong>H, Im) ]             (2)
[ kron(In, D)  -kron(E</strong>H, Im) ],
Ik is the identity matrix of size k and X<strong>H is the transpose of X.
kron(X, Y) is the Kronecker product between the matrices X and Y.
If TRANS = 'C', y in the conjugate transposed system Z</strong>H<em>y = scale</em>b
is solved for, which is equivalent to solve for R and L in
A<strong>H * R  + D</strong>H * L   = scale * C           (3)
R  * B<strong>H + L  * E</strong>H  = scale * -F
This case is used to compute an estimate of Dif[(A, D), (B, E)] =
= sigma_min(Z) using reverse communication with CLACON.
CTGSY2 also (IJOB &gt;= 1) contributes to the computation in CTGSYL
of an upper bound on the separation between to matrix pairs. Then
the input (A, D), (B, E) are sub-pencils of two matrix pairs in
CTGSYL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctgsyl.html'>stdlib_ctgsyl</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C            (1)
D * R - L * E = scale * F
where R and L are unknown m-by-n matrices, (A, D), (B, E) and
(C, F) are given matrix pairs of size m-by-m, n-by-n and m-by-n,
respectively, with complex entries. A, B, D and E are upper
triangular (i.e., (A,D) and (B,E) in generalized Schur form).
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1
is an output scaling factor chosen to avoid overflow.
In matrix notation (1) is equivalent to solve Zx = scale<em>b, where Z
is defined as
Z = [ kron(In, A)  -kron(B</em><em>H, Im) ]        (2)
[ kron(In, D)  -kron(E</em><em>H, Im) ],
Here Ix is the identity matrix of size x and X</em><em>H is the conjugate
transpose of X. Kron(X, Y) is the Kronecker product between the
matrices X and Y.
If TRANS = 'C', y in the conjugate transposed system Z</em><em>H </em>y = scale<em>b
is solved for, which is equivalent to solve for R and L in
A</em><em>H * R + D</em><em>H * L = scale * C           (3)
R * B</em><em>H + L * E</em>*H = scale * -F
This case (TRANS = 'C') is used to compute an one-norm-based estimate
of Dif[(A,D), (B,E)], the separation between the matrix pairs (A,D)
and (B,E), using CLACON.
If IJOB &gt;= 1, CTGSYL computes a Frobenius norm-based estimate of
Dif[(A,D),(B,E)]. That is, the reciprocal of a lower bound on the
reciprocal of the smallest singular value of Z.
This is a level-3 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpcon.html'>stdlib_ctpcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctplqt.html'>stdlib_ctplqt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctplqt2.html'>stdlib_ctplqt2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpmlqt.html'>stdlib_ctpmlqt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" complex block reflector H to a general
complex matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpmqrt.html'>stdlib_ctpmqrt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" complex block reflector H to a general
complex matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpmv.html'>stdlib_ctpmv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpqrt.html'>stdlib_ctpqrt</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpqrt2.html'>stdlib_ctpqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctprfb.html'>stdlib_ctprfb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>conjugate transpose H**H to a complex matrix C, which is composed of two
blocks A and B, either from the left or right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctprfs.html'>stdlib_ctprfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular packed
coefficient matrix.
The solution matrix X must be computed by CTPTRS or some other
means before entering this routine.  CTPRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpsv.html'>stdlib_ctpsv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix, supplied in packed form.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctptri.html'>stdlib_ctptri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A stored in packed format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctptrs.html'>stdlib_ctptrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular matrix of order N stored in packed format,
and B is an N-by-NRHS matrix.  A check is made to verify that A is
nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpttf.html'>stdlib_ctpttf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctpttr.html'>stdlib_ctpttr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrcon.html'>stdlib_ctrcon</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrevc.html'>stdlib_ctrevc</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex upper triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a complex general matrix:  A = Q<em>T</em>Q<strong>H, as computed by CHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix.  If Q is the unitary factor that reduces a matrix A to
Schur form T, then Q<em>X and Q</em>Y are the matrices of right and left
eigenvectors of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrevc3.html'>stdlib_ctrevc3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>a complex upper triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a complex general matrix:  A = Q<em>T</em>Q<strong>H, as computed by CHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix. If Q is the unitary factor that reduces a matrix A to
Schur form T, then Q<em>X and Q</em>Y are the matrices of right and left
eigenvectors of A.
This uses a Level 3 BLAS version of the back transformation.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrexc.html'>stdlib_ctrexc</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q<strong>H, so that the diagonal element of T with row index IFST
is moved to row ILST.
The Schur form T is reordered by a unitary similarity transformation
Z</strong>H<em>T</em>Z, and optionally the matrix Q of Schur vectors is updated by
postmultplying it with Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrmm.html'>stdlib_ctrmm</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>B := alpha<em>op( A )</em>B,   or   B := alpha<em>B</em>op( A )
where  alpha  is a scalar,  B  is an m by n matrix,  A  is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A<strong>T   or   op( A ) = A</strong>H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrmv.html'>stdlib_ctrmv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrrfs.html'>stdlib_ctrrfs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular
coefficient matrix.
The solution matrix X must be computed by CTRTRS or some other
means before entering this routine.  CTRRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrsen.html'>stdlib_ctrsen</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q**H, so that a selected cluster of eigenvalues appears in
the leading positions on the diagonal of the upper triangular matrix
T, and the leading columns of Q form an orthonormal basis of the
corresponding right invariant subspace.
Optionally the routine computes the reciprocal condition numbers of
the cluster of eigenvalues and/or the invariant subspace.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrsm.html'>stdlib_ctrsm</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>op( A )<em>X = alpha</em>B,   or   X<em>op( A ) = alpha</em>B,
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A<strong>T   or   op( A ) = A</strong>H.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrsna.html'>stdlib_ctrsna</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>eigenvalues and/or right eigenvectors of a complex upper triangular
matrix T (or of any matrix Q<em>T</em>Q**H with Q unitary).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrsv.html'>stdlib_ctrsv</a></td><td><a href='../module/stdlib_linalg_blas_c.html'>stdlib_linalg_blas_c</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrsyl.html'>stdlib_ctrsyl</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>op(A)<em>X + X</em>op(B) = scale<em>C or
op(A)</em>X - X<em>op(B) = scale</em>C,
where op(A) = A or A**H, and A and B are both upper triangular. A is
M-by-M and B is N-by-N; the right hand side C and the solution X are
M-by-N; and scale is an output scale factor, set &lt;= 1 to avoid
overflow in X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrti2.html'>stdlib_ctrti2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix.
This is the Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrtri.html'>stdlib_ctrtri</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix A.
This is the Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrtrs.html'>stdlib_ctrtrs</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular matrix of order N, and B is an N-by-NRHS
matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrttf.html'>stdlib_ctrttf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF) .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctrttp.html'>stdlib_ctrttp</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ctzrzf.html'>stdlib_ctzrzf</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>to upper triangular form by means of unitary transformations.
The upper trapezoidal matrix A is factored as
A = ( R  0 ) * Z,
where Z is an N-by-N unitary matrix and R is an M-by-M upper
triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb.html'>stdlib_cunbdb</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>partitioned unitary matrix X:
[ B11 | B12 0  0 ]
[ X11 | X12 ]   [ P1 |    ] [  0  |  0 -I  0 ] [ Q1 |    ]**H
X = [-----------] = [---------] [----------------] [---------]   .
[ X21 | X22 ]   [    | P2 ] [ B21 | B22 0  0 ] [    | Q2 ]
[  0  |  0  0  I ]
X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is
not the case, then X must be transposed and/or permuted. This can be
done in constant time using the TRANS and SIGNS options. See CUNCSD
for details.)
The unitary matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by-
(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are
represented implicitly by Householder vectors.
B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb1.html'>stdlib_cunbdb1</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P,
M-P, or M-Q. Routines CUNBDB2, CUNBDB3, and CUNBDB4 handle cases in
which Q is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb2.html'>stdlib_cunbdb2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P,
Q, or M-Q. Routines CUNBDB1, CUNBDB3, and CUNBDB4 handle cases in
which P is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are P-by-P bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb3.html'>stdlib_cunbdb3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P,
Q, or M-Q. Routines CUNBDB1, CUNBDB2, and CUNBDB4 handle cases in
which M-P is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb4.html'>stdlib_cunbdb4</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P,
M-P, or Q. Routines CUNBDB1, CUNBDB2, and CUNBDB3 handle cases in
which M-Q is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb5.html'>stdlib_cunbdb5</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then some other vector from the orthogonal complement
is returned. This vector is chosen in an arbitrary but deterministic
way.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunbdb6.html'>stdlib_cunbdb6</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then the zero vector is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cuncsd.html'>stdlib_cuncsd</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>unitary matrix X:
[  I  0  0 |  0  0  0 ]
[  0  C  0 |  0 -S  0 ]
[ X11 | X12 ]   [ U1 |    ] [  0  0  0 |  0  0 -I ] [ V1 |    ]**H
X = [-----------] = [---------] [---------------------] [---------]   .
[ X21 | X22 ]   [    | U2 ] [  0  0  0 |  I  0  0 ] [    | V2 ]
[  0  S  0 |  0  C  0 ]
[  0  0  I |  0  0  0 ]
X11 is P-by-Q. The unitary matrices U1, U2, V1, and V2 are P-by-P,
(M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are
R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in
which R = MIN(P,M-P,Q,M-Q).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cuncsd2by1.html'>stdlib_cuncsd2by1</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>orthonormal columns that has been partitioned into a 2-by-1 block
structure:
[  I1 0  0 ]
[  0  C  0 ]
[ X11 ]   [ U1 |    ] [  0  0  0 ]
X = [-----] = [---------] [----------] V1**T .
[ X21 ]   [    | U2 ] [  0  0  0 ]
[  0  S  0 ]
[  0  0  I2]
X11 is P-by-Q. The unitary matrices U1, U2, and V1 are P-by-P,
(M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R
nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which
R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a
K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cung2l.html'>stdlib_cung2l</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the last n columns of a product of k elementary
reflectors of order m
Q  =  H(k) . . . H(2) H(1)
as returned by CGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cung2r.html'>stdlib_cung2r</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the first n columns of a product of k elementary
reflectors of order m
Q  =  H(1) H(2) . . . H(k)
as returned by CGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungbr.html'>stdlib_cungbr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>determined by CGEBRD when reducing a complex matrix A to bidiagonal
form: A = Q * B * P<strong>H.  Q and P</strong>H are defined as products of
elementary reflectors H(i) or G(i) respectively.
If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q
is of order M:
if m &gt;= k, Q = H(1) H(2) . . . H(k) and CUNGBR returns the first n
columns of Q, where m &gt;= n &gt;= k;
if m &lt; k, Q = H(1) H(2) . . . H(m-1) and CUNGBR returns Q as an
M-by-M matrix.
If VECT = 'P', A is assumed to have been a K-by-N matrix, and P<strong>H
is of order N:
if k &lt; n, P</strong>H = G(k) . . . G(2) G(1) and CUNGBR returns the first m
rows of P<strong>H, where n &gt;= m &gt;= k;
if k &gt;= n, P</strong>H = G(n-1) . . . G(2) G(1) and CUNGBR returns P**H as
an N-by-N matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunghr.html'>stdlib_cunghr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>product of IHI-ILO elementary reflectors of order N, as returned by
CGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungl2.html'>stdlib_cungl2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the first m rows of a product of k elementary
reflectors of order n
Q  =  H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by CGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunglq.html'>stdlib_cunglq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the first M rows of a product of K elementary
reflectors of order N
Q  =  H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by CGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungql.html'>stdlib_cungql</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the last N columns of a product of K elementary
reflectors of order M
Q  =  H(k) . . . H(2) H(1)
as returned by CGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungqr.html'>stdlib_cungqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the first N columns of a product of K elementary
reflectors of order M
Q  =  H(1) H(2) . . . H(k)
as returned by CGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungr2.html'>stdlib_cungr2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the last m rows of a product of k elementary
reflectors of order n
Q  =  H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by CGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungrq.html'>stdlib_cungrq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>which is defined as the last M rows of a product of K elementary
reflectors of order N
Q  =  H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by CGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungtr.html'>stdlib_cungtr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors of order N, as returned by
CHETRD:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungtsqr.html'>stdlib_cungtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>columns, which are the first N columns of a product of comlpex unitary
matrices of order M which are returned by CLATSQR
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
See the documentation for CLATSQR.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cungtsqr_row.html'>stdlib_cungtsqr_row</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>orthonormal columns from the output of CLATSQR. These N orthonormal
columns are the first N columns of a product of complex unitary
matrices Q(k)_in of order M, which are returned by CLATSQR in
a special format.
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
The input matrices Q(k)_in are stored in row and column blocks in A.
See the documentation of CLATSQR for more details on the format of
Q(k)_in, where each Q(k)_in is represented by block Householder
transformations. This routine calls an auxiliary routine CLARFB_GETT,
where the computation is performed on each individual block. The
algorithm first sweeps NB-sized column blocks from the right to left
starting in the bottom row block and continues to the top row block
(hence _ROW in the routine name). This sweep is in reverse order of
the order in which CLATSQR generates the output blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunhr_col.html'>stdlib_cunhr_col</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>as input, stored in A, and performs Householder Reconstruction (HR),
i.e. reconstructs Householder vectors V(i) implicitly representing
another M-by-N matrix Q_out, with the property that Q_in = Q_out*S,
where S is an N-by-N diagonal matrix with diagonal entries
equal to +1 or -1. The Householder vectors (columns V(i) of V) are
stored in A on output, and the diagonal entries of S are stored in D.
Block reflectors are also returned in T
(same output format as CGEQRT).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunm22.html'>stdlib_cunm22</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_cunm2l.html'>stdlib_cunm2l</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by CGEQLF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunm2r.html'>stdlib_cunm2r</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CGEQRF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmbr.html'>stdlib_cunmbr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>If VECT = 'Q', CUNMBR: overwrites the general complex M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
If VECT = 'P', CUNMBR overwrites the general complex M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      P * C          C * P
TRANS = 'C':      P<strong>H * C       C * P</strong>H
Here Q and P<strong>H are the unitary matrices determined by CGEBRD when
reducing a complex matrix A to bidiagonal form: A = Q * B * P</strong>H. Q
and P<strong>H are defined as products of elementary reflectors H(i) and
G(i) respectively.
Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the
order of the unitary matrix Q or P</strong>H that is applied.
If VECT = 'Q', A is assumed to have been an NQ-by-K matrix:
if nq &gt;= k, Q = H(1) H(2) . . . H(k);
if nq &lt; k, Q = H(1) H(2) . . . H(nq-1).
If VECT = 'P', A is assumed to have been a K-by-NQ matrix:
if k &lt; nq, P = G(1) G(2) . . . G(k);
if k &gt;= nq, P = G(1) G(2) . . . G(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmhr.html'>stdlib_cunmhr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
IHI-ILO elementary reflectors, as returned by CGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunml2.html'>stdlib_cunml2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by CGELQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmlq.html'>stdlib_cunmlq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by CGELQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmql.html'>stdlib_cunmql</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by CGEQLF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmqr.html'>stdlib_cunmqr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CGEQRF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmr2.html'>stdlib_cunmr2</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by CGERQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmr3.html'>stdlib_cunmr3</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CTZRZF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmrq.html'>stdlib_cunmrq</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by CGERQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmrz.html'>stdlib_cunmrz</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CTZRZF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cunmtr.html'>stdlib_cunmtr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by CHETRD:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cupgtr.html'>stdlib_cupgtr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors H(i) of order n, as returned by
CHPTRD using packed storage:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_cupmtr.html'>stdlib_cupmtr</a></td><td><a href='../module/stdlib_linalg_lapack_c.html'>stdlib_linalg_lapack_c</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by CHPTRD using packed
storage:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dasum.html'>stdlib_dasum</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_daxpy.html'>stdlib_daxpy</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>uses unrolled loops for increments equal to one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dbbcsd.html'>stdlib_dbbcsd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>bidiagonal-block form,
[ B11 | B12 0  0 ]
[  0  |  0 -I  0 ]
X = [----------------]
[ B21 | B22 0  0 ]
[  0  |  0  0  I ]
[  C | -S  0  0 ]
[ U1 |    ] [  0 |  0 -I  0 ] [ V1 |    ]**T
= [---------] [---------------] [---------]   .
[    | U2 ] [  S |  C  0  0 ] [    | V2 ]
[  0 |  0  0  I ]
X is M-by-M, its top-left block is P-by-Q, and Q must be no larger
than P, M-P, or M-Q. (If Q is not the smallest index, then X must be
transposed and/or permuted. This can be done in constant time using
the TRANS and SIGNS options. See DORCSD for details.)
The bidiagonal matrices B11, B12, B21, and B22 are represented
implicitly by angles THETA(1:Q) and PHI(1:Q-1).
The orthogonal matrices U1, U2, V1T, and V2T are input/output.
The input matrices are pre- or post-multiplied by the appropriate
singular vector matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dbdsdc.html'>stdlib_dbdsdc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>N-by-N (upper or lower) bidiagonal matrix B:  B = U * S * VT,
using a divide and conquer method, where S is a diagonal matrix
with non-negative diagonal elements (the singular values of B), and
U and VT are orthogonal matrices of left and right singular vectors,
respectively. DBDSDC can be used to compute all singular values,
and optionally, singular vectors or singular vectors in compact form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See DLASD3 for details.
The code currently calls DLASDQ if singular values only are desired.
However, it can be slightly modified to compute singular values
using the divide and conquer method.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dbdsqr.html'>stdlib_dbdsqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>left singular vectors from the singular value decomposition (SVD) of
a real N-by-N (upper or lower) bidiagonal matrix B using the implicit
zero-shift QR algorithm.  The SVD of B has the form
B = Q * S * P<strong>T
where S is the diagonal matrix of singular values, Q is an orthogonal
matrix of left singular vectors, and P is an orthogonal matrix of
right singular vectors.  If left singular vectors are requested, this
subroutine actually returns U*Q instead of Q, and, if right singular
vectors are requested, this subroutine returns P</strong>T<em>VT instead of
P</em><em>T, for given real input matrices U and VT.  When U and VT are the
orthogonal matrices that reduce a general matrix A to bidiagonal
form:  A = U</em>B<em>VT, as computed by DGEBRD, then
A = (U</em>Q) * S * (P<strong>T*VT)
is the SVD of A.  Optionally, the subroutine may also compute Q</strong>T*C
for a given real input matrix C.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3 (or SIAM J. Sci. Statist. Comput. vol. 11,
no. 5, pp. 873-912, Sept 1990) and
"Accurate singular values and differential qd algorithms," by
B. Parlett and V. Fernando, Technical Report CPAM-554, Mathematics
Department, University of California at Berkeley, July 1992
for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dcabs1.html'>stdlib_dcabs1</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_dcopy.html'>stdlib_dcopy</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>uses unrolled loops for increments equal to 1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ddisna.html'>stdlib_ddisna</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric or complex Hermitian matrix or for the left or
right singular vectors of a general m-by-n matrix. The reciprocal
condition number is the 'gap' between the corresponding eigenvalue or
singular value and the nearest other one.
The bound on the error, measured by angle in radians, in the I-th
computed vector is given by
DLAMCH( 'E' ) * ( ANORM / SEP( I ) )
where ANORM = 2-norm(A) = max( abs( D(j) ) ).  SEP(I) is not allowed
to be smaller than DLAMCH( 'E' )*ANORM in order to limit the size of
the error bound.
DDISNA may also be used to compute error bounds for eigenvectors of
the generalized symmetric definite eigenproblem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ddot.html'>stdlib_ddot</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Function</td><td><p>uses unrolled loops for increments equal to one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbbrd.html'>stdlib_dgbbrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>bidiagonal form B by an orthogonal transformation: Q<strong>T * A * P = B.
The routine computes B, and optionally forms Q or P</strong>T, or computes
Q*<em>T</em>C for a given matrix C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbcon.html'>stdlib_dgbcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>general band matrix A, in either the 1-norm or the infinity-norm,
using the LU factorization computed by DGBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbequ.html'>stdlib_dgbequ</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N band matrix A and reduce its condition number.  R returns the
row scale factors and C the column scale factors, chosen to try to
make the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbequb.html'>stdlib_dgbequb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from DGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbmv.html'>stdlib_dgbmv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<em><em>T</em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n band matrix, with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbrfs.html'>stdlib_dgbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is banded, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbsv.html'>stdlib_dgbsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B, where A is a band matrix of order N with KL subdiagonals
and KU superdiagonals, and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as A = L * U, where L is a product of permutation
and unit lower triangular matrices with KL subdiagonals, and U is
upper triangular with KL+KU superdiagonals.  The factored form of A
is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbsvx.html'>stdlib_dgbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B, A<strong>T * X = B, or A</strong>H * X = B,
where A is a band matrix of order N with KL subdiagonals and KU
superdiagonals, and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbtf2.html'>stdlib_dgbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbtrf.html'>stdlib_dgbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgbtrs.html'>stdlib_dgbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B
with a general band matrix A using the LU factorization computed
by DGBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgebak.html'>stdlib_dgebak</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>by backward transformation on the computed eigenvectors of the
balanced matrix output by DGEBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgebal.html'>stdlib_dgebal</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>permuting A by a similarity transformation to isolate eigenvalues
in the first 1 to ILO-1 and last IHI+1 to N elements on the
diagonal; and second, applying a diagonal similarity transformation
to rows and columns ILO to IHI to make the rows and columns as
close in norm as possible.  Both steps are optional.
Balancing may reduce the 1-norm of the matrix, and improve the
accuracy of the computed eigenvalues and/or eigenvectors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgebd2.html'>stdlib_dgebd2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>bidiagonal form B by an orthogonal transformation: Q**T * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgebrd.html'>stdlib_dgebrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>bidiagonal form B by an orthogonal transformation: Q**T * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgecon.html'>stdlib_dgecon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real matrix A, in either the 1-norm or the infinity-norm, using
the LU factorization computed by DGETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeequ.html'>stdlib_dgeequ</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeequb.html'>stdlib_dgeequb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from DGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgees.html'>stdlib_dgees</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues, the real Schur form T, and, optionally, the matrix of
Schur vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z*<em>T).
Optionally, it also orders the eigenvalues on the diagonal of the
real Schur form so that selected eigenvalues are at the top left.
The leading columns of Z then form an orthonormal basis for the
invariant subspace corresponding to the selected eigenvalues.
A matrix is in real Schur form if it is upper quasi-triangular with
1-by-1 and 2-by-2 blocks. 2-by-2 blocks will be standardized in the
form
[  a  b  ]
[  c  a  ]
where b</em>c &lt; 0. The eigenvalues of such a block are a +- sqrt(bc).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeesx.html'>stdlib_dgeesx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues, the real Schur form T, and, optionally, the matrix of
Schur vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z*<em>T).
Optionally, it also orders the eigenvalues on the diagonal of the
real Schur form so that selected eigenvalues are at the top left;
computes a reciprocal condition number for the average of the
selected eigenvalues (RCONDE); and computes a reciprocal condition
number for the right invariant subspace corresponding to the
selected eigenvalues (RCONDV).  The leading columns of Z form an
orthonormal basis for this invariant subspace.
For further explanation of the reciprocal condition numbers RCONDE
and RCONDV, see Section 4.10_dp of the LAPACK Users' Guide (where
these quantities are called s and sep respectively).
A real matrix is in real Schur form if it is upper quasi-triangular
with 1-by-1 and 2-by-2 blocks. 2-by-2 blocks will be standardized in
the form
[  a  b  ]
[  c  a  ]
where b</em>c &lt; 0. The eigenvalues of such a block are a +- sqrt(bc).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeev.html'>stdlib_dgeev</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)**H denotes the conjugate-transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeevx.html'>stdlib_dgeevx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
Optionally also, it computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
SCALE, and ABNRM), reciprocal condition numbers for the eigenvalues
(RCONDE), and reciprocal condition numbers for the right
eigenvectors (RCONDV).
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)<strong>H denotes the conjugate-transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.
Balancing a matrix means permuting the rows and columns to make it
more nearly upper triangular, and applying a diagonal similarity
transformation D * A * D</strong>(-1), where D is a diagonal matrix, to
make its rows and columns closer in norm and the condition numbers
of its eigenvalues and eigenvectors smaller.  The computed
reciprocal condition numbers correspond to the balanced matrix.
Permuting rows and columns will not change the condition numbers
(in exact arithmetic) but diagonal scaling will.  For further
explanation of balancing, see section 4.10.2_dp of the LAPACK
Users' Guide.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgehd2.html'>stdlib_dgehd2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>an orthogonal similarity transformation:  Q**T * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgehrd.html'>stdlib_dgehrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>an orthogonal similarity transformation:  Q**T * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgejsv.html'>stdlib_dgejsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix [A], where M &gt;= N. The SVD of [A] is written as
[A] = [U] * [SIGMA] * [V]^t,
where [SIGMA] is an N-by-N (M-by-N) matrix which is zero except for its N
diagonal elements, [U] is an M-by-N (or M-by-M) orthonormal matrix, and
[V] is an N-by-N orthogonal matrix. The diagonal elements of [SIGMA] are
the singular values of [A]. The columns of [U] and [V] are the left and
the right singular vectors of [A], respectively. The matrices [U] and [V]
are computed and stored in the arrays U and V, respectively. The diagonal
of [SIGMA] is computed and stored in the array SVA.
DGEJSV can sometimes compute tiny singular values and their singular vectors much
more accurately than other SVD routines, see below under Further Details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelq.html'>stdlib_dgelq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelq2.html'>stdlib_dgelq2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a n-by-n orthogonal matrix;
L is a lower-triangular m-by-m matrix;
0 is a m-by-(n-m) zero matrix, if m &lt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelqf.html'>stdlib_dgelqf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelqt.html'>stdlib_dgelqt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelqt3.html'>stdlib_dgelqt3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgels.html'>stdlib_dgels</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, or its transpose, using a QR or LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'T' and m &gt;= n:  find the minimum norm solution of
an underdetermined system A</em><em>T * X = B.
4. If TRANS = 'T' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelsd.html'>stdlib_dgelsd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>squares problem:
minimize 2-norm(| b - A*x |)
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The problem is solved in three steps:
(1) Reduce the coefficient matrix A to bidiagonal form with
Householder transformations, reducing the original problem
into a "bidiagonal least squares problem" (BLS)
(2) Solve the BLS using a divide and conquer approach.
(3) Apply back all the Householder transformations to solve
the original least squares problem.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelss.html'>stdlib_dgelss</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>squares problem:
Minimize 2-norm(| b - A*x |).
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix
X.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgelsy.html'>stdlib_dgelsy</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>squares problem:
minimize || A * X - B ||
using a complete orthogonal factorization of A.  A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The routine first computes a QR factorization with column pivoting:
A * P = Q * [ R11 R12 ]
[  0  R22 ]
with R11 defined as the largest leading submatrix whose estimated
condition number is less than 1/RCOND.  The order of R11, RANK,
is the effective rank of A.
Then, R22 is considered to be negligible, and R12 is annihilated
by orthogonal transformations from the right, arriving at the
complete orthogonal factorization:
A * P = Q * [ T11 0 ] * Z
[  0  0 ]
The minimum-norm solution is then
X = P * Z<strong>T [ inv(T11)*Q1</strong>T*B ]
[        0         ]
where Q1 consists of the first RANK columns of Q.
This routine is basically identical to the original xGELSX except
three differences:
o The call to the subroutine xGEQPF has been substituted by the
the call to the subroutine xGEQP3. This subroutine is a Blas-3
version of the QR factorization with column pivoting.
o Matrix B (the right hand side) is updated with Blas-3.
o The permutation of matrix B (the right hand side) is faster and
more simple.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgemlq.html'>stdlib_dgemlq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product
of blocked elementary reflectors computed by short wide LQ
factorization (DGELQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgemlqt.html'>stdlib_dgemlqt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'T':   Q<strong>T C            C Q</strong>T
where Q is a real orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**T
generated using the compact WY representation as returned by DGELQT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgemm.html'>stdlib_dgemm</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>C := alpha<em>op( A )</em>op( B ) + beta<em>C,
where  op( X ) is one of
op( X ) = X   or   op( X ) = X</em>*T,
alpha and beta are scalars, and A, B and C are matrices, with op( A )
an m by k matrix,  op( B )  a  k by n matrix and  C an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgemqr.html'>stdlib_dgemqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (DGEQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgemqrt.html'>stdlib_dgemqrt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'T':   Q<strong>T C            C Q</strong>T
where Q is a real orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**T
generated using the compact WY representation as returned by DGEQRT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgemv.html'>stdlib_dgemv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<em><em>T</em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeql2.html'>stdlib_dgeql2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqlf.html'>stdlib_dgeqlf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqp3.html'>stdlib_dgeqp3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A:  A<em>P = Q</em>R  using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqr.html'>stdlib_dgeqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqr2.html'>stdlib_dgeqr2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqr2p.html'>stdlib_dgeqr2p</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix with nonnegative diagonal
entries;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqrf.html'>stdlib_dgeqrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqrfp.html'>stdlib_dgeqrfp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DGEQR2P computes a QR factorization of a real M-by-N matrix A:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix with nonnegative diagonal
entries;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqrt.html'>stdlib_dgeqrt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqrt2.html'>stdlib_dgeqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgeqrt3.html'>stdlib_dgeqrt3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dger.html'>stdlib_dger</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y**T + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgerfs.html'>stdlib_dgerfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations and provides error bounds and backward error estimates for
the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgerq2.html'>stdlib_dgerq2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgerqf.html'>stdlib_dgerqf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesc2.html'>stdlib_dgesc2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = scale* RHS
with a general N-by-N matrix A using the LU factorization with
complete pivoting computed by DGETC2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesdd.html'>stdlib_dgesdd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and right singular
vectors.  If singular vectors are desired, it uses a
divide-and-conquer algorithm.
The SVD is written
A = U * SIGMA * transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M orthogonal matrix, and
V is an N-by-N orthogonal matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns VT = V**T, not V.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesv.html'>stdlib_dgesv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as
A = P * L * U,
where P is a permutation matrix, L is unit lower triangular, and U is
upper triangular.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesvd.html'>stdlib_dgesvd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors. The SVD is written
A = U * SIGMA * transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M orthogonal matrix, and
V is an N-by-N orthogonal matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns V**T, not V.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesvdq.html'>stdlib_dgesvdq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N orthogonal matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesvj.html'>stdlib_dgesvj</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^t,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N orthogonal matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.
DGESVJ can sometimes compute tiny singular values and their singular vectors much
more accurately than other SVD routines, see below under Further Details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgesvx.html'>stdlib_dgesvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>system of linear equations
A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetc2.html'>stdlib_dgetc2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>n-by-n matrix A. The factorization has the form A = P * L * U * Q,
where P and Q are permutation matrices, L is lower triangular with
unit diagonal elements and U is upper triangular.
This is the Level 2 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetf2.html'>stdlib_dgetf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetrf.html'>stdlib_dgetrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetrf2.html'>stdlib_dgetrf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = min(m,n)/2
[  A21 | A22  ]       n2 = n-n1
[ A11 ]
The subroutine calls itself to factor [ --- ],
[ A12 ]
[ A12 ]
do the swaps on [ --- ], solve A12, update A22,
[ A22 ]
then calls itself to factor A22 and do the swaps on A21.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetri.html'>stdlib_dgetri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>computed by DGETRF.
This method inverts U and then computes inv(A) by solving the system
inv(A)*L = inv(U) for inv(A).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetrs.html'>stdlib_dgetrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B
with a general N-by-N matrix A using the LU factorization computed
by DGETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetsls.html'>stdlib_dgetsls</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, using a tall skinny QR or short wide LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'T' and m &gt;= n:  find the minimum norm solution of
an undetermined system A</em><em>T * X = B.
4. If TRANS = 'T' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgetsqrhrt.html'>stdlib_dgetsqrhrt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real M-by-N matrix A with M &gt;= N,
A = Q * R.
The routine uses internally a NB1-sized column blocked and MB1-sized
row blocked TSQR-factorization and perfors the reconstruction
of the Householder vectors from the TSQR output. The routine also
converts the R_tsqr factor from the TSQR-factorization output into
the R factor that corresponds to the Householder QR-factorization,
A = Q_tsqr * R_tsqr = Q * R.
The output Q and R factors are stored in the same format as in DGEQRT
(Q is in blocked compact WY-representation). See the documentation
of DGEQRT for more details on the format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggbak.html'>stdlib_dggbak</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalue problem A<em>x = lambda</em>B*x, by backward transformation on
the computed eigenvectors of the balanced pair of matrices output by
DGGBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggbal.html'>stdlib_dggbal</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>involves, first, permuting A and B by similarity transformations to
isolate eigenvalues in the first 1 to ILO$-$1 and last IHI+1 to N
elements on the diagonal; and second, applying a diagonal similarity
transformation to rows and columns ILO to IHI to make the rows
and columns as close in norm as possible. Both steps are optional.
Balancing may reduce the 1-norm of the matrices, and improve the
accuracy of the computed eigenvalues and/or eigenvectors in the
generalized eigenvalue problem A<em>x = lambda</em>B*x.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgges.html'>stdlib_dgges</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, the generalized real Schur form (S,T),
optionally, the left and/or right matrices of Schur vectors (VSL and
VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>T, (VSL)<em>T</em>(VSR)</strong>T )
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
quasi-triangular matrix S and the upper triangular matrix T.The
leading columns of VSL and VSR then form an orthonormal basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
DGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w*B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or both being zero.
A pair of matrices (S,T) is in generalized real Schur form if T is
upper triangular with non-negative diagonal and S is block upper
triangular with 1-by-1 and 2-by-2 blocks.  1-by-1 blocks correspond
to real generalized eigenvalues, while 2-by-2 blocks of S will be
"standardized" by making the corresponding elements of T have the
form:
[  a  0  ]
[  0  b  ]
and the pair of corresponding 2-by-2 blocks in S and T will have a
complex conjugate pair of generalized eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgges3.html'>stdlib_dgges3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, the generalized real Schur form (S,T),
optionally, the left and/or right matrices of Schur vectors (VSL and
VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>T, (VSL)<em>T</em>(VSR)</strong>T )
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
quasi-triangular matrix S and the upper triangular matrix T.The
leading columns of VSL and VSR then form an orthonormal basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
DGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w*B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or both being zero.
A pair of matrices (S,T) is in generalized real Schur form if T is
upper triangular with non-negative diagonal and S is block upper
triangular with 1-by-1 and 2-by-2 blocks.  1-by-1 blocks correspond
to real generalized eigenvalues, while 2-by-2 blocks of S will be
"standardized" by making the corresponding elements of T have the
form:
[  a  0  ]
[  0  b  ]
and the pair of corresponding 2-by-2 blocks in S and T will have a
complex conjugate pair of generalized eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggesx.html'>stdlib_dggesx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the real Schur form (S,T), and,
optionally, the left and/or right matrices of Schur vectors (VSL and
VSR).  This gives the generalized Schur factorization
(A,B) = ( (VSL) S (VSR)<strong>T, (VSL) T (VSR)</strong>T )
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
quasi-triangular matrix S and the upper triangular matrix T; computes
a reciprocal condition number for the average of the selected
eigenvalues (RCONDE); and computes a reciprocal condition number for
the right and left deflating subspaces corresponding to the selected
eigenvalues (RCONDV). The leading columns of VSL and VSR then form
an orthonormal basis for the corresponding left and right eigenspaces
(deflating subspaces).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w*B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or for both being zero.
A pair of matrices (S,T) is in generalized real Schur form if T is
upper triangular with non-negative diagonal and S is block upper
triangular with 1-by-1 and 2-by-2 blocks.  1-by-1 blocks correspond
to real generalized eigenvalues, while 2-by-2 blocks of S will be
"standardized" by making the corresponding elements of T have the
form:
[  a  0  ]
[  0  b  ]
and the pair of corresponding 2-by-2 blocks in S and T will have a
complex conjugate pair of generalized eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggev.html'>stdlib_dggev</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, and optionally, the left and/or right
generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B .
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggev3.html'>stdlib_dggev3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, and optionally, the left and/or right
generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B .
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggevx.html'>stdlib_dggevx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, and optionally, the left and/or right
generalized eigenvectors.
Optionally also, it computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
LSCALE, RSCALE, ABNRM, and BBNRM), reciprocal condition numbers for
the eigenvalues (RCONDE), and reciprocal condition numbers for the
right eigenvectors (RCONDV).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j) .
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B.
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggglm.html'>stdlib_dggglm</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>minimize || y ||_2   subject to   d = A<em>x + B</em>y
x
where A is an N-by-M matrix, B is an N-by-P matrix, and d is a
given N-vector. It is assumed that M &lt;= N &lt;= M+P, and
rank(A) = M    and    rank( A B ) = N.
Under these assumptions, the constrained equation is always
consistent, and there is a unique solution x and a minimal 2-norm
solution y, which is obtained using a generalized QR factorization
of the matrices (A, B) given by
A = Q<em>(R),   B = Q</em>T<em>Z.
(0)
In particular, if matrix B is square nonsingular, then the problem
GLM is equivalent to the following weighted linear least squares
problem
minimize || inv(B)</em>(d-A*x) ||_2
x
where inv(B) denotes the inverse of B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgghd3.html'>stdlib_dgghd3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Hessenberg form using orthogonal transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the orthogonal matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>T</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>T</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>T*x.
The orthogonal matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>T = (Q1<em>Q) * H * (Z1</em>Z)<strong>T
Q1 * B * Z1</strong>T = (Q1<em>Q) * T * (Z1</em>Z)<em><em>T
If Q1 is the orthogonal matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then DGGHD3 reduces the original
problem to generalized Hessenberg form.
This is a blocked variant of DGGHRD, using matrix-matrix
multiplications for parts of the computation to enhance performance.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgghrd.html'>stdlib_dgghrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Hessenberg form using orthogonal transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the orthogonal matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>T</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>T</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>T*x.
The orthogonal matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>T = (Q1<em>Q) * H * (Z1</em>Z)<strong>T
Q1 * B * Z1</strong>T = (Q1<em>Q) * T * (Z1</em>Z)<em><em>T
If Q1 is the orthogonal matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then DGGHRD reduces the original
problem to generalized Hessenberg form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgglse.html'>stdlib_dgglse</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>minimize || c - A<em>x ||_2   subject to   B</em>x = d
where A is an M-by-N matrix, B is a P-by-N matrix, c is a given
M-vector, and d is a given P-vector. It is assumed that
P &lt;= N &lt;= M+P, and
rank(B) = P and  rank( (A) ) = N.
( (B) )
These conditions ensure that the LSE problem has a unique solution,
which is obtained using a generalized RQ factorization of the
matrices (B, A) given by
B = (0 R)<em>Q,   A = Z</em>T*Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggqrf.html'>stdlib_dggqrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>and an N-by-P matrix B:
A = Q<em>R,        B = Q</em>T<em>Z,
where Q is an N-by-N orthogonal matrix, Z is a P-by-P orthogonal
matrix, and R and T assume one of the forms:
if N &gt;= M,  R = ( R11 ) M  ,   or if N &lt; M,  R = ( R11  R12 ) N,
(  0  ) N-M                         N   M-N
M
where R11 is upper triangular, and
if N &lt;= P,  T = ( 0  T12 ) N,   or if N &gt; P,  T = ( T11 ) N-P,
P-N  N                           ( T21 ) P
P
where T12 or T21 is upper triangular.
In particular, if B is square and nonsingular, the GQR factorization
of A and B implicitly gives the QR factorization of inv(B)</em>A:
inv(B)<em>A = Z</em><em>T</em>(inv(T)<em>R)
where inv(B) denotes the inverse of the matrix B, and Z</em>*T denotes the
transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dggrqf.html'>stdlib_dggrqf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>and a P-by-N matrix B:
A = R<em>Q,        B = Z</em>T<em>Q,
where Q is an N-by-N orthogonal matrix, Z is a P-by-P orthogonal
matrix, and R and T assume one of the forms:
if M &lt;= N,  R = ( 0  R12 ) M,   or if M &gt; N,  R = ( R11 ) M-N,
N-M  M                           ( R21 ) N
N
where R12 or R21 is upper triangular, and
if P &gt;= N,  T = ( T11 ) N  ,   or if P &lt; N,  T = ( T11  T12 ) P,
(  0  ) P-N                         P   N-P
N
where T11 is upper triangular.
In particular, if B is square and nonsingular, the GRQ factorization
of A and B implicitly gives the RQ factorization of A</em>inv(B):
A<em>inv(B) = (R</em>inv(T))<em>Z</em><em>T
where inv(B) denotes the inverse of the matrix B, and Z</em>*T denotes the
transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgsvj0.html'>stdlib_dgsvj0</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as DGESVJ does, but
it does not check convergence (stopping criterion). Few tuning
parameters (marked by [TP]) are available for the implementer.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgsvj1.html'>stdlib_dgsvj1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as DGESVJ does, but
it targets only particular pivots and it does not check convergence
(stopping criterion). Few tuning parameters (marked by [TP]) are
available for the implementer.
Further Details
~~~~~~~~~~~~~~~
DGSVJ1 applies few sweeps of Jacobi rotations in the column space of
the input M-by-N matrix A. The pivot pairs are taken from the (1,2)
off-diagonal block in the corresponding N-by-N Gram matrix A^T * A. The
block-entries (tiles) of the (1,2) off-diagonal block are marked by the
[x]'s in the following scheme:
| *  *  * [x] [x] [x]|
| *  *  * [x] [x] [x]|    Row-cycling in the nblr-by-nblc [x] blocks.
| *  *  * [x] [x] [x]|    Row-cyclic pivoting inside each [x] block.
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
In terms of the columns of A, the first N1 columns are rotated 'against'
the remaining N-N1 columns, trying to increase the angle between the
corresponding subspaces. The off-diagonal block is N1-by(N-N1) and it is
tiled using quadratic tiles of side KBL. Here, KBL is a tuning parameter.
The number of sweeps is given in NSWEEP and the orthogonality threshold
is given in TOL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgtcon.html'>stdlib_dgtcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>tridiagonal matrix A using the LU factorization as computed by
DGTTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgtrfs.html'>stdlib_dgtrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is tridiagonal, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgtsv.html'>stdlib_dgtsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A<em>X = B,
where A is an n by n tridiagonal matrix, by Gaussian elimination with
partial pivoting.
Note that the equation  A</em><em>T</em>X = B  may be solved by interchanging the
order of the arguments DU and DL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgtsvx.html'>stdlib_dgtsvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B or A**T * X = B,
where A is a tridiagonal matrix of order N and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgttrf.html'>stdlib_dgttrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using elimination with partial pivoting and row interchanges.
The factorization has the form
A = L * U
where L is a product of permutation and unit lower bidiagonal
matrices and U is upper triangular with nonzeros in only the main
diagonal and first two superdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgttrs.html'>stdlib_dgttrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A<em>X = B  or  A</em><em>T</em>X = B,
with a tridiagonal matrix A using the LU factorization computed
by DGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dgtts2.html'>stdlib_dgtts2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A<em>X = B  or  A</em><em>T</em>X = B,
with a tridiagonal matrix A using the LU factorization computed
by DGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dhgeqz.html'>stdlib_dhgeqz</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a real matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>T,  B = Q1<em>T</em>Z1</strong>T,
as computed by DGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>T,  T = Q<em>P</em>Z</strong>T,
where Q and Z are orthogonal matrices, P is an upper triangular
matrix, and S is a quasi-triangular matrix with 1-by-1 and 2-by-2
diagonal blocks.
The 1-by-1 blocks correspond to real eigenvalues of the matrix pair
(H,T) and the 2-by-2 blocks correspond to complex conjugate pairs of
eigenvalues.
Additionally, the 2-by-2 upper triangular diagonal blocks of P
corresponding to 2-by-2 blocks of S are reduced to positive diagonal
form, i.e., if S(j+1,j) is non-zero, then P(j+1,j) = P(j,j+1) = 0,
P(j,j) &gt; 0, and P(j+1,j+1) &gt; 0.
Optionally, the orthogonal matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
orthogonal matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the orthogonal matrices from DGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the orthogonal factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>T,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>T.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Real eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dhsein.html'>stdlib_dhsein</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvectors of a real upper Hessenberg matrix H.
The right eigenvector x and the left eigenvector y of the matrix H
corresponding to an eigenvalue w are defined by:
H * x = w * x,     y<strong>h * H = w * y</strong>h
where y**h denotes the conjugate transpose of the vector y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dhseqr.html'>stdlib_dhseqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>T, where T is an upper quasi-triangular matrix (the
Schur form), and Z is the orthogonal matrix of Schur vectors.
Optionally Z may be postmultiplied into an input orthogonal
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the orthogonal matrix Q:  A = Q<em>H</em>Q</strong>T = (QZ)<em>T</em>(QZ)**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_disnan.html'>stdlib_disnan</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>otherwise.  To be replaced by the Fortran 2003 intrinsic in the
future.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_gbamv.html'>stdlib_dla_gbamv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_gbrcond.html'>stdlib_dla_gbrcond</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number  cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_gbrpvgrw.html'>stdlib_dla_gbrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_geamv.html'>stdlib_dla_geamv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_gercond.html'>stdlib_dla_gercond</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_gerpvgrw.html'>stdlib_dla_gerpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_lin_berr.html'>stdlib_dla_lin_berr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the formula
max(i) ( abs(R(i)) / ( abs(op(A_s))*abs(Y) + abs(B_s) )(i) )
where abs(Z) is the component-wise absolute value of the matrix
or vector Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_porcond.html'>stdlib_dla_porcond</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number  cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_porpvgrw.html'>stdlib_dla_porpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_syamv.html'>stdlib_dla_syamv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_syrcond.html'>stdlib_dla_syrcond</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_syrpvgrw.html'>stdlib_dla_syrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dla_wwaddw.html'>stdlib_dla_wwaddw</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>This works for all extant IBM's hex and binary floating point
arithmetic, but not for decimal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlabad.html'>stdlib_dlabad</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>overflow, and returns the square root of each of these values if the
log of LARGE is sufficiently large.  This subroutine is intended to
identify machines with a large exponent range, such as the Crays, and
redefine the underflow and overflow limits to be the square roots of
the values computed by DLAMCH.  This subroutine is needed because
DLAMCH does not compensate for poor arithmetic in the upper half of
the exponent range, as is found on a Cray.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlabrd.html'>stdlib_dlabrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>m by n matrix A to upper or lower bidiagonal form by an orthogonal
transformation Q**T * A * P, and returns the matrices X and Y which
are needed to apply the transformation to the unreduced part of A.
If m &gt;= n, A is reduced to upper bidiagonal form; if m &lt; n, to lower
bidiagonal form.
This is an auxiliary routine called by DGEBRD</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlacn2.html'>stdlib_dlacn2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlacon.html'>stdlib_dlacon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlacpy.html'>stdlib_dlacpy</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dladiv.html'>stdlib_dladiv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a + i<em>b
p + i</em>q = ---------
c + i*d
The algorithm is due to Michael Baudin and Robert L. Smith
and can be found in the paper
"A Robust Complex Division in Scilab"</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dladiv1.html'>stdlib_dladiv1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_dladiv2.html'>stdlib_dladiv2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_dlae2.html'>stdlib_dlae2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>[  A   B  ]
[  B   C  ].
On return, RT1 is the eigenvalue of larger absolute value, and RT2
is the eigenvalue of smaller absolute value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaebz.html'>stdlib_dlaebz</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>function N(w), which is the count of eigenvalues of a symmetric
tridiagonal matrix T less than or equal to its argument  w.  It
performs a choice of two types of loops:
IJOB=1, followed by
IJOB=2: It takes as input a list of intervals and returns a list of
sufficiently small intervals whose union contains the same
eigenvalues as the union of the original intervals.
The input intervals are (AB(j,1),AB(j,2)], j=1,...,MINP.
The output interval (AB(j,1),AB(j,2)] will contain
eigenvalues NAB(j,1)+1,...,NAB(j,2), where 1 &lt;= j &lt;= MOUT.
IJOB=3: It performs a binary search in each input interval
(AB(j,1),AB(j,2)] for a point  w(j)  such that
N(w(j))=NVAL(j), and uses  C(j)  as the starting point of
the search.  If such a w(j) is found, then on output
AB(j,1)=AB(j,2)=w.  If no such w(j) is found, then on output
(AB(j,1),AB(j,2)] will be a small interval containing the
point where N(w) jumps through NVAL(j), unless that point
lies outside the initial interval.
Note that the intervals are in all cases half-open intervals,
i.e., of the form  (a,b] , which includes  b  but not  a .
To avoid underflow, the matrix should be scaled so that its largest
element is no greater than  overflow<strong>(1/2) * underflow</strong>(1/4)
in absolute value.  To assure the most accurate computation
of small eigenvalues, the matrix should be scaled to be
not much smaller than that, either.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966
Note: the arguments are, in general, <em>not</em> checked for unreasonable
values.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed0.html'>stdlib_dlaed0</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed1.html'>stdlib_dlaed1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix after modification by a rank-one symmetric matrix.  This
routine is used only for the eigenproblem which requires all
eigenvalues and eigenvectors of a tridiagonal matrix.  DLAED7 handles
the case in which eigenvalues only or eigenvalues and eigenvectors
of a full symmetric matrix (which was reduced to tridiagonal form)
are desired.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>T ) Q</em><em>T(in) = Q(out) * D(out) * Q</em><em>T(out)
where Z = Q</em><em>T</em>u, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine DLAED2.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine DLAED4 (as called by DLAED3).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed2.html'>stdlib_dlaed2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny entry in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed3.html'>stdlib_dlaed3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>values in D, W, and RHO, between 1 and K.  It makes the
appropriate calls to DLAED4 and then updates the eigenvectors by
multiplying the matrix of eigenvectors of the pair of eigensystems
being combined by the matrix of eigenvectors of the K-by-K system
which is solved here.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed4.html'>stdlib_dlaed4</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>This subroutine computes the I-th updated eigenvalue of a symmetric
rank-one modification to a diagonal matrix whose elements are
given in the array d, and that
D(i) &lt; D(j)  for  i &lt; j
and that RHO &gt; 0.  This is arranged by the calling routine, and is
no loss in generality.  The rank-one modified system is thus
diag( D )  +  RHO * Z * Z_transpose.
where we assume the Euclidean norm of Z is 1.
The method consists of approximating the rational functions in the
secular equation by simpler interpolating rational functions.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed5.html'>stdlib_dlaed5</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>This subroutine computes the I-th eigenvalue of a symmetric rank-one
modification of a 2-by-2 diagonal matrix
diag( D )  +  RHO * Z * transpose(Z) .
The diagonal elements in the array D are assumed to satisfy
D(i) &lt; D(j)  for  i &lt; j .
We also assume RHO &gt; 0 and that the Euclidean norm of the vector
Z is one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed6.html'>stdlib_dlaed6</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of
z(1)        z(2)        z(3)
f(x) =   rho + --------- + ---------- + ---------
d(1)-x      d(2)-x      d(3)-x
It is assumed that
if ORGATI = .true. the root is between d(2) and d(3);
otherwise it is between d(1) and d(2)
This routine will be called by DLAED4 when necessary. In most cases,
the root sought is the smallest in magnitude, though it might not be
in some extremely rare situations.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed7.html'>stdlib_dlaed7</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix after modification by a rank-one symmetric matrix. This
routine is used only for the eigenproblem which requires all
eigenvalues and optionally eigenvectors of a dense symmetric matrix
that has been reduced to tridiagonal form.  DLAED1 handles
the case in which all eigenvalues and eigenvectors of a symmetric
tridiagonal matrix are desired.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>T ) Q</em><em>T(in) = Q(out) * D(out) * Q</em><em>T(out)
where Z = Q</em>*Tu, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine DLAED8.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine DLAED4 (as called by DLAED9).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed8.html'>stdlib_dlaed8</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny element in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaed9.html'>stdlib_dlaed9</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>values in D, Z, and RHO, between KSTART and KSTOP.  It makes the
appropriate calls to DLAED4 and then stores the new matrix of
eigenvectors for use in calculating the next level of Z vectors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaeda.html'>stdlib_dlaeda</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>CURLVLth step of the merge process with TLVLS steps for the CURPBMth
problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaein.html'>stdlib_dlaein</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>corresponding to the eigenvalue (WR,WI) of a real upper Hessenberg
matrix H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaev2.html'>stdlib_dlaev2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>[  A   B  ]
[  B   C  ].
On return, RT1 is the eigenvalue of larger absolute value, RT2 is the
eigenvalue of smaller absolute value, and (CS1,SN1) is the unit right
eigenvector for RT1, giving the decomposition
[ CS1  SN1 ] [  A   B  ] [ CS1 -SN1 ]  =  [ RT1  0  ]
[-SN1  CS1 ] [  B   C  ] [ SN1  CS1 ]     [  0  RT2 ].</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaexc.html'>stdlib_dlaexc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>an upper quasi-triangular matrix T by an orthogonal similarity
transformation.
T must be in Schur canonical form, that is, block upper triangular
with 1-by-1 and 2-by-2 diagonal blocks; each 2-by-2 diagonal block
has its diagonal elements equal and its off-diagonal elements of
opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlag2.html'>stdlib_dlag2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>problem  A - w B, with scaling as necessary to avoid over-/underflow.
The scaling factor "s" results in a modified eigenvalue equation
s A - w B
where  s  is a non-negative scaling factor chosen so that  w,  w B,
and  s A  do not overflow and, if possible, do not underflow, either.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlag2s.html'>stdlib_dlag2s</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>PRECISION matrix, A.
RMAX is the overflow for the SINGLE PRECISION arithmetic
DLAG2S checks that all the entries of A are between -RMAX and
RMAX. If not the conversion is aborted and a flag is raised.
This is an auxiliary routine so there is no argument checking.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlags2.html'>stdlib_dlags2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>that if ( UPPER ) then
U<strong>T <em>A</em>Q = U</strong>T <em>( A1 A2 )</em>Q = ( x  0  )
( 0  A3 )     ( x  x  )
and
V<strong>T<em>B</em>Q = V</strong>T <em>( B1 B2 )</em>Q = ( x  0  )
( 0  B3 )     ( x  x  )
or if ( .NOT.UPPER ) then
U<strong>T <em>A</em>Q = U</strong>T <em>( A1 0  )</em>Q = ( x  x  )
( A2 A3 )     ( 0  x  )
and
V<strong>T<em>B</em>Q = V</strong>T<em>( B1 0  )</em>Q = ( x  x  )
( B2 B3 )     ( 0  x  )
The rows of the transformed A and B are parallel, where
U = (  CSU  SNU ), V = (  CSV SNV ), Q = (  CSQ   SNQ )
( -SNU  CSU )      ( -SNV CSV )      ( -SNQ   CSQ )
Z**T denotes the transpose of Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlagtf.html'>stdlib_dlagtf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>tridiagonal matrix and lambda is a scalar, as
T - lambda*I = PLU,
where P is a permutation matrix, L is a unit lower tridiagonal matrix
with at most one non-zero sub-diagonal elements per column and U is
an upper triangular matrix with at most two non-zero super-diagonal
elements per column.
The factorization is obtained by Gaussian elimination with partial
pivoting and implicit row scaling.
The parameter LAMBDA is included in the routine so that DLAGTF may
be used, in conjunction with DLAGTS, to obtain eigenvectors of T by
inverse iteration.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlagtm.html'>stdlib_dlagtm</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>B := alpha * A * X + beta * B
where A is a tridiagonal matrix of order N, B and X are N by NRHS
matrices, and alpha and beta are real scalars, each of which may be
0., 1., or -1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlagts.html'>stdlib_dlagts</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>(T - lambda<em>I)</em>x = y   or   (T - lambda<em>I)</em><em>T</em>x = y,
where T is an n by n tridiagonal matrix, for x, following the
factorization of (T - lambda<em>I) as
(T - lambda</em>I) = P<em>L</em>U ,
by routine DLAGTF. The choice of equation to be solved is
controlled by the argument JOB, and in each case there is an option
to perturb zero or very small diagonal elements of U, this option
being intended for use in applications such as inverse iteration.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlagv2.html'>stdlib_dlagv2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix pencil (A,B) where B is upper triangular. This routine
computes orthogonal (rotation) matrices given by CSL, SNL and CSR,
SNR such that
1) if the pencil (A,B) has two real eigenvalues (include 0/0 or 1/0
types), then
[ a11 a12 ] := [  CSL  SNL ] [ a11 a12 ] [  CSR -SNR ]
[  0  a22 ]    [ -SNL  CSL ] [ a21 a22 ] [  SNR  CSR ]
[ b11 b12 ] := [  CSL  SNL ] [ b11 b12 ] [  CSR -SNR ]
[  0  b22 ]    [ -SNL  CSL ] [  0  b22 ] [  SNR  CSR ],
2) if the pencil (A,B) has a pair of complex conjugate eigenvalues,
then
[ a11 a12 ] := [  CSL  SNL ] [ a11 a12 ] [  CSR -SNR ]
[ a21 a22 ]    [ -SNL  CSL ] [ a21 a22 ] [  SNR  CSR ]
[ b11  0  ] := [  CSL  SNL ] [ b11 b12 ] [  CSR -SNR ]
[  0  b22 ]    [ -SNL  CSL ] [  0  b22 ] [  SNR  CSR ]
where b11 &gt;= b22 &gt; 0.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlahqr.html'>stdlib_dlahqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues and Schur decomposition already computed by DHSEQR, by
dealing with the Hessenberg submatrix in rows and columns ILO to
IHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlahr2.html'>stdlib_dlahr2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A so that elements below the k-th subdiagonal are zero. The
reduction is performed by an orthogonal similarity transformation
Q<strong>T * A * Q. The routine returns the matrices V and T which determine
Q as a block reflector I - V<em>T</em>V</strong>T, and also the matrix Y = A * V * T.
This is an auxiliary routine called by DGEHRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaic1.html'>stdlib_dlaic1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>its simplest version:
Let x, twonorm(x) = 1, be an approximate singular vector of an j-by-j
lower triangular matrix L, such that
twonorm(L<em>x) = sest
Then DLAIC1 computes sestpr, s, c such that
the vector
[ s</em>x ]
xhat = [  c  ]
is an approximate singular vector of
[ L       0  ]
Lhat = [ w<strong>T gamma ]
in the sense that
twonorm(Lhat*xhat) = sestpr.
Depending on JOB, an estimate for the largest or smallest singular
value is computed.
Note that [s c]</strong>T and sestpr<strong>2 is an eigenpair of the system
diag(sest*sest, 0) + [alpha  gamma] * [ alpha ]
[ gamma ]
where  alpha =  x</strong>T*w.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaisnan.html'>stdlib_dlaisnan</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>This routine is not for general use.  It exists solely to avoid
over-optimization in DISNAN.
DLAISNAN: checks for NaNs by comparing its two arguments for
inequality.  NaN is the only floating-point value where NaN != NaN
returns .TRUE.  To check for NaNs, pass the same variable as both
arguments.
A compiler must assume that the two arguments are
not the same variable, and the test will not be optimized away.
Interprocedural or whole-program optimization may delete this
test.  The ISNAN functions will be replaced by the correct
Fortran 03 intrinsic once the intrinsic is widely available.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaln2.html'>stdlib_dlaln2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>or (ca A<strong>T - w D) X = s B   with possible scaling ("s") and
perturbation of A.  (A</strong>T means A-transpose.)
A is an NA x NA real matrix, ca is a real scalar, D is an NA x NA
real diagonal matrix, w is a real or complex value, and X and B are
NA x 1 matrices -- real if w is real, complex if w is complex.  NA
may be 1 or 2.
If w is complex, X and B are represented as NA x 2 matrices,
the first column of each being the real part and the second
being the imaginary part.
"s" is a scaling factor (&lt;= 1), computed by DLALN2, which is
so chosen that X can be computed without overflow.  X is further
scaled if necessary to assure that norm(ca A - w D)<em>norm(X) is less
than overflow.
If both singular values of (ca A - w D) are less than SMIN,
SMIN</em>identity will be used instead of (ca A - w D).  If only one
singular value is less than SMIN, one element of (ca A - w D) will be
perturbed enough to make the smallest singular value roughly SMIN.
If both singular values are at least SMIN, (ca A - w D) will not be
perturbed.  In any case, the perturbation will be at most some small
multiple of max( SMIN, ulp*norm(ca A - w D) ).  The singular values
are computed by infinity-norm approximations, and thus will only be
correct to a factor of 2 or so.
Note: all input quantities are assumed to be smaller than overflow
by a reasonable factor.  (See BIGNUM.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlals0.html'>stdlib_dlals0</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>right singular vector matrix of a diagonal matrix appended by a row
to the right hand side matrix B in solving the least squares problem
using the divide-and-conquer SVD approach.
For the left singular vector matrix, three types of orthogonal
matrices are involved:
(1L) Givens rotations: the number of such rotations is GIVPTR; the
pairs of columns/rows they were applied to are stored in GIVCOL;
and the C- and S-values of these rotations are stored in GIVNUM.
(2L) Permutation. The (NL+1)-st row of B is to be moved to the first
row, and for J=2:N, PERM(J)-th row of B is to be moved to the
J-th row.
(3L) The left singular vector matrix of the remaining matrix.
For the right singular vector matrix, four types of orthogonal
matrices are involved:
(1R) The right singular vector matrix of the remaining matrix.
(2R) If SQRE = 1, one extra Givens rotation to generate the right
null space.
(3R) The inverse transformation of (2L).
(4R) The inverse transformation of (1L).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlalsa.html'>stdlib_dlalsa</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>by computing the SVD of the coefficient matrix in compact form (The
singular vectors are computed as products of simple orthorgonal
matrices.).
If ICOMPQ = 0, DLALSA applies the inverse of the left singular vector
matrix of an upper bidiagonal matrix to the right hand side; and if
ICOMPQ = 1, DLALSA applies the right singular vector matrix to the
right hand side. The singular vector matrices were generated in
compact form by DLALSA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlalsd.html'>stdlib_dlalsd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>squares problem of finding X to minimize the Euclidean norm of each
column of A*X-B, where A is N-by-N upper bidiagonal, and X and B
are N-by-NRHS. The solution X overwrites B.
The singular values of A smaller than RCOND times the largest
singular value are treated as zero in solving the least squares
problem; in this case a minimum norm solution is returned.
The actual singular values are returned in D in ascending order.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlamc3.html'>stdlib_dlamc3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_dlamch.html'>stdlib_dlamch</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_dlamrg.html'>stdlib_dlamrg</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of A (which is composed of two independently sorted sets) into a
single set which is sorted in ascending order.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlamswlq.html'>stdlib_dlamswlq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of blocked
elementary reflectors computed by short wide LQ
factorization (DLASWLQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlamtsqr.html'>stdlib_dlamtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (DLATSQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaneg.html'>stdlib_dlaneg</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>encountered while factoring tridiagonal T - sigma I = L D L^T.
This implementation works directly on the factors without forming
the tridiagonal matrix T.  The Sturm count is also the number of
eigenvalues of T less than sigma.
This routine is called from DLARRB.
The current routine does not use the PIVMIN parameter but rather
requires IEEE-754 propagation of Infinities and NaNs.  This
routine also has no input range restrictions but does require
default exception handling such that x/0 produces Inf when x is
non-zero, and Inf/Inf produces NaN.  For more information, see:
Marques, Riedy, and Voemel, "Benefits of IEEE-754 Features in
Modern Symmetric Tridiagonal Eigensolvers," SIAM Journal on
Scientific Computing, v28, n5, 2006.  DOI 10.1137/050641624
(Tech report version in LAWN 172 with the same title.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlangb.html'>stdlib_dlangb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n band matrix  A,  with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlange.html'>stdlib_dlange</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlangt.html'>stdlib_dlangt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlanhs.html'>stdlib_dlanhs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
Hessenberg matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlansb.html'>stdlib_dlansb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n symmetric band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlansf.html'>stdlib_dlansf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the infinity norm, or the element of largest absolute value of a
real symmetric matrix A in RFP format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlansp.html'>stdlib_dlansp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlanst.html'>stdlib_dlanst</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlansy.html'>stdlib_dlansy</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlantb.html'>stdlib_dlantb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n triangular band matrix A,  with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlantp.html'>stdlib_dlantp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
triangular matrix A, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlantr.html'>stdlib_dlantr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
trapezoidal or triangular matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlanv2.html'>stdlib_dlanv2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix in standard form:
[ A  B ] = [ CS -SN ] [ AA  BB ] [ CS  SN ]
[ C  D ]   [ SN  CS ] [ CC  DD ] [-SN  CS ]
where either
1) CC = 0 so that AA and DD are real eigenvalues of the matrix, or
2) AA = DD and BB<em>CC &lt; 0, so that AA + or - sqrt(BB</em>CC) are complex
conjugate eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaorhr_col_getrfnp.html'>stdlib_dlaorhr_col_getrfnp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>pivoting of a real general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is
at least one in absolute value (so that division-by-zero not
not possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine DORHR_COL. In DORHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the blocked right-looking version of the algorithm,
calling Level 3 BLAS to update the submatrix. To factorize a block,
this routine calls the recursive routine DLAORHR_COL_GETRFNP2.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaorhr_col_getrfnp2.html'>stdlib_dlaorhr_col_getrfnp2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>pivoting of a real general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is at
least one in absolute value (so that division-by-zero not
possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine DORHR_COL. In DORHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the recursive version of the LU factorization algorithm.
Denote A - S by B. The algorithm divides the matrix B into four
submatrices:
[  B11 | B12  ]  where B11 is n1 by n1,
B = [ -----|----- ]        B21 is (m-n1) by n1,
[  B21 | B22  ]        B12 is n1 by n2,
B22 is (m-n1) by n2,
with n1 = min(m,n)/2, n2 = n-n1.
The subroutine calls itself to factor B11, solves for B21,
solves for B12, updates B22, then calls itself to factor B22.
For more details on the recursive LU algorithm, see [2].
DLAORHR_COL_GETRFNP2 is called to factorize a block by the blocked
routine DLAORHR_COL_GETRFNP, which uses blocked code calling
Level 3 BLAS to update the submatrix. However, DLAORHR_COL_GETRFNP2
is self-sufficient and can be used without DLAORHR_COL_GETRFNP.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.
[2] "Recursion leads to automatic variable blocking for dense linear
algebra algorithms", F. Gustavson, IBM J. of Res. and Dev.,
vol. 41, no. 6, pp. 737-755, 1997.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlapll.html'>stdlib_dlapll</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Given two column vectors X and Y, let
A = ( X Y ).
The subroutine first computes the QR factorization of A = Q*R,
and then computes the SVD of the 2-by-2 upper triangular matrix R.
The smaller singular value of R is returned in SSMIN, which is used
as the measurement of the linear dependency of the vectors X and Y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlapmr.html'>stdlib_dlapmr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(M) of the integers 1,...,M.
If FORWRD = .TRUE.,  forward permutation:
X(K(I),<em>) is moved X(I,</em>) for I = 1,2,...,M.
If FORWRD = .FALSE., backward permutation:
X(I,<em>) is moved to X(K(I),</em>) for I = 1,2,...,M.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlapmt.html'>stdlib_dlapmt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(N) of the integers 1,...,N.
If FORWRD = .TRUE.,  forward permutation:
X(<em>,K(J)) is moved X(</em>,J) for J = 1,2,...,N.
If FORWRD = .FALSE., backward permutation:
X(<em>,J) is moved to X(</em>,K(J)) for J = 1,2,...,N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlapy2.html'>stdlib_dlapy2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>overflow and unnecessary underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlapy3.html'>stdlib_dlapy3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>unnecessary overflow and unnecessary underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqgb.html'>stdlib_dlaqgb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>subdiagonals and KU superdiagonals using the row and scaling factors
in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqge.html'>stdlib_dlaqge</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>column scaling factors in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqp2.html'>stdlib_dlaqp2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the block A(OFFSET+1:M,1:N).
The block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqps.html'>stdlib_dlaqps</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real M-by-N matrix A by using Blas-3.  It tries to factorize
NB columns from A starting from the row OFFSET+1, and updates all
of the matrix with Blas-3 xGEMM.
In some cases, due to catastrophic cancellations, it cannot
factorize NB columns.  Hence, the actual number of factorized
columns is returned in KB.
Block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqr0.html'>stdlib_dlaqr0</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>T, where T is an upper quasi-triangular matrix (the
Schur form), and Z is the orthogonal matrix of Schur vectors.
Optionally Z may be postmultiplied into an input orthogonal
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the orthogonal matrix Q:  A = Q<em>H</em>Q</strong>T = (QZ)<em>T</em>(QZ)**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqr1.html'>stdlib_dlaqr1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Given a 2-by-2 or 3-by-3 matrix H, DLAQR1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (H - (sr1 + i</em>si1)<em>I)</em>(H - (sr2 + i<em>si2)</em>I)
scaling to avoid overflows and most underflows. It
is assumed that either
1) sr1 = sr2 and si1 = -si2
or
2) si1 = si2 = 0.
This is useful for starting double implicit shift bulges
in the QR algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqr2.html'>stdlib_dlaqr2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>recursion by calling DLAHQR instead of DLAQR4.
Aggressive early deflation:
This subroutine accepts as input an upper Hessenberg matrix
H and performs an orthogonal similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an orthogonal similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqr3.html'>stdlib_dlaqr3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Aggressive early deflation:
DLAQR3: accepts as input an upper Hessenberg matrix
H and performs an orthogonal similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an orthogonal similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqr4.html'>stdlib_dlaqr4</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>It is a complete implementation of the small bulge multi-shift
QR algorithm.  It may be called by DLAQR0 and, for large enough
deflation window size, it may be called by DLAQR3.  This
subroutine is identical to DLAQR0 except that it calls DLAQR2
instead of DLAQR3.
DLAQR4 computes the eigenvalues of a Hessenberg matrix H
and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>T, where T is an upper quasi-triangular matrix (the
Schur form), and Z is the orthogonal matrix of Schur vectors.
Optionally Z may be postmultiplied into an input orthogonal
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the orthogonal matrix Q:  A = Q<em>H</em>Q</strong>T = (QZ)<em>T</em>(QZ)**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqr5.html'>stdlib_dlaqr5</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>single small-bulge multi-shift QR sweep.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqsb.html'>stdlib_dlaqsb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqsp.html'>stdlib_dlaqsp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqsy.html'>stdlib_dlaqsy</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqtr.html'>stdlib_dlaqtr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>op(T)<em>p = scale</em>c,               if LREAL = .TRUE.
or the complex quasi-triangular systems
op(T + iB)<em>(p+iq) = scale</em>(c+id),  if LREAL = .FALSE.
in real arithmetic, where T is upper quasi-triangular.
If LREAL = .FALSE., then the first diagonal block of T must be
1 by 1, B is the specially structured matrix
B = [ b(1) b(2) ... b(n) ]
[       w            ]
[           w        ]
[              .     ]
[                 w  ]
op(A) = A or A<strong>T, A</strong>T denotes the transpose of
matrix A.
On input, X = [ c ].  On output, X = [ p ].
[ d ]                  [ q ]
This subroutine is designed for the condition number estimation
in routine DTRSNA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqz0.html'>stdlib_dlaqz0</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a real matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>T,  B = Q1<em>T</em>Z1</strong>T,
as computed by DGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>T,  T = Q<em>P</em>Z</strong>T,
where Q and Z are orthogonal matrices, P is an upper triangular
matrix, and S is a quasi-triangular matrix with 1-by-1 and 2-by-2
diagonal blocks.
The 1-by-1 blocks correspond to real eigenvalues of the matrix pair
(H,T) and the 2-by-2 blocks correspond to complex conjugate pairs of
eigenvalues.
Additionally, the 2-by-2 upper triangular diagonal blocks of P
corresponding to 2-by-2 blocks of S are reduced to positive diagonal
form, i.e., if S(j+1,j) is non-zero, then P(j+1,j) = P(j,j+1) = 0,
P(j,j) &gt; 0, and P(j+1,j+1) &gt; 0.
Optionally, the orthogonal matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
orthogonal matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the orthogonal matrices from DGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the orthogonal factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>T,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>T.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Real eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.
Ref: B. Kagstrom, D. Kressner, "Multishift Variants of the QZ
Algorithm with Aggressive Early Deflation", SIAM J. Numer.
Anal., 29(2006), pp. 199--227.
Ref: T. Steel, D. Camps, K. Meerbergen, R. Vandebril "A multishift,
multipole rational QZ method with agressive early deflation"</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqz1.html'>stdlib_dlaqz1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Given a 3-by-3 matrix pencil (A,B), DLAQZ1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (A - (beta2</em>sr2 - i<em>si)</em>B)<em>B^(-1)</em>(beta1<em>A - (sr2 + i</em>si2)<em>B)</em>B^(-1).
It is assumed that either
1) sr1 = sr2
or
2) si = 0.
This is useful for starting double implicit shift bulges
in the QZ algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqz2.html'>stdlib_dlaqz2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DLAQZ2: chases a 2x2 shift bulge in a matrix pencil down a single position</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqz3.html'>stdlib_dlaqz3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DLAQZ3: performs AED</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaqz4.html'>stdlib_dlaqz4</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DLAQZ4: Executes a single multishift QZ sweep</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlar1v.html'>stdlib_dlar1v</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the sumbmatrix in rows B1 through BN of the tridiagonal matrix
L D L<strong>T - sigma I. When sigma is close to an eigenvalue, the
computed vector is an accurate eigenvector. Usually, r corresponds
to the index where the eigenvector is largest in magnitude.
The following steps accomplish this computation :
(a) Stationary qd transform,  L D L</strong>T - sigma I = L(+) D(+) L(+)<strong>T,
(b) Progressive qd transform, L D L</strong>T - sigma I = U(-) D(-) U(-)<strong>T,
(c) Computation of the diagonal elements of the inverse of
L D L</strong>T - sigma I by combining the above transforms, and choosing
r as the index where the diagonal of the inverse is (one of the)
largest in magnitude.
(d) Computation of the (scaled) r-th column of the inverse using the
twisted factorization obtained by combining the top part of the
the stationary and the bottom part of the progressive transform.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlar2v.html'>stdlib_dlar2v</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a sequence of 2-by-2 real symmetric matrices, defined by the elements
of the vectors x, y and z. For i = 1,2,...,n
( x(i)  z(i) ) := (  c(i)  s(i) ) ( x(i)  z(i) ) ( c(i) -s(i) )
( z(i)  y(i) )    ( -s(i)  c(i) ) ( z(i)  y(i) ) ( s(i)  c(i) )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarf.html'>stdlib_dlarf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>C, from either the left or the right. H is represented in the form
H = I - tau * v * v**T
where tau is a real scalar and v is a real vector.
If tau = 0, then H is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarfb.html'>stdlib_dlarfb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real m by n matrix C, from either the left or the right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarfb_gett.html'>stdlib_dlarfb_gett</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>left to a real (K+M)-by-N  "triangular-pentagonal" matrix
composed of two block matrices: an upper trapezoidal K-by-N matrix A
stored in the array A, and a rectangular M-by-(N-K) matrix B, stored
in the array B. The block reflector H is stored in a compact
WY-representation, where the elementary reflectors are in the
arrays A, B and T. See Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarfg.html'>stdlib_dlarfg</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>that
H * ( alpha ) = ( beta ),   H<strong>T * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, and x is an (n-1)-element real
vector. H is represented in the form
H = I - tau * ( 1 ) * ( 1 v</strong>T ) ,
( v )
where tau is a real scalar and v is a real (n-1)-element
vector.
If the elements of x are all zero, then tau = 0 and H is taken to be
the unit matrix.
Otherwise  1 &lt;= tau &lt;= 2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarfgp.html'>stdlib_dlarfgp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>that
H * ( alpha ) = ( beta ),   H<strong>T * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, beta is non-negative, and x is
an (n-1)-element real vector.  H is represented in the form
H = I - tau * ( 1 ) * ( 1 v</strong>T ) ,
( v )
where tau is a real scalar and v is a real (n-1)-element
vector.
If the elements of x are all zero, then tau = 0 and H is taken to be
the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarft.html'>stdlib_dlarft</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of order n, which is defined as a product of k elementary reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>T
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>T * T * V</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarfx.html'>stdlib_dlarfx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v**T
where tau is a real scalar and v is a real vector.
If tau = 0, then H is taken to be the unit matrix
This version uses inline code if H has order &lt; 11.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarfy.html'>stdlib_dlarfy</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to an n x n symmetric matrix C, from both the left and the right.
H is represented in the form
H = I - tau * v * v'
where  tau  is a scalar and  v  is a vector.
If  tau  is  zero, then  H  is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlargv.html'>stdlib_dlargv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>elements of the real vectors x and y. For i = 1,2,...,n
(  c(i)  s(i) ) ( x(i) ) = ( a(i) )
( -s(i)  c(i) ) ( y(i) ) = (   0  )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarnv.html'>stdlib_dlarnv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>normal distribution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarra.html'>stdlib_dlarra</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Compute the splitting points with threshold SPLTOL.
DLARRA: sets any "small" off-diagonal elements to zero.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrb.html'>stdlib_dlarrb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Given the relatively robust representation(RRR) L D L^T, DLARRB:
does "limited" bisection to refine the eigenvalues of L D L^T,
W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial
guesses for these eigenvalues are input in W, the corresponding estimate
of the error in these guesses and their gaps are input in WERR
and WGAP, respectively. During bisection, intervals
[left, right] are maintained by storing their mid-points and
semi-widths in the arrays W and WERR respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrc.html'>stdlib_dlarrc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Find the number of eigenvalues of the symmetric tridiagonal matrix T
that are in the interval (VL,VU] if JOBT = 'T', and of L D L^T
if JOBT = 'L'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrd.html'>stdlib_dlarrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix T to suitable accuracy. This is an auxiliary code to be
called from DSTEMR.
The user may ask for all eigenvalues, all eigenvalues
in the half-open interval (VL, VU], or the IL-th through IU-th
eigenvalues.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarre.html'>stdlib_dlarre</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>To find the desired eigenvalues of a given real symmetric
tridiagonal matrix T, DLARRE: sets any "small" off-diagonal
elements to zero, and for each unreduced block T_i, it finds
(a) a suitable shift at one end of the block's spectrum,
(b) the base representation, T_i - sigma_i I = L_i D_i L_i^T, and
(c) eigenvalues of each L_i D_i L_i^T.
The representations and eigenvalues found are then used by
DSTEMR to compute the eigenvectors of T.
The accuracy varies depending on whether bisection is used to
find a few eigenvalues or the dqds algorithm (subroutine DLASQ2) to
conpute all and then discard any unwanted one.
As an added benefit, DLARRE also outputs the n
Gerschgorin intervals for the matrices L_i D_i L_i^T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrf.html'>stdlib_dlarrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Given the initial representation L D L^T and its cluster of close
eigenvalues (in a relative measure), W( CLSTRT ), W( CLSTRT+1 ), ...
W( CLEND ), DLARRF: finds a new relatively robust representation
L D L^T - SIGMA I = L(+) D(+) L(+)^T such that at least one of the
eigenvalues of L(+) D(+) L(+)^T is relatively isolated.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrj.html'>stdlib_dlarrj</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Given the initial eigenvalue approximations of T, DLARRJ:
does  bisection to refine the eigenvalues of T,
W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial
guesses for these eigenvalues are input in W, the corresponding estimate
of the error in these guesses in WERR. During bisection, intervals
[left, right] are maintained by storing their mid-points and
semi-widths in the arrays W and WERR respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrk.html'>stdlib_dlarrk</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix T to suitable accuracy. This is an auxiliary code to be
called from DSTEMR.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrr.html'>stdlib_dlarrr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Perform tests to decide whether the symmetric tridiagonal matrix T
warrants expensive computations which guarantee high relative accuracy
in the eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarrv.html'>stdlib_dlarrv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>T = L D L<strong>T given L, D and APPROXIMATIONS to the eigenvalues of L D L</strong>T.
The input eigenvalues should have been computed by DLARRE.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlartg.html'>stdlib_dlartg</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_dlartg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_dlartgp.html'>stdlib_dlartgp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>[  CS  SN  ]  .  [ F ]  =  [ R ]   where CS<strong>2 + SN</strong>2 = 1.
[ -SN  CS  ]     [ G ]     [ 0 ]
This is a slower, more accurate version of the Level 1 BLAS routine DROTG,
with the following other differences:
F and G are unchanged on return.
If G=0, then CS=(+/-)1 and SN=0.
If F=0 and (G .ne. 0), then CS=0 and SN=(+/-)1.
The sign is chosen so that R &gt;= 0.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlartgs.html'>stdlib_dlartgs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Golub-Reinsch-style implicit QR iteration for the bidiagonal SVD
problem. X and Y are the top-row entries, and SIGMA is the shift.
The computed CS and SN define a plane rotation satisfying
[  CS  SN  ]  .  [ X^2 - SIGMA ]  =  [ R ],
[ -SN  CS  ]     [    X * Y    ]     [ 0 ]
with R nonnegative.  If X^2 - SIGMA and X * Y are 0, then the
rotation is by PI/2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlartv.html'>stdlib_dlartv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real vectors x and y. For i = 1,2,...,n
( x(i) ) := (  c(i)  s(i) ) ( x(i) )
( y(i) )    ( -s(i)  c(i) ) ( y(i) )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaruv.html'>stdlib_dlaruv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>distribution (n &lt;= 128).
This is an auxiliary routine called by DLARNV and ZLARNV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarz.html'>stdlib_dlarz</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v**T
where tau is a real scalar and v is a real vector.
If tau = 0, then H is taken to be the unit matrix.
H is a product of k elementary reflectors as returned by DTZRZF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarzb.html'>stdlib_dlarzb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real distributed M-by-N  C from the left or the right.
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlarzt.html'>stdlib_dlarzt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>H of order &gt; n, which is defined as a product of k elementary
reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>T
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>T * T * V
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlas2.html'>stdlib_dlas2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>[  F   G  ]
[  0   H  ].
On return, SSMIN is the smaller singular value and SSMAX is the
larger singular value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlascl.html'>stdlib_dlascl</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>CTO/CFROM.  This is done without over/underflow as long as the final
result CTO*A(I,J)/CFROM does not over/underflow. TYPE specifies that
A may be full, upper triangular, lower triangular, upper Hessenberg,
or banded.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd0.html'>stdlib_dlasd0</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Using a divide and conquer approach, DLASD0: computes the singular
value decomposition (SVD) of a real upper bidiagonal N-by-M
matrix B with diagonal D and offdiagonal E, where M = N + SQRE.
The algorithm computes orthogonal matrices U and VT such that
B = U * S * VT. The singular values S are overwritten on D.
A related subroutine, DLASDA, computes only the singular values,
and optionally, the singular vectors in compact form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd1.html'>stdlib_dlasd1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>where N = NL + NR + 1 and M = N + SQRE. DLASD1 is called from DLASD0.
A related subroutine DLASD7 handles the case in which the singular
values (and the singular vectors in factored form) are desired.
DLASD1 computes the SVD as follows:
( D1(in)    0    0       0 )
B = U(in) * (   Z1<strong>T   a   Z2</strong>T    b ) * VT(in)
(   0       0   D2(in)   0 )
= U(out) * ( D(out) 0) * VT(out)
where Z<strong>T = (Z1</strong>T a Z2<strong>T b) = u</strong>T VT**T, and u is a vector of dimension M
with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros
elsewhere; and the entry b is empty if SQRE = 0.
The left singular vectors of the original matrix are stored in U, and
the transpose of the right singular vectors are stored in VT, and the
singular values are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple singular values or when there are zeros in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine DLASD2.
The second stage consists of calculating the updated
singular values. This is done by finding the square roots of the
roots of the secular equation via the routine DLASD4 (as called
by DLASD3). This routine also calculates the singular vectors of
the current problem.
The final stage consists of computing the updated singular vectors
directly using the updated singular values.  The singular vectors
for the current problem are multiplied with the singular vectors
from the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd2.html'>stdlib_dlasd2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
singular values are close together or if there is a tiny entry in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.
DLASD2 is called from DLASD1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd3.html'>stdlib_dlasd3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equation, as defined by the values in D and Z.  It makes the
appropriate calls to DLASD4 and then updates the singular
vectors by matrix multiplication.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.
DLASD3 is called from DLASD1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd4.html'>stdlib_dlasd4</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>This subroutine computes the square root of the I-th updated
eigenvalue of a positive symmetric rank-one modification to
a positive diagonal matrix whose entries are given as the squares
of the corresponding entries in the array d, and that
0 &lt;= D(i) &lt; D(j)  for  i &lt; j
and that RHO &gt; 0. This is arranged by the calling routine, and is
no loss in generality.  The rank-one modified system is thus
diag( D ) * diag( D ) +  RHO * Z * Z_transpose.
where we assume the Euclidean norm of Z is 1.
The method consists of approximating the rational functions in the
secular equation by simpler interpolating rational functions.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd5.html'>stdlib_dlasd5</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>This subroutine computes the square root of the I-th eigenvalue
of a positive symmetric rank-one modification of a 2-by-2 diagonal
matrix
diag( D ) * diag( D ) +  RHO * Z * transpose(Z) .
The diagonal entries in the array D are assumed to satisfy
0 &lt;= D(i) &lt; D(j)  for  i &lt; j .
We also assume RHO &gt; 0 and that the Euclidean norm of the vector
Z is one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd6.html'>stdlib_dlasd6</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>obtained by merging two smaller ones by appending a row. This
routine is used only for the problem which requires all singular
values and optionally singular vector matrices in factored form.
B is an N-by-M matrix with N = NL + NR + 1 and M = N + SQRE.
A related subroutine, DLASD1, handles the case in which all singular
values and singular vectors of the bidiagonal matrix are desired.
DLASD6 computes the SVD as follows:
( D1(in)    0    0       0 )
B = U(in) * (   Z1<strong>T   a   Z2</strong>T    b ) * VT(in)
(   0       0   D2(in)   0 )
= U(out) * ( D(out) 0) * VT(out)
where Z<strong>T = (Z1</strong>T a Z2<strong>T b) = u</strong>T VT**T, and u is a vector of dimension M
with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros
elsewhere; and the entry b is empty if SQRE = 0.
The singular values of B can be computed using D1, D2, the first
components of all the right singular vectors of the lower block, and
the last components of all the right singular vectors of the upper
block. These components are stored and updated in VF and VL,
respectively, in DLASD6. Hence U and VT are not explicitly
referenced.
The singular values are stored in D. The algorithm consists of two
stages:
The first stage consists of deflating the size of the problem
when there are multiple singular values or if there is a zero
in the Z vector. For each such occurrence the dimension of the
secular equation problem is reduced by one. This stage is
performed by the routine DLASD7.
The second stage consists of calculating the updated
singular values. This is done by finding the roots of the
secular equation via the routine DLASD4 (as called by DLASD8).
This routine also updates VF and VL and computes the distances
between the updated singular values and the old singular
values.
DLASD6 is called from DLASDA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd7.html'>stdlib_dlasd7</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>sorted set. Then it tries to deflate the size of the problem. There
are two ways in which deflation can occur:  when two or more singular
values are close together or if there is a tiny entry in the Z
vector. For each such occurrence the order of the related
secular equation problem is reduced by one.
DLASD7 is called from DLASD6.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasd8.html'>stdlib_dlasd8</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>as defined by the values in DSIGMA and Z. It makes the appropriate
calls to DLASD4, and stores, for each  element in D, the distance
to its two nearest poles (elements in DSIGMA). It also updates
the arrays VF and VL, the first and last components of all the
right singular vectors of the original bidiagonal matrix.
DLASD8 is called from DLASD6.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasda.html'>stdlib_dlasda</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Using a divide and conquer approach, DLASDA: computes the singular
value decomposition (SVD) of a real upper bidiagonal N-by-M matrix
B with diagonal D and offdiagonal E, where M = N + SQRE. The
algorithm computes the singular values in the SVD B = U * S * VT.
The orthogonal matrices U and VT are optionally computed in
compact form.
A related subroutine, DLASD0, computes the singular values and
the singular vectors in explicit form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasdq.html'>stdlib_dlasdq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>(upper or lower) bidiagonal matrix with diagonal D and offdiagonal
E, accumulating the transformations if desired. Letting B denote
the input bidiagonal matrix, the algorithm computes orthogonal
matrices Q and P such that B = Q * S * P<strong>T (P</strong>T denotes the transpose
of P). The singular values S are overwritten on D.
The input matrix U  is changed to U  * Q  if desired.
The input matrix VT is changed to P<strong>T * VT if desired.
The input matrix C  is changed to Q</strong>T * C  if desired.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3, for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasdt.html'>stdlib_dlasdt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>conquer.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaset.html'>stdlib_dlaset</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>ALPHA on the offdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasq1.html'>stdlib_dlasq1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix with diagonal D and off-diagonal E. The singular values
are computed to high relative accuracy, in the absence of
denormalization, underflow and overflow. The algorithm was first
presented in
"Accurate singular values and differential qd algorithms" by K. V.
Fernando and B. N. Parlett, Numer. Math., Vol-67, No. 2, pp. 191-230,
1994,
and the present implementation is described in "An implementation of
the dqds Algorithm (Positive Case)", LAPACK Working Note.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasq2.html'>stdlib_dlasq2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>definite tridiagonal matrix associated with the qd array Z to high
relative accuracy are computed to high relative accuracy, in the
absence of denormalization, underflow and overflow.
To see the relation of Z to the tridiagonal matrix, let L be a
unit lower bidiagonal matrix with subdiagonals Z(2,4,6,,..) and
let U be an upper bidiagonal matrix with 1's above and diagonal
Z(1,3,5,,..). The tridiagonal is L*U or, if you prefer, the
symmetric tridiagonal to which it is similar.
Note : DLASQ2 defines a logical variable, IEEE, which is true
on machines which follow ieee-754 floating-point standard in their
handling of infinities and NaNs, and false otherwise. This variable
is passed to DLASQ3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasq3.html'>stdlib_dlasq3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>In case of failure it changes shifts, and tries again until output
is positive.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasq4.html'>stdlib_dlasq4</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using values of d from the previous transform.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasq5.html'>stdlib_dlasq5</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>version for IEEE machines another for non IEEE machines.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasq6.html'>stdlib_dlasq6</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>ping-pong form, with protection against underflow and overflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasr.html'>stdlib_dlasr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>from either the left or the right.
When SIDE = 'L', the transformation takes the form
A := P<em>A
and when SIDE = 'R', the transformation takes the form
A := A</em>P<strong>T
where P is an orthogonal matrix consisting of a sequence of z plane
rotations, with z = M when SIDE = 'L' and z = N when SIDE = 'R',
and P</strong>T is the transpose of P.
When DIRECT = 'F' (Forward sequence), then
P = P(z-1) * ... * P(2) * P(1)
and when DIRECT = 'B' (Backward sequence), then
P = P(1) * P(2) * ... * P(z-1)
where P(k) is a plane rotation matrix defined by the 2-by-2 rotation
R(k) = (  c(k)  s(k) )
= ( -s(k)  c(k) ).
When PIVOT = 'V' (Variable pivot), the rotation is performed
for the plane (k,k+1), i.e., P(k) has the form
P(k) = (  1                                            )
(       ...                                     )
(              1                                )
(                   c(k)  s(k)                  )
(                  -s(k)  c(k)                  )
(                                1              )
(                                     ...       )
(                                            1  )
where R(k) appears as a rank-2 modification to the identity matrix in
rows and columns k and k+1.
When PIVOT = 'T' (Top pivot), the rotation is performed for the
plane (1,k+1), so P(k) has the form
P(k) = (  c(k)                    s(k)                 )
(         1                                     )
(              ...                              )
(                     1                         )
( -s(k)                    c(k)                 )
(                                 1             )
(                                      ...      )
(                                             1 )
where R(k) appears in rows and columns 1 and k+1.
Similarly, when PIVOT = 'B' (Bottom pivot), the rotation is
performed for the plane (k,z), giving P(k) the form
P(k) = ( 1                                             )
(      ...                                      )
(             1                                 )
(                  c(k)                    s(k) )
(                         1                     )
(                              ...              )
(                                     1         )
(                 -s(k)                    c(k) )
where R(k) appears in rows and columns k and z.  The rotations are
performed without ever forming P(k) explicitly.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasrt.html'>stdlib_dlasrt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Sort the numbers in D in increasing order (if ID = 'I') or
in decreasing order (if ID = 'D' ).
Use Quick Sort, reverting to Insertion sort on arrays of
size &lt;= 20. Dimension of STACK limits N to about 2**32.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlassq.html'>stdlib_dlassq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_dlassq.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasv2.html'>stdlib_dlasv2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>triangular matrix
[  F   G  ]
[  0   H  ].
On return, abs(SSMAX) is the larger singular value, abs(SSMIN) is the
smaller singular value, and (CSL,SNL) and (CSR,SNR) are the left and
right singular vectors for abs(SSMAX), giving the decomposition
[ CSL  SNL ] [  F   G  ] [ CSR -SNR ]  =  [ SSMAX   0   ]
[-SNL  CSL ] [  0   H  ] [ SNR  CSR ]     [  0    SSMIN ].</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaswlq.html'>stdlib_dlaswlq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real M-by-N matrix A for M &lt;= N:
A = ( L 0 ) *  Q,
where:
Q is a n-by-N orthogonal matrix, stored on exit in an implicit
form in the elements above the diagonal of the array A and in
the elements of the array T;
L is a lower-triangular M-by-M matrix stored on exit in
the elements on and below the diagonal of the array A.
0 is a M-by-(N-M) zero matrix, if M &lt; N, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlaswp.html'>stdlib_dlaswp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>One row interchange is initiated for each of rows K1 through K2 of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasy2.html'>stdlib_dlasy2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>op(TL)<em>X + ISGN</em>X<em>op(TR) = SCALE</em>B,
where TL is N1 by N1, TR is N2 by N2, B is N1 by N2, and ISGN = 1 or
-1.  op(T) = T or T<strong>T, where T</strong>T denotes the transpose of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasyf.html'>stdlib_dlasyf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method. The partial
factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
DLASYF is an auxiliary routine called by DSYTRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasyf_aa.html'>stdlib_dlasyf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DLATRF_AA factorizes a panel of a real symmetric matrix A using
the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasyf_rk.html'>stdlib_dlasyf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
DLASYF_RK is an auxiliary routine called by DSYTRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlasyf_rook.html'>stdlib_dlasyf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
DLASYF_ROOK is an auxiliary routine called by DSYTRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlat2s.html'>stdlib_dlat2s</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>PRECISION triangular matrix, A.
RMAX is the overflow for the SINGLE PRECISION arithmetic
DLAS2S checks that all the entries of A are between -RMAX and
RMAX. If not the conversion is aborted and a flag is raised.
This is an auxiliary routine so there is no argument checking.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatbs.html'>stdlib_dlatbs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A <em>x = s</em>b  or  A<strong>T<em>x = s</em>b
with scaling to prevent overflow, where A is an upper or lower
triangular band matrix.  Here A</strong>T denotes the transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine DTBSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatdf.html'>stdlib_dlatdf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DGETC2 and computes a contribution to the reciprocal Dif-estimate
by solving Z * x = b for x, and choosing the r.h.s. b such that
the norm of x is as large as possible. On entry RHS = b holds the
contribution from earlier solved sub-systems, and on return RHS = x.
The factorization of Z returned by DGETC2 has the form Z = P<em>L</em>U*Q,
where P and Q are permutation matrices. L is lower triangular with
unit diagonal elements and U is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatps.html'>stdlib_dlatps</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A <em>x = s</em>b  or  A<strong>T<em>x = s</em>b
with scaling to prevent overflow, where A is an upper or lower
triangular matrix stored in packed form.  Here A</strong>T denotes the
transpose of A, x and b are n-element vectors, and s is a scaling
factor, usually less than or equal to 1, chosen so that the
components of x will be less than the overflow threshold.  If the
unscaled problem will not cause overflow, the Level 2 BLAS routine
DTPSV is called. If the matrix A is singular (A(j,j) = 0 for some j),
then s is set to 0 and a non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatrd.html'>stdlib_dlatrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric tridiagonal form by an orthogonal similarity
transformation Q**T * A * Q, and returns the matrices V and W which are
needed to apply the transformation to the unreduced part of A.
If UPLO = 'U', DLATRD reduces the last NB rows and columns of a
matrix, of which the upper triangle is supplied;
if UPLO = 'L', DLATRD reduces the first NB rows and columns of a
matrix, of which the lower triangle is supplied.
This is an auxiliary routine called by DSYTRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatrs.html'>stdlib_dlatrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A <em>x = s</em>b  or  A<strong>T <em>x = s</em>b
with scaling to prevent overflow.  Here A is an upper or lower
triangular matrix, A</strong>T denotes the transpose of A, x and b are
n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine DTRSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatrz.html'>stdlib_dlatrz</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>[ A1 A2 ] = [ A(1:M,1:M) A(1:M,N-L+1:N) ] as ( R  0 ) * Z, by means
of orthogonal transformations.  Z is an (M+L)-by-(M+L) orthogonal
matrix and, R and A1 are M-by-M upper triangular matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlatsqr.html'>stdlib_dlatsqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real M-by-N matrix A for M &gt;= N:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix, stored on exit in an implicit
form in the elements below the diagonal of the array A and in
the elements of the array T;
R is an upper-triangular N-by-N matrix, stored on exit in
the elements on and above the diagonal of the array A.
0 is a (M-N)-by-N zero matrix, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlauu2.html'>stdlib_dlauu2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the unblocked form of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dlauum.html'>stdlib_dlauum</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the blocked form of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dnrm2.html'>stdlib_dnrm2</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Function</td><td><p>!</p><a href="../proc/stdlib_dnrm2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_dopgtr.html'>stdlib_dopgtr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors H(i) of order n, as returned by
DSPTRD using packed storage:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dopmtr.html'>stdlib_dopmtr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by DSPTRD using packed
storage:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb.html'>stdlib_dorbdb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>partitioned orthogonal matrix X:
[ B11 | B12 0  0 ]
[ X11 | X12 ]   [ P1 |    ] [  0  |  0 -I  0 ] [ Q1 |    ]**T
X = [-----------] = [---------] [----------------] [---------]   .
[ X21 | X22 ]   [    | P2 ] [ B21 | B22 0  0 ] [    | Q2 ]
[  0  |  0  0  I ]
X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is
not the case, then X must be transposed and/or permuted. This can be
done in constant time using the TRANS and SIGNS options. See DORCSD
for details.)
The orthogonal matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by-
(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are
represented implicitly by Householder vectors.
B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb1.html'>stdlib_dorbdb1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P,
M-P, or M-Q. Routines DORBDB2, DORBDB3, and DORBDB4 handle cases in
which Q is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb2.html'>stdlib_dorbdb2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P,
Q, or M-Q. Routines DORBDB1, DORBDB3, and DORBDB4 handle cases in
which P is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are P-by-P bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb3.html'>stdlib_dorbdb3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P,
Q, or M-Q. Routines DORBDB1, DORBDB2, and DORBDB4 handle cases in
which M-P is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb4.html'>stdlib_dorbdb4</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P,
M-P, or Q. Routines DORBDB1, DORBDB2, and DORBDB3 handle cases in
which M-Q is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb5.html'>stdlib_dorbdb5</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then some other vector from the orthogonal complement
is returned. This vector is chosen in an arbitrary but deterministic
way.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorbdb6.html'>stdlib_dorbdb6</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then the zero vector is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorcsd.html'>stdlib_dorcsd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>orthogonal matrix X:
[  I  0  0 |  0  0  0 ]
[  0  C  0 |  0 -S  0 ]
[ X11 | X12 ]   [ U1 |    ] [  0  0  0 |  0  0 -I ] [ V1 |    ]**T
X = [-----------] = [---------] [---------------------] [---------]   .
[ X21 | X22 ]   [    | U2 ] [  0  0  0 |  I  0  0 ] [    | V2 ]
[  0  S  0 |  0  C  0 ]
[  0  0  I |  0  0  0 ]
X11 is P-by-Q. The orthogonal matrices U1, U2, V1, and V2 are P-by-P,
(M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are
R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in
which R = MIN(P,M-P,Q,M-Q).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorcsd2by1.html'>stdlib_dorcsd2by1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>orthonormal columns that has been partitioned into a 2-by-1 block
structure:
[  I1 0  0 ]
[  0  C  0 ]
[ X11 ]   [ U1 |    ] [  0  0  0 ]
X = [-----] = [---------] [----------] V1**T .
[ X21 ]   [    | U2 ] [  0  0  0 ]
[  0  S  0 ]
[  0  0  I2]
X11 is P-by-Q. The orthogonal matrices U1, U2, and V1 are P-by-P,
(M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R
nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which
R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a
K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorg2l.html'>stdlib_dorg2l</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the last n columns of a product of k elementary
reflectors of order m
Q  =  H(k) . . . H(2) H(1)
as returned by DGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorg2r.html'>stdlib_dorg2r</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the first n columns of a product of k elementary
reflectors of order m
Q  =  H(1) H(2) . . . H(k)
as returned by DGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgbr.html'>stdlib_dorgbr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>determined by DGEBRD when reducing a real matrix A to bidiagonal
form: A = Q * B * P<strong>T.  Q and P</strong>T are defined as products of
elementary reflectors H(i) or G(i) respectively.
If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q
is of order M:
if m &gt;= k, Q = H(1) H(2) . . . H(k) and DORGBR returns the first n
columns of Q, where m &gt;= n &gt;= k;
if m &lt; k, Q = H(1) H(2) . . . H(m-1) and DORGBR returns Q as an
M-by-M matrix.
If VECT = 'P', A is assumed to have been a K-by-N matrix, and P<strong>T
is of order N:
if k &lt; n, P</strong>T = G(k) . . . G(2) G(1) and DORGBR returns the first m
rows of P<strong>T, where n &gt;= m &gt;= k;
if k &gt;= n, P</strong>T = G(n-1) . . . G(2) G(1) and DORGBR returns P**T as
an N-by-N matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorghr.html'>stdlib_dorghr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>product of IHI-ILO elementary reflectors of order N, as returned by
DGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgl2.html'>stdlib_dorgl2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the first m rows of a product of k elementary
reflectors of order n
Q  =  H(k) . . . H(2) H(1)
as returned by DGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorglq.html'>stdlib_dorglq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the first M rows of a product of K elementary
reflectors of order N
Q  =  H(k) . . . H(2) H(1)
as returned by DGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgql.html'>stdlib_dorgql</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the last N columns of a product of K elementary
reflectors of order M
Q  =  H(k) . . . H(2) H(1)
as returned by DGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgqr.html'>stdlib_dorgqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the first N columns of a product of K elementary
reflectors of order M
Q  =  H(1) H(2) . . . H(k)
as returned by DGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgr2.html'>stdlib_dorgr2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the last m rows of a product of k elementary
reflectors of order n
Q  =  H(1) H(2) . . . H(k)
as returned by DGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgrq.html'>stdlib_dorgrq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which is defined as the last M rows of a product of K elementary
reflectors of order N
Q  =  H(1) H(2) . . . H(k)
as returned by DGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgtr.html'>stdlib_dorgtr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors of order N, as returned by
DSYTRD:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgtsqr.html'>stdlib_dorgtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>which are the first N columns of a product of real orthogonal
matrices of order M which are returned by DLATSQR
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
See the documentation for DLATSQR.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorgtsqr_row.html'>stdlib_dorgtsqr_row</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>orthonormal columns from the output of DLATSQR. These N orthonormal
columns are the first N columns of a product of complex unitary
matrices Q(k)_in of order M, which are returned by DLATSQR in
a special format.
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
The input matrices Q(k)_in are stored in row and column blocks in A.
See the documentation of DLATSQR for more details on the format of
Q(k)_in, where each Q(k)_in is represented by block Householder
transformations. This routine calls an auxiliary routine DLARFB_GETT,
where the computation is performed on each individual block. The
algorithm first sweeps NB-sized column blocks from the right to left
starting in the bottom row block and continues to the top row block
(hence _ROW in the routine name). This sweep is in reverse order of
the order in which DLATSQR generates the output blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorhr_col.html'>stdlib_dorhr_col</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>as input, stored in A, and performs Householder Reconstruction (HR),
i.e. reconstructs Householder vectors V(i) implicitly representing
another M-by-N matrix Q_out, with the property that Q_in = Q_out*S,
where S is an N-by-N diagonal matrix with diagonal entries
equal to +1 or -1. The Householder vectors (columns V(i) of V) are
stored in A on output, and the diagonal entries of S are stored in D.
Block reflectors are also returned in T
(same output format as DGEQRT).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorm22.html'>stdlib_dorm22</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_dorm2l.html'>stdlib_dorm2l</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T * C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGEQLF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorm2r.html'>stdlib_dorm2r</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGEQRF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormbr.html'>stdlib_dormbr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>If VECT = 'Q', DORMBR: overwrites the general real M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
If VECT = 'P', DORMBR overwrites the general real M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      P * C          C * P
TRANS = 'T':      P<strong>T * C       C * P</strong>T
Here Q and P<strong>T are the orthogonal matrices determined by DGEBRD when
reducing a real matrix A to bidiagonal form: A = Q * B * P</strong>T. Q and
P<strong>T are defined as products of elementary reflectors H(i) and G(i)
respectively.
Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the
order of the orthogonal matrix Q or P</strong>T that is applied.
If VECT = 'Q', A is assumed to have been an NQ-by-K matrix:
if nq &gt;= k, Q = H(1) H(2) . . . H(k);
if nq &lt; k, Q = H(1) H(2) . . . H(nq-1).
If VECT = 'P', A is assumed to have been a K-by-NQ matrix:
if k &lt; nq, P = G(1) G(2) . . . G(k);
if k &gt;= nq, P = G(1) G(2) . . . G(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormhr.html'>stdlib_dormhr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
IHI-ILO elementary reflectors, as returned by DGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dorml2.html'>stdlib_dorml2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGELQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormlq.html'>stdlib_dormlq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGELQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormql.html'>stdlib_dormql</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by DGEQLF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormqr.html'>stdlib_dormqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGEQRF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormr2.html'>stdlib_dormr2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGERQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormr3.html'>stdlib_dormr3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'C',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DTZRZF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormrq.html'>stdlib_dormrq</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DGERQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormrz.html'>stdlib_dormrz</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by DTZRZF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dormtr.html'>stdlib_dormtr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by DSYTRD:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbcon.html'>stdlib_dpbcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite band matrix using the
Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by DPBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbequ.html'>stdlib_dpbequ</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric positive definite band matrix A and reduce its condition
number (with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbrfs.html'>stdlib_dpbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite
and banded, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbstf.html'>stdlib_dpbstf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric positive definite band matrix A.
This routine is designed to be used in conjunction with DSBGST.
The factorization has the form  A = S*<em>T</em>S  where S is a band matrix
of the same bandwidth as A and the following structure:
S = ( U    )
( M  L )
where U is upper triangular of order m = (n+kd)/2, and L is lower
triangular of order n-m.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbsv.html'>stdlib_dpbsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite band matrix and X
and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>T * U,  if UPLO = 'U', or
A = L * L</strong>T,  if UPLO = 'L',
where U is an upper triangular band matrix, and L is a lower
triangular band matrix, with the same number of superdiagonals or
subdiagonals as A.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbsvx.html'>stdlib_dpbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>compute the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric positive definite band matrix and X
and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbtf2.html'>stdlib_dpbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>T * U ,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix, U**T is the transpose of U, and
L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbtrf.html'>stdlib_dpbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpbtrs.html'>stdlib_dpbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite band matrix A using the Cholesky factorization
A = U<strong>T<em>U or A = L</em>L</strong>T computed by DPBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpftrf.html'>stdlib_dpftrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpftri.html'>stdlib_dpftri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T
computed by DPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpftrs.html'>stdlib_dpftrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>T<em>U or A = L</em>L</strong>T computed by DPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpocon.html'>stdlib_dpocon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite matrix using the
Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by DPOTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpoequ.html'>stdlib_dpoequ</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpoequb.html'>stdlib_dpoequb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.
This routine differs from DPOEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled diagonal entries are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dporfs.html'>stdlib_dporfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite,
and provides error bounds and backward error estimates for the
solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dposv.html'>stdlib_dposv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite matrix and X and B
are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>T* U,  if UPLO = 'U', or
A = L * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dposvx.html'>stdlib_dposvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>compute the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric positive definite matrix and X and B
are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpotf2.html'>stdlib_dpotf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>T * U ,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpotrf.html'>stdlib_dpotrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpotrf2.html'>stdlib_dpotrf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A using the recursive algorithm.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = n/2
[  A21 | A22  ]       n2 = n-n1
The subroutine calls itself to factor A11. Update and scale A21
or A12, update A22 then calls itself to factor A22.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpotri.html'>stdlib_dpotri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T
computed by DPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpotrs.html'>stdlib_dpotrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>T<em>U or A = L</em>L</strong>T computed by DPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dppcon.html'>stdlib_dppcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite packed matrix using
the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by
DPPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dppequ.html'>stdlib_dppequ</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric positive definite matrix A in packed storage and reduce
its condition number (with respect to the two-norm).  S contains the
scale factors, S(i)=1/sqrt(A(i,i)), chosen so that the scaled matrix
B with elements B(i,j)=S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.
This choice of S puts the condition number of B within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpprfs.html'>stdlib_dpprfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dppsv.html'>stdlib_dppsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>T* U,  if UPLO = 'U', or
A = L * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dppsvx.html'>stdlib_dppsvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>compute the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpptrf.html'>stdlib_dpptrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A stored in packed format.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpptri.html'>stdlib_dpptri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T
computed by DPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpptrs.html'>stdlib_dpptrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite matrix A in packed storage using the Cholesky
factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by DPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpstf2.html'>stdlib_dpstf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>pivoting of a real symmetric positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>T * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpstrf.html'>stdlib_dpstrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>pivoting of a real symmetric positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>T * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dptcon.html'>stdlib_dptcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite tridiagonal matrix
using the factorization A = L<em>D</em>L<strong>T or A = U</strong>T<em>D</em>U computed by
DPTTRF.
Norm(inv(A)) is computed by a direct method, and the reciprocal of
the condition number is computed as
RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpteqr.html'>stdlib_dpteqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric positive definite tridiagonal matrix by first factoring the
matrix using DPTTRF, and then calling DBDSQR to compute the singular
values of the bidiagonal factor.
This routine computes the eigenvalues of the positive definite
tridiagonal matrix to high relative accuracy.  This means that if the
eigenvalues range over many orders of magnitude in size, then the
small eigenvalues and corresponding eigenvectors will be computed
more accurately than, for example, with the standard QR method.
The eigenvectors of a full or band symmetric positive definite matrix
can also be found if DSYTRD, DSPTRD, or DSBTRD has been used to
reduce this matrix to tridiagonal form. (The reduction to tridiagonal
form, however, may preclude the possibility of obtaining high
relative accuracy in the small eigenvalues of the original matrix, if
these eigenvalues range over many orders of magnitude.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dptrfs.html'>stdlib_dptrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite
and tridiagonal, and provides error bounds and backward error
estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dptsv.html'>stdlib_dptsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A<em>X = B, where A is an N-by-N symmetric positive definite tridiagonal
matrix, and X and B are N-by-NRHS matrices.
A is factored as A = L</em>D<em>L</em>*T, and the factored form of A is then
used to solve the system of equations.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dptsvx.html'>stdlib_dptsvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to a real system of linear equations A*X = B, where A is an N-by-N
symmetric positive definite tridiagonal matrix and X and B are
N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpttrf.html'>stdlib_dpttrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>positive definite tridiagonal matrix A.  The factorization may also
be regarded as having the form A = U<em><em>T</em>D</em>U.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dpttrs.html'>stdlib_dpttrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B
using the L<em>D</em>L**T factorization of A computed by DPTTRF.  D is a
diagonal matrix specified in the vector D, L is a unit bidiagonal
matrix whose subdiagonal is specified in the vector E, and X and B
are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dptts2.html'>stdlib_dptts2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B
using the L<em>D</em>L**T factorization of A computed by DPTTRF.  D is a
diagonal matrix specified in the vector D, L is a unit bidiagonal
matrix whose subdiagonal is specified in the vector E, and X and B
are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_drot.html'>stdlib_drot</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_drotg.html'>stdlib_drotg</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_drotg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_drotm.html'>stdlib_drotm</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>APPLY THE MODIFIED GIVENS TRANSFORMATION, H, TO THE 2 BY N MATRIX
(DX<strong>T) , WHERE </strong>T INDICATES TRANSPOSE. THE ELEMENTS OF DX ARE IN
(DY<em><em>T)
DX(LX+I</em>INCX), I = 0 TO N-1, WHERE LX = 1 IF INCX &gt;= 0, ELSE
LX = (-INCX)</em>N, AND SIMILARLY FOR SY USING LY AND INCY.
WITH DPARAM(1)=DFLAG, H HAS ONE OF THE FOLLOWING FORMS..
DFLAG=-1._dp     DFLAG=0._dp        DFLAG=1._dp     DFLAG=-2.D0
(DH11  DH12)    (1._dp  DH12)    (DH11  1._dp)    (1._dp  0._dp)
H=(          )    (          )    (          )    (          )
(DH21  DH22),   (DH21  1._dp),   (-1._dp DH22),   (0._dp  1._dp).
SEE DROTMG FOR A DESCRIPTION OF DATA STORAGE IN DPARAM.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_drotmg.html'>stdlib_drotmg</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>CONSTRUCT THE MODIFIED GIVENS TRANSFORMATION MATRIX H WHICH ZEROS
THE SECOND COMPONENT OF THE 2-VECTOR  (SQRT(DD1)<em>DX1,SQRT(DD2)    DY2)</em>*T.
WITH DPARAM(1)=DFLAG, H HAS ONE OF THE FOLLOWING FORMS..
DFLAG=-1._dp     DFLAG=0._dp        DFLAG=1._dp     DFLAG=-2.D0
(DH11  DH12)    (1._dp  DH12)    (DH11  1._dp)    (1._dp  0._dp)
H=(          )    (          )    (          )    (          )
(DH21  DH22),   (DH21  1._dp),   (-1._dp DH22),   (0._dp  1._dp).
LOCATIONS 2-4 OF DPARAM CONTAIN DH11, DH21, DH12, AND DH22
RESPECTIVELY. (VALUES OF 1._dp, -1._dp, OR 0._dp IMPLIED BY THE
VALUE OF DPARAM(1) ARE NOT STORED IN DPARAM.)
THE VALUES OF GAMSQ AND RGAMSQ SET IN THE DATA STATEMENT MAY BE
INEXACT.  THIS IS OK AS THEY ARE ONLY USED FOR TESTING THE SIZE
OF DD1 AND DD2.  ALL ACTUAL SCALING OF DATA IS DONE USING GAM.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_droundup_lwork.html'>stdlib_droundup_lwork</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This routine guarantees it is rounded up instead of down by
multiplying LWORK by 1+eps when it is necessary, where eps is the relative machine precision.
E.g.,
float( 9007199254740993            ) == 9007199254740992
float( 9007199254740993 ) * (1.+eps) == 9007199254740994
\return DROUNDUP_LWORK</p><a href="../proc/stdlib_droundup_lwork.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_drscl.html'>stdlib_drscl</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>This is done without overflow or underflow as long as
the final result x/a does not overflow or underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsb2st_kernels.html'>stdlib_dsb2st_kernels</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>subroutine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbev.html'>stdlib_dsbev</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real symmetric band matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbevd.html'>stdlib_dsbevd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real symmetric band matrix A. If eigenvectors are desired, it uses
a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbevx.html'>stdlib_dsbevx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric band matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbgst.html'>stdlib_dsbgst</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenproblem  A<em>x = lambda</em>B<em>x  to standard form  C</em>y = lambda<em>y,
such that C has the same bandwidth as A.
B must have been previously factorized as S</em><em>T</em>S by DPBSTF, using a
split Cholesky factorization. A is overwritten by C = X<strong>T<em>A</em>X, where
X = S</strong>(-1)*Q and Q is an orthogonal matrix chosen to preserve the
bandwidth of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbgv.html'>stdlib_dsbgv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be symmetric
and banded, and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbgvd.html'>stdlib_dsbgvd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of the
form A<em>x=(lambda)</em>B*x.  Here A and B are assumed to be symmetric and
banded, and B is also positive definite.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbgvx.html'>stdlib_dsbgvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x.  Here A and B are assumed to be symmetric
and banded, and B is also positive definite.  Eigenvalues and
eigenvectors can be selected by specifying either all eigenvalues,
a range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbmv.html'>stdlib_dsbmv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric band matrix, with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsbtrd.html'>stdlib_dsbtrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>tridiagonal form T by an orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dscal.html'>stdlib_dscal</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>uses unrolled loops for increment equal to 1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsdot.html'>stdlib_dsdot</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Function</td><td><p>Compute the inner product of two vectors with extended
precision accumulation and result.
Returns D.P. dot product accumulated in D.P., for S.P. SX and SY
DSDOT: = sum for I = 0 to N-1 of  SX(LX+I<em>INCX) * SY(LY+I</em>INCY),
where LX = 1 if INCX &gt;= 0, else LX = 1+(1-N)*INCX, and LY is
defined in a similar way using INCY.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsfrk.html'>stdlib_dsfrk</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for C in RFP Format.
DSFRK: performs one of the symmetric rank--k operations
C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where alpha and beta are real scalars, C is an n--by--n symmetric
matrix and A is an n--by--k matrix in the first case and a k--by--n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsgesv.html'>stdlib_dsgesv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
DSGESV first attempts to factorize the matrix in SINGLE PRECISION
and use this factorization within an iterative refinement procedure
to produce a solution with DOUBLE PRECISION normwise backward error
quality (see below). If the approach fails the method switches to a
DOUBLE PRECISION factorization and solve.
The iterative refinement is not going to be a winning strategy if
the ratio SINGLE PRECISION performance over DOUBLE PRECISION
performance is too small. A reasonable strategy should take the
number of right-hand sides and the size of the matrix into account.
This might be done with a call to ILAENV in the future. Up to now, we
always try iterative refinement.
The iterative refinement process is stopped if
ITER &gt; ITERMAX
or for all the RHS we have:
RNRM &lt; SQRT(N)<em>XNRM</em>ANRM<em>EPS</em>BWDMAX
where
o ITER is the number of the current iteration in the iterative
refinement process
o RNRM is the infinity-norm of the residual
o XNRM is the infinity-norm of the solution
o ANRM is the infinity-operator-norm of the matrix A
o EPS is the machine epsilon returned by DLAMCH('Epsilon')
The value ITERMAX and BWDMAX are fixed to 30 and 1.0D+00
respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspcon.html'>stdlib_dspcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric packed matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by DSPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspev.html'>stdlib_dspev</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real symmetric matrix A in packed storage.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspevd.html'>stdlib_dspevd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A in packed storage. If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspevx.html'>stdlib_dspevx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A in packed storage.  Eigenvalues/vectors
can be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspgst.html'>stdlib_dspgst</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to standard form, using packed storage.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T</em>A<em>L.
B must have been previously factorized as U</em><em>T</em>U or L<em>L</em>*T by DPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspgv.html'>stdlib_dspgv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be symmetric, stored in packed format,
and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspgvd.html'>stdlib_dspgvd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be symmetric, stored in packed format, and B is also
positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspgvx.html'>stdlib_dspgvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A
and B are assumed to be symmetric, stored in packed storage, and B
is also positive definite.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of indices
for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspmv.html'>stdlib_dspmv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsposv.html'>stdlib_dsposv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite matrix and X and B
are N-by-NRHS matrices.
DSPOSV first attempts to factorize the matrix in SINGLE PRECISION
and use this factorization within an iterative refinement procedure
to produce a solution with DOUBLE PRECISION normwise backward error
quality (see below). If the approach fails the method switches to a
DOUBLE PRECISION factorization and solve.
The iterative refinement is not going to be a winning strategy if
the ratio SINGLE PRECISION performance over DOUBLE PRECISION
performance is too small. A reasonable strategy should take the
number of right-hand sides and the size of the matrix into account.
This might be done with a call to ILAENV in the future. Up to now, we
always try iterative refinement.
The iterative refinement process is stopped if
ITER &gt; ITERMAX
or for all the RHS we have:
RNRM &lt; SQRT(N)<em>XNRM</em>ANRM<em>EPS</em>BWDMAX
where
o ITER is the number of the current iteration in the iterative
refinement process
o RNRM is the infinity-norm of the residual
o XNRM is the infinity-norm of the solution
o ANRM is the infinity-operator-norm of the matrix A
o EPS is the machine epsilon returned by DLAMCH('Epsilon')
The value ITERMAX and BWDMAX are fixed to 30 and 1.0D+00
respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspr.html'>stdlib_dspr</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**T + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspr2.html'>stdlib_dspr2</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>T + alpha<em>y</em>x</strong>T + A,
where alpha is a scalar, x and y are n element vectors and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsprfs.html'>stdlib_dsprfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspsv.html'>stdlib_dspsv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is symmetric and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dspsvx.html'>stdlib_dspsvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = L<em>D</em>L**T to compute the solution to a real system of linear
equations A * X = B, where A is an N-by-N symmetric matrix stored
in packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsptrd.html'>stdlib_dsptrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric tridiagonal form T by an orthogonal similarity
transformation: Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsptrf.html'>stdlib_dsptrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>in packed format using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsptri.html'>stdlib_dsptri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by DSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsptrs.html'>stdlib_dsptrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by DSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstebz.html'>stdlib_dstebz</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix T.  The user may ask for all eigenvalues, all eigenvalues
in the half-open interval (VL, VU], or the IL-th through IU-th
eigenvalues.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstedc.html'>stdlib_dstedc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.
The eigenvectors of a full or band real symmetric matrix can also be
found if DSYTRD or DSPTRD or DSBTRD has been used to reduce this
matrix to tridiagonal form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See DLAED3 for details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstegr.html'>stdlib_dstegr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
DSTEGR is a compatibility wrapper around the improved DSTEMR routine.
See DSTEMR for further details.
One important change is that the ABSTOL parameter no longer provides any
benefit and hence is no longer used.
Note : DSTEGR and DSTEMR work only on machines which follow
IEEE-754 floating-point standard in their handling of infinities and
NaNs.  Normal execution may create these exceptiona values and hence
may abort due to a floating point exception in environments which
do not conform to the IEEE-754 standard.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstein.html'>stdlib_dstein</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix T corresponding to specified eigenvalues, using inverse
iteration.
The maximum number of iterations allowed for each eigenvector is
specified by an internal parameter MAXITS (currently set to 5).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstemr.html'>stdlib_dstemr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
Depending on the number of desired eigenvalues, these are computed either
by bisection or the dqds algorithm. Numerically orthogonal eigenvectors are
computed by the use of various suitable L D L^T factorizations near clusters
of close eigenvalues (referred to as RRRs, Relatively Robust
Representations). An informal sketch of the algorithm follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
For more details, see:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Further Details
1.DSTEMR works only on machines which follow IEEE-754
floating-point standard in their handling of infinities and NaNs.
This permits the use of efficient inner loops avoiding a check for
zero divisors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsteqr.html'>stdlib_dsteqr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the implicit QL or QR method.
The eigenvectors of a full or band symmetric matrix can also be found
if DSYTRD or DSPTRD or DSBTRD has been used to reduce this matrix to
tridiagonal form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsterf.html'>stdlib_dsterf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the Pal-Walker-Kahan variant of the QL or QR algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstev.html'>stdlib_dstev</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real symmetric tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstevd.html'>stdlib_dstevd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real symmetric tridiagonal matrix. If eigenvectors are desired, it
uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstevr.html'>stdlib_dstevr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T.  Eigenvalues and
eigenvectors can be selected by specifying either a range of values
or a range of indices for the desired eigenvalues.
Whenever possible, DSTEVR calls DSTEMR to compute the
eigenspectrum using Relatively Robust Representations.  DSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows. For the i-th
unreduced block of T,
(a) Compute T - sigma_i = L_i D_i L_i^T, such that L_i D_i L_i^T
is a relatively robust representation,
(b) Compute the eigenvalues, lambda_j, of L_i D_i L_i^T to high
relative accuracy by the dqds algorithm,
(c) If there is a cluster of close eigenvalues, "choose" sigma_i
close to the cluster, and go to step (a),
(d) Given the approximate eigenvalue lambda_j of L_i D_i L_i^T,
compute the corresponding eigenvector by forming a
rank-revealing twisted factorization.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem", by Inderjit Dhillon,
Computer Science Division Technical Report No. UCB//CSD-97-971,
UC Berkeley, May 1997.
Note 1 : DSTEVR calls DSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
DSTEVR calls DSTEBZ and DSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of DSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dstevx.html'>stdlib_dstevx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix A.  Eigenvalues and
eigenvectors can be selected by specifying either a range of values
or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dswap.html'>stdlib_dswap</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>uses unrolled loops for increments equal to 1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsycon.html'>stdlib_dsycon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by DSYTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsycon_rook.html'>stdlib_dsycon_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by DSYTRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyconv.html'>stdlib_dsyconv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Get Non-diag elements of D (returned in workspace) and
apply or reverse permutation done in TRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyconvf.html'>stdlib_dsyconvf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
DSYCONVF: converts the factorization output format used in
DSYTRF provided on entry in parameter A into the factorization
output format used in DSYTRF_RK (or DSYTRF_BK) that is stored
on exit in parameters A and E. It also converts in place details of
the intechanges stored in IPIV from the format used in DSYTRF into
the format used in DSYTRF_RK (or DSYTRF_BK).
If parameter WAY = 'R':
DSYCONVF performs the conversion in reverse direction, i.e.
converts the factorization output format used in DSYTRF_RK
(or DSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in DSYTRF that is stored
on exit in parameter A. It also converts in place details of
the intechanges stored in IPIV from the format used in DSYTRF_RK
(or DSYTRF_BK) into the format used in DSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyconvf_rook.html'>stdlib_dsyconvf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
DSYCONVF_ROOK: converts the factorization output format used in
DSYTRF_ROOK provided on entry in parameter A into the factorization
output format used in DSYTRF_RK (or DSYTRF_BK) that is stored
on exit in parameters A and E. IPIV format for DSYTRF_ROOK and
DSYTRF_RK (or DSYTRF_BK) is the same and is not converted.
If parameter WAY = 'R':
DSYCONVF_ROOK performs the conversion in reverse direction, i.e.
converts the factorization output format used in DSYTRF_RK
(or DSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in DSYTRF_ROOK that is stored
on exit in parameter A. IPIV format for DSYTRF_ROOK and
DSYTRF_RK (or DSYTRF_BK) is the same and is not converted.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyequb.html'>stdlib_dsyequb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyev.html'>stdlib_dsyev</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyevd.html'>stdlib_dsyevd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>real symmetric matrix A. If eigenvectors are desired, it uses a
divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.
Because of large use of BLAS of level 3, DSYEVD needs N**2 more
workspace than DSYEVX.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyevr.html'>stdlib_dsyevr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of
indices for the desired eigenvalues.
DSYEVR first reduces the matrix A to tridiagonal form T with a call
to DSYTRD.  Then, whenever possible, DSYEVR calls DSTEMR to compute
the eigenspectrum using Relatively Robust Representations.  DSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see DSTEMR's documentation and:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Note 1 : DSYEVR calls DSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
DSYEVR calls DSTEBZ and DSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of DSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyevx.html'>stdlib_dsyevx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of indices
for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsygs2.html'>stdlib_dsygs2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T </em>A<em>L.
B must have been previously factorized as U</em><em>T </em>U or L<em>L</em>*T by DPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsygst.html'>stdlib_dsygst</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T</em>A<em>L.
B must have been previously factorized as U</em><em>T</em>U or L<em>L</em>*T by DPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsygv.html'>stdlib_dsygv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be symmetric and B is also
positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsygvd.html'>stdlib_dsygvd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be symmetric and B is also positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsygvx.html'>stdlib_dsygvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A
and B are assumed to be symmetric and B is also positive definite.
Eigenvalues and eigenvectors can be selected by specifying either a
range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsymm.html'>stdlib_dsymm</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where alpha and beta are scalars,  A is a symmetric matrix and  B and
C are  m by n matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsymv.html'>stdlib_dsymv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyr.html'>stdlib_dsyr</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**T + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyr2.html'>stdlib_dsyr2</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>T + alpha<em>y</em>x</strong>T + A,
where alpha is a scalar, x and y are n element vectors and A is an n
by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyr2k.html'>stdlib_dsyr2k</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B<strong>T + alpha<em>B</em>A</strong>T + beta<em>C,
or
C := alpha</em>A<strong>T<em>B + alpha</em>B</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars, C is an  n by n  symmetric matrix
and  A and B  are  n by k  matrices  in the  first  case  and  k by n
matrices in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyrfs.html'>stdlib_dsyrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyrk.html'>stdlib_dsyrk</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars, C is an  n by n  symmetric matrix
and  A  is an  n by k  matrix in the first case and a  k by n  matrix
in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsysv.html'>stdlib_dsysv</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsysv_aa.html'>stdlib_dsysv_aa</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DSYSV computes the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>T * T * U,  if UPLO = 'U', or
A = L * T * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is symmetric tridiagonal. The factored
form of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsysv_rk.html'>stdlib_dsysv_rk</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations A * X = B, where A is an N-by-N symmetric matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
DSYTRF_RK is called to compute the factorization of a real
symmetric matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine DSYTRS_3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsysv_rook.html'>stdlib_dsysv_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
DSYTRF_ROOK is called to compute the factorization of a real
symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling DSYTRS_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsysvx.html'>stdlib_dsysvx</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>solution to a real system of linear equations A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsyswapr.html'>stdlib_dsyswapr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytd2.html'>stdlib_dsytd2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>form T by an orthogonal similarity transformation: Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytf2.html'>stdlib_dsytf2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytf2_rk.html'>stdlib_dsytf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytf2_rook.html'>stdlib_dsytf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrd.html'>stdlib_dsytrd</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>tridiagonal form T by an orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrd_sb2st.html'>stdlib_dsytrd_sb2st</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>tridiagonal form T by a orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrd_sy2sb.html'>stdlib_dsytrd_sy2sb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>band-diagonal form AB by a orthogonal similarity transformation:
Q**T * A * Q = AB.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrf.html'>stdlib_dsytrf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<strong>T<em>D</em>U  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrf_aa.html'>stdlib_dsytrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>T<em>T</em>U  or  A = L<em>T</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a symmetric tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrf_rk.html'>stdlib_dsytrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrf_rook.html'>stdlib_dsytrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytri.html'>stdlib_dsytri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by
DSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytri_rook.html'>stdlib_dsytri_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T
computed by DSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrs.html'>stdlib_dsytrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by DSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrs2.html'>stdlib_dsytrs2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by DSYTRF and converted by DSYCONV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrs_3.html'>stdlib_dsytrs_3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization computed
by DSYTRF_RK or DSYTRF_BK:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrs_aa.html'>stdlib_dsytrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<strong>T<em>T</em>U or
A = L<em>T</em>L</strong>T computed by DSYTRF_AA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dsytrs_rook.html'>stdlib_dsytrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by DSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtbcon.html'>stdlib_dtbcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>triangular band matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtbmv.html'>stdlib_dtbmv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular band matrix, with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtbrfs.html'>stdlib_dtbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular band
coefficient matrix.
The solution matrix X must be computed by DTBTRS or some other
means before entering this routine.  DTBRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtbsv.html'>stdlib_dtbsv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular band matrix, with ( k + 1 )
diagonals.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtbtrs.html'>stdlib_dtbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B,
where A is a triangular band matrix of order N, and B is an
N-by NRHS matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtfsm.html'>stdlib_dtfsm</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for A in RFP Format.
DTFSM:  solves the matrix equation
op( A )<em>X = alpha</em>B  or  X<em>op( A ) = alpha</em>B
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**T.
A is in Rectangular Full Packed (RFP) Format.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtftri.html'>stdlib_dtftri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>format.
This is a Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtfttp.html'>stdlib_dtfttp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>format (TF) to standard packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtfttr.html'>stdlib_dtfttr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>format (TF) to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgevc.html'>stdlib_dtgevc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a pair of real matrices (S,P), where S is a quasi-triangular matrix
and P is upper triangular.  Matrix pairs of this type are produced by
the generalized Schur factorization of a matrix pair (A,B):
A = Q<em>S</em>Z<strong>T,  B = Q<em>P</em>Z</strong>T
as computed by DGGHRD + DHGEQZ.
The right eigenvector x and the left eigenvector y of (S,P)
corresponding to an eigenvalue w are defined by:
S<em>x = w</em>P<em>x,  (y</em><em>H)</em>S = w<em>(y</em><em>H)</em>P,
where y<em><em>H denotes the conjugate tranpose of y.
The eigenvalues are not input to this routine, but are computed
directly from the diagonal blocks of S and P.
This routine returns the matrices X and/or Y of right and left
eigenvectors of (S,P), or the products Z</em>X and/or Q</em>Y,
where Z and Q are input matrices.
If Q and Z are the orthogonal factors from the generalized Schur
factorization of a matrix pair (A,B), then Z<em>X and Q</em>Y
are the matrices of right and left eigenvectors of (A,B).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgex2.html'>stdlib_dtgex2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of size 1-by-1 or 2-by-2 in an upper (quasi) triangular matrix pair
(A, B) by an orthogonal equivalence transformation.
(A, B) must be in generalized real Schur canonical form (as returned
by DGGES), i.e. A is block upper triangular with 1-by-1 and 2-by-2
diagonal blocks. B is upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)<strong>T = Q(out) * A(out) * Z(out)</strong>T
Q(in) * B(in) * Z(in)<strong>T = Q(out) * B(out) * Z(out)</strong>T</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgexc.html'>stdlib_dtgexc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix pair (A,B) using an orthogonal equivalence transformation
(A, B) = Q * (A, B) * Z<strong>T,
so that the diagonal block of (A, B) with row index IFST is moved
to row ILST.
(A, B) must be in generalized real Schur canonical form (as returned
by DGGES), i.e. A is block upper triangular with 1-by-1 and 2-by-2
diagonal blocks. B is upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)</strong>T = Q(out) * A(out) * Z(out)<strong>T
Q(in) * B(in) * Z(in)</strong>T = Q(out) * B(out) * Z(out)**T</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgsen.html'>stdlib_dtgsen</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix pair (A, B) (in terms of an orthonormal equivalence trans-
formation Q*<em>T * (A, B) * Z), so that a selected cluster of eigenvalues
appears in the leading diagonal blocks of the upper quasi-triangular
matrix A and the upper triangular B. The leading columns of Q and
Z form orthonormal bases of the corresponding left and right eigen-
spaces (deflating subspaces). (A, B) must be in generalized real
Schur canonical form (as returned by DGGES), i.e. A is block upper
triangular with 1-by-1 and 2-by-2 diagonal blocks. B is upper
triangular.
DTGSEN also computes the generalized eigenvalues
w(j) = (ALPHAR(j) + i</em>ALPHAI(j))/BETA(j)
of the reordered matrix pair (A, B).
Optionally, DTGSEN computes the estimates of reciprocal condition
numbers for eigenvalues and eigenspaces. These are Difu[(A11,B11),
(A22,B22)] and Difl[(A11,B11), (A22,B22)], i.e. the separation(s)
between the matrix pairs (A11, B11) and (A22,B22) that correspond to
the selected cluster and the eigenvalues outside the cluster, resp.,
and norms of "projections" onto left and right eigenspaces w.r.t.
the selected cluster in the (1,1)-block.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgsja.html'>stdlib_dtgsja</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>of two real upper triangular (or trapezoidal) matrices A and B.
On entry, it is assumed that matrices A and B have the following
forms, which may be obtained by the preprocessing subroutine DGGSVP
from a general M-by-N matrix A and P-by-N matrix B:
N-K-L  K    L
A =    K ( 0    A12  A13 ) if M-K-L &gt;= 0;
L ( 0     0   A23 )
M-K-L ( 0     0    0  )
N-K-L  K    L
A =  K ( 0    A12  A13 ) if M-K-L &lt; 0;
M-K ( 0     0   A23 )
N-K-L  K    L
B =  L ( 0     0   B13 )
P-L ( 0     0    0  )
where the K-by-K matrix A12 and L-by-L matrix B13 are nonsingular
upper triangular; A23 is L-by-L upper triangular if M-K-L &gt;= 0,
otherwise A23 is (M-K)-by-L upper trapezoidal.
On exit,
U<strong>T <em>A</em>Q = D1*( 0 R ),    V</strong>T <em>B</em>Q = D2<em>( 0 R ),
where U, V and Q are orthogonal matrices.
R is a nonsingular upper triangular matrix, and D1 and D2 are
``diagonal'' matrices, which are of the following structures:
If M-K-L &gt;= 0,
K  L
D1 =     K ( I  0 )
L ( 0  C )
M-K-L ( 0  0 )
K  L
D2 = L   ( 0  S )
P-L ( 0  0 )
N-K-L  K    L
( 0 R ) = K (  0   R11  R12 ) K
L (  0    0   R22 ) L
where
C = diag( ALPHA(K+1), ... , ALPHA(K+L) ),
S = diag( BETA(K+1),  ... , BETA(K+L) ),
C</em><em>2 + S</em><em>2 = I.
R is stored in A(1:K+L,N-K-L+1:N) on exit.
If M-K-L &lt; 0,
K M-K K+L-M
D1 =   K ( I  0    0   )
M-K ( 0  C    0   )
K M-K K+L-M
D2 =   M-K ( 0  S    0   )
K+L-M ( 0  0    I   )
P-L ( 0  0    0   )
N-K-L  K   M-K  K+L-M
( 0 R ) =    K ( 0    R11  R12  R13  )
M-K ( 0     0   R22  R23  )
K+L-M ( 0     0    0   R33  )
where
C = diag( ALPHA(K+1), ... , ALPHA(M) ),
S = diag( BETA(K+1),  ... , BETA(M) ),
C</em><em>2 + S</em>*2 = I.
R = ( R11 R12 R13 ) is stored in A(1:M, N-K-L+1:N) and R33 is stored
(  0  R22 R23 )
in B(M-K+1:L,N+M-K-L+1:N) on exit.
The computation of the orthogonal transformation matrices U, V or Q
is optional.  These matrices may either be formed explicitly, or they
may be postmultiplied into input matrices U1, V1, or Q1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgsna.html'>stdlib_dtgsna</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues and/or eigenvectors of a matrix pair (A, B) in
generalized real Schur canonical form (or of any matrix pair
(Q<em>A</em>Z<strong>T, Q<em>B</em>Z</strong>T) with orthogonal matrices Q and Z, where
Z**T denotes the transpose of Z.
(A, B) must be in generalized real Schur form (as returned by DGGES),
i.e. A is block upper triangular with 1-by-1 and 2-by-2 diagonal
blocks. B is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgsy2.html'>stdlib_dtgsy2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C                (1)
D * R - L * E = scale * F,
using Level 1 and 2 BLAS. where R and L are unknown M-by-N matrices,
(A, D), (B, E) and (C, F) are given matrix pairs of size M-by-M,
N-by-N and M-by-N, respectively, with real entries. (A, D) and (B, E)
must be in generalized Schur canonical form, i.e. A, B are upper
quasi triangular and D, E are upper triangular. The solution (R, L)
overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output scaling factor
chosen to avoid overflow.
In matrix notation solving equation (1) corresponds to solve
Z<em>x = scale</em>b, where Z is defined as
Z = [ kron(In, A)  -kron(B<strong>T, Im) ]             (2)
[ kron(In, D)  -kron(E</strong>T, Im) ],
Ik is the identity matrix of size k and X<strong>T is the transpose of X.
kron(X, Y) is the Kronecker product between the matrices X and Y.
In the process of solving (1), we solve a number of such systems
where Dim(In), Dim(In) = 1 or 2.
If TRANS = 'T', solve the transposed system Z</strong>T<em>y = scale</em>b for y,
which is equivalent to solve for R and L in
A<strong>T * R  + D</strong>T * L   = scale * C           (3)
R  * B<strong>T + L  * E</strong>T  = scale * -F
This case is used to compute an estimate of Dif[(A, D), (B, E)] =
sigma_min(Z) using reverse communication with DLACON.
DTGSY2 also (IJOB &gt;= 1) contributes to the computation in DTGSYL
of an upper bound on the separation between to matrix pairs. Then
the input (A, D), (B, E) are sub-pencils of the matrix pair in
DTGSYL. See DTGSYL for details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtgsyl.html'>stdlib_dtgsyl</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C                 (1)
D * R - L * E = scale * F
where R and L are unknown m-by-n matrices, (A, D), (B, E) and
(C, F) are given matrix pairs of size m-by-m, n-by-n and m-by-n,
respectively, with real entries. (A, D) and (B, E) must be in
generalized (real) Schur canonical form, i.e. A, B are upper quasi
triangular and D, E are upper triangular.
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output
scaling factor chosen to avoid overflow.
In matrix notation (1) is equivalent to solve  Zx = scale b, where
Z is defined as
Z = [ kron(In, A)  -kron(B<strong>T, Im) ]         (2)
[ kron(In, D)  -kron(E</strong>T, Im) ].
Here Ik is the identity matrix of size k and X<strong>T is the transpose of
X. kron(X, Y) is the Kronecker product between the matrices X and Y.
If TRANS = 'T', DTGSYL solves the transposed system Z</strong>T<em>y = scale</em>b,
which is equivalent to solve for R and L in
A<strong>T * R + D</strong>T * L = scale * C           (3)
R * B<strong>T + L * E</strong>T = scale * -F
This case (TRANS = 'T') is used to compute an one-norm-based estimate
of Dif[(A,D), (B,E)], the separation between the matrix pairs (A,D)
and (B,E), using DLACON.
If IJOB &gt;= 1, DTGSYL computes a Frobenius norm-based estimate
of Dif[(A,D),(B,E)]. That is, the reciprocal of a lower bound on the
reciprocal of the smallest singular value of Z. See [1-2] for more
information.
This is a level 3 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpcon.html'>stdlib_dtpcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtplqt.html'>stdlib_dtplqt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtplqt2.html'>stdlib_dtplqt2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpmlqt.html'>stdlib_dtpmlqt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>DTPMQRT applies a real orthogonal matrix Q obtained from a
"triangular-pentagonal" real block reflector H to a general
real matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpmqrt.html'>stdlib_dtpmqrt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" real block reflector H to a general
real matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpmv.html'>stdlib_dtpmv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpqrt.html'>stdlib_dtpqrt</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpqrt2.html'>stdlib_dtpqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtprfb.html'>stdlib_dtprfb</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>transpose H**T to a real matrix C, which is composed of two
blocks A and B, either from the left or right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtprfs.html'>stdlib_dtprfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular packed
coefficient matrix.
The solution matrix X must be computed by DTPTRS or some other
means before entering this routine.  DTPRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpsv.html'>stdlib_dtpsv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix, supplied in packed form.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtptri.html'>stdlib_dtptri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A stored in packed format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtptrs.html'>stdlib_dtptrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B,
where A is a triangular matrix of order N stored in packed format,
and B is an N-by-NRHS matrix.  A check is made to verify that A is
nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpttf.html'>stdlib_dtpttf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtpttr.html'>stdlib_dtpttr</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrcon.html'>stdlib_dtrcon</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrevc.html'>stdlib_dtrevc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real upper quasi-triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a real general matrix:  A = Q<em>T</em>Q<strong>T, as computed by DHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal blocks of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix.  If Q is the orthogonal factor that reduces a matrix
A to Schur form T, then Q<em>X and Q</em>Y are the matrices of right and
left eigenvectors of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrevc3.html'>stdlib_dtrevc3</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>a real upper quasi-triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a real general matrix:  A = Q<em>T</em>Q<strong>T, as computed by DHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>T)<em>T = w</em>(y<strong>T)
where y</strong>T denotes the transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal blocks of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix. If Q is the orthogonal factor that reduces a matrix
A to Schur form T, then Q<em>X and Q</em>Y are the matrices of right and
left eigenvectors of A.
This uses a Level 3 BLAS version of the back transformation.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrexc.html'>stdlib_dtrexc</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q<strong>T, so that the diagonal block of T with row index IFST is
moved to row ILST.
The real Schur form T is reordered by an orthogonal similarity
transformation Z</strong>T<em>T</em>Z, and optionally the matrix Q of Schur vectors
is updated by postmultiplying it with Z.
T must be in Schur canonical form (as returned by DHSEQR), that is,
block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each
2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrmm.html'>stdlib_dtrmm</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>B := alpha<em>op( A )</em>B,   or   B := alpha<em>B</em>op( A ),
where  alpha  is a scalar,  B  is an m by n matrix,  A  is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrmv.html'>stdlib_dtrmv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrrfs.html'>stdlib_dtrrfs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular
coefficient matrix.
The solution matrix X must be computed by DTRTRS or some other
means before entering this routine.  DTRRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrsen.html'>stdlib_dtrsen</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q**T, so that a selected cluster of eigenvalues appears in
the leading diagonal blocks of the upper quasi-triangular matrix T,
and the leading columns of Q form an orthonormal basis of the
corresponding right invariant subspace.
Optionally the routine computes the reciprocal condition numbers of
the cluster of eigenvalues and/or the invariant subspace.
T must be in Schur canonical form (as returned by DHSEQR), that is,
block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each
2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrsm.html'>stdlib_dtrsm</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>op( A )<em>X = alpha</em>B,   or   X<em>op( A ) = alpha</em>B,
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**T.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrsna.html'>stdlib_dtrsna</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>eigenvalues and/or right eigenvectors of a real upper
quasi-triangular matrix T (or of any matrix Q<em>T</em>Q**T with Q
orthogonal).
T must be in Schur canonical form (as returned by DHSEQR), that is,
block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each
2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrsv.html'>stdlib_dtrsv</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrsyl.html'>stdlib_dtrsyl</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>op(A)<em>X + X</em>op(B) = scale<em>C or
op(A)</em>X - X<em>op(B) = scale</em>C,
where op(A) = A or A**T, and  A and B are both upper quasi-
triangular. A is M-by-M and B is N-by-N; the right hand side C and
the solution X are M-by-N; and scale is an output scale factor, set
&lt;= 1 to avoid overflow in X.
A and B must be in Schur canonical form (as returned by DHSEQR), that
is, block upper triangular with 1-by-1 and 2-by-2 diagonal blocks;
each 2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrti2.html'>stdlib_dtrti2</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix.
This is the Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrtri.html'>stdlib_dtrtri</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>matrix A.
This is the Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrtrs.html'>stdlib_dtrtrs</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B,
where A is a triangular matrix of order N, and B is an N-by-NRHS
matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrttf.html'>stdlib_dtrttf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF) .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtrttp.html'>stdlib_dtrttp</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dtzrzf.html'>stdlib_dtzrzf</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Subroutine</td><td><p>to upper triangular form by means of orthogonal transformations.
The upper trapezoidal matrix A is factored as
A = ( R  0 ) * Z,
where Z is an N-by-N orthogonal matrix and R is an M-by-M upper
triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dzasum.html'>stdlib_dzasum</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Function</td><td><p>returns a double precision result.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_dznrm2.html'>stdlib_dznrm2</a></td><td><a href='../module/stdlib_linalg_blas_d.html'>stdlib_linalg_blas_d</a></td><td>Function</td><td><p>!</p><a href="../proc/stdlib_dznrm2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_dzsum1.html'>stdlib_dzsum1</a></td><td><a href='../module/stdlib_linalg_lapack_d.html'>stdlib_linalg_lapack_d</a></td><td>Function</td><td><p>vector and returns a double precision result.
Based on DZASUM from the Level 1 BLAS.
The change is to use the 'genuine' absolute value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_icamax.html'>stdlib_icamax</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_icmax1.html'>stdlib_icmax1</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>Based on ICAMAX from Level 1 BLAS.
The change is to use the 'genuine' absolute value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_idamax.html'>stdlib_idamax</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_ieeeck.html'>stdlib_ieeeck</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>possibly NaN arithmetic is safe (i.e. will not trap).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaclc.html'>stdlib_ilaclc</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaclr.html'>stdlib_ilaclr</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_iladiag.html'>stdlib_iladiag</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This subroutine translated from a character string specifying if a
matrix has unit diagonal or not to the relevant BLAST-specified
integer constant.
ILADIAG: returns an INTEGER.  If ILADIAG: &lt; 0, then the input is not a
character indicating a unit or non-unit diagonal.  Otherwise ILADIAG
returns the constant value corresponding to DIAG.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_iladlc.html'>stdlib_iladlc</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_iladlr.html'>stdlib_iladlr</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaenv.html'>stdlib_ilaenv</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>parameters for the local environment.  See ISPEC for a description of
the parameters.
ILAENV returns an INTEGER
if ILAENV &gt;= 0: ILAENV returns the value of the parameter specified by ISPEC
if ILAENV &lt; 0:  if ILAENV = -k, the k-th argument had an illegal value.
This version provides a set of parameters which should give good,
but not optimal, performance on many of the currently available
computers.  Users are encouraged to modify this subroutine to set
the tuning parameters for their particular machine using the option
and problem size information in the arguments.
This routine will not function correctly if it is converted to all
lower case.  Converting it to all upper case is allowed.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaenv2stage.html'>stdlib_ilaenv2stage</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>parameters for the local environment.  See ISPEC for a description of
the parameters.
It sets problem and machine dependent parameters useful for *_2STAGE and
related subroutines.
ILAENV2STAGE returns an INTEGER
if ILAENV2STAGE &gt;= 0: ILAENV2STAGE returns the value of the parameter
specified by ISPEC
if ILAENV2STAGE &lt; 0:  if ILAENV2STAGE = -k, the k-th argument had an
illegal value.
This version provides a set of parameters which should give good,
but not optimal, performance on many of the currently available
computers for the 2-stage solvers. Users are encouraged to modify this
subroutine to set the tuning parameters for their particular machine using
the option and problem size information in the arguments.
This routine will not function correctly if it is converted to all
lower case.  Converting it to all upper case is allowed.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaprec.html'>stdlib_ilaprec</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This subroutine translated from a character string specifying an
intermediate precision to the relevant BLAST-specified integer
constant.
ILAPREC: returns an INTEGER.  If ILAPREC: &lt; 0, then the input is not a
character indicating a supported intermediate precision.  Otherwise
ILAPREC returns the constant value corresponding to PREC.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaslc.html'>stdlib_ilaslc</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_ilaslr.html'>stdlib_ilaslr</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_ilatrans.html'>stdlib_ilatrans</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This subroutine translates from a character string specifying a
transposition operation to the relevant BLAST-specified integer
constant.
ILATRANS: returns an INTEGER.  If ILATRANS: &lt; 0, then the input is not
a character indicating a transposition operator.  Otherwise ILATRANS
returns the constant value corresponding to TRANS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ilauplo.html'>stdlib_ilauplo</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This subroutine translated from a character string specifying a
upper- or lower-triangular matrix to the relevant BLAST-specified
integer constant.
ILAUPLO: returns an INTEGER.  If ILAUPLO: &lt; 0, then the input is not
a character indicating an upper- or lower-triangular matrix.
Otherwise ILAUPLO returns the constant value corresponding to UPLO.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ilazlc.html'>stdlib_ilazlc</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_ilazlr.html'>stdlib_ilazlr</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_iparam2stage.html'>stdlib_iparam2stage</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This program sets problem and machine dependent parameters
useful for xHETRD_2STAGE, xHETRD_HE2HB, xHETRD_HB2ST,
xGEBRD_2STAGE, xGEBRD_GE2GB, xGEBRD_GB2BD
and related subroutines for eigenvalue problems.
It is called whenever ILAENV is called with 17 &lt;= ISPEC &lt;= 21.
It is called whenever ILAENV2STAGE is called with 1 &lt;= ISPEC &lt;= 5
with a direct conversion ISPEC + 16.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_iparmq.html'>stdlib_iparmq</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This program sets problem and machine dependent parameters
useful for xHSEQR and related subroutines for eigenvalue
problems. It is called whenever
IPARMQ: is called with 12 &lt;= ISPEC &lt;= 16</p></td></tr>
			   <tr><td><a href='../proc/stdlib_isamax.html'>stdlib_isamax</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_izamax.html'>stdlib_izamax</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_izmax1.html'>stdlib_izmax1</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>Based on IZAMAX from Level 1 BLAS.
The change is to use the 'genuine' absolute value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_lsame.html'>stdlib_lsame</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td><p>case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_lsamen.html'>stdlib_lsamen</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>first N letters of CB, regardless of case.
LSAMEN returns .TRUE. if CA and CB are equivalent except for case
and .FALSE. otherwise.  LSAMEN also returns .FALSE. if LEN( CA )
or LEN( CB ) is less than N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sasum.html'>stdlib_sasum</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Function</td><td><p>uses unrolled loops for increment equal to one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_saxpy.html'>stdlib_saxpy</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>uses unrolled loops for increments equal to one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sbbcsd.html'>stdlib_sbbcsd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>bidiagonal-block form,
[ B11 | B12 0  0 ]
[  0  |  0 -I  0 ]
X = [----------------]
[ B21 | B22 0  0 ]
[  0  |  0  0  I ]
[  C | -S  0  0 ]
[ U1 |    ] [  0 |  0 -I  0 ] [ V1 |    ]**T
= [---------] [---------------] [---------]   .
[    | U2 ] [  S |  C  0  0 ] [    | V2 ]
[  0 |  0  0  I ]
X is M-by-M, its top-left block is P-by-Q, and Q must be no larger
than P, M-P, or M-Q. (If Q is not the smallest index, then X must be
transposed and/or permuted. This can be done in constant time using
the TRANS and SIGNS options. See SORCSD for details.)
The bidiagonal matrices B11, B12, B21, and B22 are represented
implicitly by angles THETA(1:Q) and PHI(1:Q-1).
The orthogonal matrices U1, U2, V1T, and V2T are input/output.
The input matrices are pre- or post-multiplied by the appropriate
singular vector matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sbdsdc.html'>stdlib_sbdsdc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>N-by-N (upper or lower) bidiagonal matrix B:  B = U * S * VT,
using a divide and conquer method, where S is a diagonal matrix
with non-negative diagonal elements (the singular values of B), and
U and VT are orthogonal matrices of left and right singular vectors,
respectively. SBDSDC can be used to compute all singular values,
and optionally, singular vectors or singular vectors in compact form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See SLASD3 for details.
The code currently calls SLASDQ if singular values only are desired.
However, it can be slightly modified to compute singular values
using the divide and conquer method.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sbdsqr.html'>stdlib_sbdsqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>left singular vectors from the singular value decomposition (SVD) of
a real N-by-N (upper or lower) bidiagonal matrix B using the implicit
zero-shift QR algorithm.  The SVD of B has the form
B = Q * S * P<strong>T
where S is the diagonal matrix of singular values, Q is an orthogonal
matrix of left singular vectors, and P is an orthogonal matrix of
right singular vectors.  If left singular vectors are requested, this
subroutine actually returns U*Q instead of Q, and, if right singular
vectors are requested, this subroutine returns P</strong>T<em>VT instead of
P</em><em>T, for given real input matrices U and VT.  When U and VT are the
orthogonal matrices that reduce a general matrix A to bidiagonal
form:  A = U</em>B<em>VT, as computed by SGEBRD, then
A = (U</em>Q) * S * (P<strong>T*VT)
is the SVD of A.  Optionally, the subroutine may also compute Q</strong>T*C
for a given real input matrix C.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3 (or SIAM J. Sci. Statist. Comput. vol. 11,
no. 5, pp. 873-912, Sept 1990) and
"Accurate singular values and differential qd algorithms," by
B. Parlett and V. Fernando, Technical Report CPAM-554, Mathematics
Department, University of California at Berkeley, July 1992
for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_scabs1.html'>stdlib_scabs1</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_scasum.html'>stdlib_scasum</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Function</td><td><p>returns a single precision result.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_scnrm2.html'>stdlib_scnrm2</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Function</td><td><p>!</p><a href="../proc/stdlib_scnrm2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_scopy.html'>stdlib_scopy</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>uses unrolled loops for increments equal to 1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_scsum1.html'>stdlib_scsum1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>vector and returns a single precision result.
Based on SCASUM from the Level 1 BLAS.
The change is to use the 'genuine' absolute value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sdisna.html'>stdlib_sdisna</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric or complex Hermitian matrix or for the left or
right singular vectors of a general m-by-n matrix. The reciprocal
condition number is the 'gap' between the corresponding eigenvalue or
singular value and the nearest other one.
The bound on the error, measured by angle in radians, in the I-th
computed vector is given by
SLAMCH( 'E' ) * ( ANORM / SEP( I ) )
where ANORM = 2-norm(A) = max( abs( D(j) ) ).  SEP(I) is not allowed
to be smaller than SLAMCH( 'E' )*ANORM in order to limit the size of
the error bound.
SDISNA may also be used to compute error bounds for eigenvectors of
the generalized symmetric definite eigenproblem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sdot.html'>stdlib_sdot</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Function</td><td><p>uses unrolled loops for increments equal to one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sdsdot.html'>stdlib_sdsdot</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Function</td><td><p>Compute the inner product of two vectors with extended
precision accumulation.
Returns S.P. result with dot product accumulated in D.P.
SDSDOT: = SB + sum for I = 0 to N-1 of SX(LX+I<em>INCX)</em>SY(LY+I<em>INCY),
where LX = 1 if INCX &gt;= 0, else LX = 1+(1-N)</em>INCX, and LY is
defined in a similar way using INCY.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbbrd.html'>stdlib_sgbbrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>bidiagonal form B by an orthogonal transformation: Q<strong>T * A * P = B.
The routine computes B, and optionally forms Q or P</strong>T, or computes
Q*<em>T</em>C for a given matrix C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbcon.html'>stdlib_sgbcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>general band matrix A, in either the 1-norm or the infinity-norm,
using the LU factorization computed by SGBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbequ.html'>stdlib_sgbequ</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N band matrix A and reduce its condition number.  R returns the
row scale factors and C the column scale factors, chosen to try to
make the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbequb.html'>stdlib_sgbequb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from SGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbmv.html'>stdlib_sgbmv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<em><em>T</em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n band matrix, with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbrfs.html'>stdlib_sgbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is banded, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbsv.html'>stdlib_sgbsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B, where A is a band matrix of order N with KL subdiagonals
and KU superdiagonals, and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as A = L * U, where L is a product of permutation
and unit lower triangular matrices with KL subdiagonals, and U is
upper triangular with KL+KU superdiagonals.  The factored form of A
is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbsvx.html'>stdlib_sgbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B, A<strong>T * X = B, or A</strong>H * X = B,
where A is a band matrix of order N with KL subdiagonals and KU
superdiagonals, and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbtf2.html'>stdlib_sgbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbtrf.html'>stdlib_sgbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgbtrs.html'>stdlib_sgbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B
with a general band matrix A using the LU factorization computed
by SGBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgebak.html'>stdlib_sgebak</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>by backward transformation on the computed eigenvectors of the
balanced matrix output by SGEBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgebal.html'>stdlib_sgebal</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>permuting A by a similarity transformation to isolate eigenvalues
in the first 1 to ILO-1 and last IHI+1 to N elements on the
diagonal; and second, applying a diagonal similarity transformation
to rows and columns ILO to IHI to make the rows and columns as
close in norm as possible.  Both steps are optional.
Balancing may reduce the 1-norm of the matrix, and improve the
accuracy of the computed eigenvalues and/or eigenvectors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgebd2.html'>stdlib_sgebd2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>bidiagonal form B by an orthogonal transformation: Q**T * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgebrd.html'>stdlib_sgebrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>bidiagonal form B by an orthogonal transformation: Q**T * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgecon.html'>stdlib_sgecon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real matrix A, in either the 1-norm or the infinity-norm, using
the LU factorization computed by SGETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeequ.html'>stdlib_sgeequ</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeequb.html'>stdlib_sgeequb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from SGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgees.html'>stdlib_sgees</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues, the real Schur form T, and, optionally, the matrix of
Schur vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z*<em>T).
Optionally, it also orders the eigenvalues on the diagonal of the
real Schur form so that selected eigenvalues are at the top left.
The leading columns of Z then form an orthonormal basis for the
invariant subspace corresponding to the selected eigenvalues.
A matrix is in real Schur form if it is upper quasi-triangular with
1-by-1 and 2-by-2 blocks. 2-by-2 blocks will be standardized in the
form
[  a  b  ]
[  c  a  ]
where b</em>c &lt; 0. The eigenvalues of such a block are a +- sqrt(bc).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeesx.html'>stdlib_sgeesx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues, the real Schur form T, and, optionally, the matrix of
Schur vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z*<em>T).
Optionally, it also orders the eigenvalues on the diagonal of the
real Schur form so that selected eigenvalues are at the top left;
computes a reciprocal condition number for the average of the
selected eigenvalues (RCONDE); and computes a reciprocal condition
number for the right invariant subspace corresponding to the
selected eigenvalues (RCONDV).  The leading columns of Z form an
orthonormal basis for this invariant subspace.
For further explanation of the reciprocal condition numbers RCONDE
and RCONDV, see Section 4.10_sp of the LAPACK Users' Guide (where
these quantities are called s and sep respectively).
A real matrix is in real Schur form if it is upper quasi-triangular
with 1-by-1 and 2-by-2 blocks. 2-by-2 blocks will be standardized in
the form
[  a  b  ]
[  c  a  ]
where b</em>c &lt; 0. The eigenvalues of such a block are a +- sqrt(bc).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeev.html'>stdlib_sgeev</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)**H denotes the conjugate-transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeevx.html'>stdlib_sgeevx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
Optionally also, it computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
SCALE, and ABNRM), reciprocal condition numbers for the eigenvalues
(RCONDE), and reciprocal condition numbers for the right
eigenvectors (RCONDV).
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)<strong>H denotes the conjugate-transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.
Balancing a matrix means permuting the rows and columns to make it
more nearly upper triangular, and applying a diagonal similarity
transformation D * A * D</strong>(-1), where D is a diagonal matrix, to
make its rows and columns closer in norm and the condition numbers
of its eigenvalues and eigenvectors smaller.  The computed
reciprocal condition numbers correspond to the balanced matrix.
Permuting rows and columns will not change the condition numbers
(in exact arithmetic) but diagonal scaling will.  For further
explanation of balancing, see section 4.10.2_sp of the LAPACK
Users' Guide.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgehd2.html'>stdlib_sgehd2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>an orthogonal similarity transformation:  Q**T * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgehrd.html'>stdlib_sgehrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>an orthogonal similarity transformation:  Q**T * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgejsv.html'>stdlib_sgejsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix [A], where M &gt;= N. The SVD of [A] is written as
[A] = [U] * [SIGMA] * [V]^t,
where [SIGMA] is an N-by-N (M-by-N) matrix which is zero except for its N
diagonal elements, [U] is an M-by-N (or M-by-M) orthonormal matrix, and
[V] is an N-by-N orthogonal matrix. The diagonal elements of [SIGMA] are
the singular values of [A]. The columns of [U] and [V] are the left and
the right singular vectors of [A], respectively. The matrices [U] and [V]
are computed and stored in the arrays U and V, respectively. The diagonal
of [SIGMA] is computed and stored in the array SVA.
SGEJSV can sometimes compute tiny singular values and their singular vectors much
more accurately than other SVD routines, see below under Further Details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelq.html'>stdlib_sgelq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelq2.html'>stdlib_sgelq2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a n-by-n orthogonal matrix;
L is a lower-triangular m-by-m matrix;
0 is a m-by-(n-m) zero matrix, if m &lt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelqf.html'>stdlib_sgelqf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelqt.html'>stdlib_sgelqt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>DGELQT computes a blocked LQ factorization of a real M-by-N matrix A
using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelqt3.html'>stdlib_sgelqt3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgels.html'>stdlib_sgels</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, or its transpose, using a QR or LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'T' and m &gt;= n:  find the minimum norm solution of
an underdetermined system A</em><em>T * X = B.
4. If TRANS = 'T' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelsd.html'>stdlib_sgelsd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>squares problem:
minimize 2-norm(| b - A*x |)
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The problem is solved in three steps:
(1) Reduce the coefficient matrix A to bidiagonal form with
Householder transformations, reducing the original problem
into a "bidiagonal least squares problem" (BLS)
(2) Solve the BLS using a divide and conquer approach.
(3) Apply back all the Householder transformations to solve
the original least squares problem.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelss.html'>stdlib_sgelss</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>squares problem:
Minimize 2-norm(| b - A*x |).
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix
X.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgelsy.html'>stdlib_sgelsy</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>squares problem:
minimize || A * X - B ||
using a complete orthogonal factorization of A.  A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The routine first computes a QR factorization with column pivoting:
A * P = Q * [ R11 R12 ]
[  0  R22 ]
with R11 defined as the largest leading submatrix whose estimated
condition number is less than 1/RCOND.  The order of R11, RANK,
is the effective rank of A.
Then, R22 is considered to be negligible, and R12 is annihilated
by orthogonal transformations from the right, arriving at the
complete orthogonal factorization:
A * P = Q * [ T11 0 ] * Z
[  0  0 ]
The minimum-norm solution is then
X = P * Z<strong>T [ inv(T11)*Q1</strong>T*B ]
[        0         ]
where Q1 consists of the first RANK columns of Q.
This routine is basically identical to the original xGELSX except
three differences:
o The call to the subroutine xGEQPF has been substituted by the
the call to the subroutine xGEQP3. This subroutine is a Blas-3
version of the QR factorization with column pivoting.
o Matrix B (the right hand side) is updated with Blas-3.
o The permutation of matrix B (the right hand side) is faster and
more simple.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgemlq.html'>stdlib_sgemlq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product
of blocked elementary reflectors computed by short wide LQ
factorization (SGELQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgemlqt.html'>stdlib_sgemlqt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>DGEMLQT overwrites the general real M-by-N matrix C with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'T':   Q<strong>T C            C Q</strong>T
where Q is a real orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**T
generated using the compact WY representation as returned by SGELQT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgemm.html'>stdlib_sgemm</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>C := alpha<em>op( A )</em>op( B ) + beta<em>C,
where  op( X ) is one of
op( X ) = X   or   op( X ) = X</em>*T,
alpha and beta are scalars, and A, B and C are matrices, with op( A )
an m by k matrix,  op( B )  a  k by n matrix and  C an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgemqr.html'>stdlib_sgemqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (SGEQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgemqrt.html'>stdlib_sgemqrt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'T':   Q<strong>T C            C Q</strong>T
where Q is a real orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**T
generated using the compact WY representation as returned by SGEQRT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgemv.html'>stdlib_sgemv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<em><em>T</em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeql2.html'>stdlib_sgeql2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqlf.html'>stdlib_sgeqlf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqp3.html'>stdlib_sgeqp3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A:  A<em>P = Q</em>R  using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqr.html'>stdlib_sgeqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqr2.html'>stdlib_sgeqr2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqr2p.html'>stdlib_sgeqr2p</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix with nonnegative diagonal
entries;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqrf.html'>stdlib_sgeqrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqrfp.html'>stdlib_sgeqrfp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SGEQR2P computes a QR factorization of a real M-by-N matrix A:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix with nonnegative diagonal
entries;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqrt.html'>stdlib_sgeqrt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqrt2.html'>stdlib_sgeqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgeqrt3.html'>stdlib_sgeqrt3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sger.html'>stdlib_sger</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y**T + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgerfs.html'>stdlib_sgerfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations and provides error bounds and backward error estimates for
the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgerq2.html'>stdlib_sgerq2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgerqf.html'>stdlib_sgerqf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesc2.html'>stdlib_sgesc2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = scale* RHS
with a general N-by-N matrix A using the LU factorization with
complete pivoting computed by SGETC2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesdd.html'>stdlib_sgesdd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and right singular
vectors.  If singular vectors are desired, it uses a
divide-and-conquer algorithm.
The SVD is written
A = U * SIGMA * transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M orthogonal matrix, and
V is an N-by-N orthogonal matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns VT = V**T, not V.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesv.html'>stdlib_sgesv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as
A = P * L * U,
where P is a permutation matrix, L is unit lower triangular, and U is
upper triangular.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesvd.html'>stdlib_sgesvd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors. The SVD is written
A = U * SIGMA * transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M orthogonal matrix, and
V is an N-by-N orthogonal matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns V**T, not V.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesvdq.html'>stdlib_sgesvdq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N orthogonal matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesvj.html'>stdlib_sgesvj</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^t,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N orthogonal matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.
SGESVJ can sometimes compute tiny singular values and their singular vectors much
more accurately than other SVD routines, see below under Further Details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgesvx.html'>stdlib_sgesvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>system of linear equations
A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetc2.html'>stdlib_sgetc2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>n-by-n matrix A. The factorization has the form A = P * L * U * Q,
where P and Q are permutation matrices, L is lower triangular with
unit diagonal elements and U is upper triangular.
This is the Level 2 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetf2.html'>stdlib_sgetf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetrf.html'>stdlib_sgetrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetrf2.html'>stdlib_sgetrf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = min(m,n)/2
[  A21 | A22  ]       n2 = n-n1
[ A11 ]
The subroutine calls itself to factor [ --- ],
[ A12 ]
[ A12 ]
do the swaps on [ --- ], solve A12, update A22,
[ A22 ]
then calls itself to factor A22 and do the swaps on A21.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetri.html'>stdlib_sgetri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>computed by SGETRF.
This method inverts U and then computes inv(A) by solving the system
inv(A)*L = inv(U) for inv(A).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetrs.html'>stdlib_sgetrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B
with a general N-by-N matrix A using the LU factorization computed
by SGETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetsls.html'>stdlib_sgetsls</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, using a tall skinny QR or short wide LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'T' and m &gt;= n:  find the minimum norm solution of
an undetermined system A</em><em>T * X = B.
4. If TRANS = 'T' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgetsqrhrt.html'>stdlib_sgetsqrhrt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a complex M-by-N matrix A with M &gt;= N,
A = Q * R.
The routine uses internally a NB1-sized column blocked and MB1-sized
row blocked TSQR-factorization and perfors the reconstruction
of the Householder vectors from the TSQR output. The routine also
converts the R_tsqr factor from the TSQR-factorization output into
the R factor that corresponds to the Householder QR-factorization,
A = Q_tsqr * R_tsqr = Q * R.
The output Q and R factors are stored in the same format as in SGEQRT
(Q is in blocked compact WY-representation). See the documentation
of SGEQRT for more details on the format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggbak.html'>stdlib_sggbak</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalue problem A<em>x = lambda</em>B*x, by backward transformation on
the computed eigenvectors of the balanced pair of matrices output by
SGGBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggbal.html'>stdlib_sggbal</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>involves, first, permuting A and B by similarity transformations to
isolate eigenvalues in the first 1 to ILO$-$1 and last IHI+1 to N
elements on the diagonal; and second, applying a diagonal similarity
transformation to rows and columns ILO to IHI to make the rows
and columns as close in norm as possible. Both steps are optional.
Balancing may reduce the 1-norm of the matrices, and improve the
accuracy of the computed eigenvalues and/or eigenvectors in the
generalized eigenvalue problem A<em>x = lambda</em>B*x.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgges.html'>stdlib_sgges</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, the generalized real Schur form (S,T),
optionally, the left and/or right matrices of Schur vectors (VSL and
VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>T, (VSL)<em>T</em>(VSR)</strong>T )
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
quasi-triangular matrix S and the upper triangular matrix T.The
leading columns of VSL and VSR then form an orthonormal basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
SGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w*B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or both being zero.
A pair of matrices (S,T) is in generalized real Schur form if T is
upper triangular with non-negative diagonal and S is block upper
triangular with 1-by-1 and 2-by-2 blocks.  1-by-1 blocks correspond
to real generalized eigenvalues, while 2-by-2 blocks of S will be
"standardized" by making the corresponding elements of T have the
form:
[  a  0  ]
[  0  b  ]
and the pair of corresponding 2-by-2 blocks in S and T will have a
complex conjugate pair of generalized eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgges3.html'>stdlib_sgges3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, the generalized real Schur form (S,T),
optionally, the left and/or right matrices of Schur vectors (VSL and
VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>T, (VSL)<em>T</em>(VSR)</strong>T )
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
quasi-triangular matrix S and the upper triangular matrix T.The
leading columns of VSL and VSR then form an orthonormal basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
SGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w*B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or both being zero.
A pair of matrices (S,T) is in generalized real Schur form if T is
upper triangular with non-negative diagonal and S is block upper
triangular with 1-by-1 and 2-by-2 blocks.  1-by-1 blocks correspond
to real generalized eigenvalues, while 2-by-2 blocks of S will be
"standardized" by making the corresponding elements of T have the
form:
[  a  0  ]
[  0  b  ]
and the pair of corresponding 2-by-2 blocks in S and T will have a
complex conjugate pair of generalized eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggesx.html'>stdlib_sggesx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the real Schur form (S,T), and,
optionally, the left and/or right matrices of Schur vectors (VSL and
VSR).  This gives the generalized Schur factorization
(A,B) = ( (VSL) S (VSR)<strong>T, (VSL) T (VSR)</strong>T )
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
quasi-triangular matrix S and the upper triangular matrix T; computes
a reciprocal condition number for the average of the selected
eigenvalues (RCONDE); and computes a reciprocal condition number for
the right and left deflating subspaces corresponding to the selected
eigenvalues (RCONDV). The leading columns of VSL and VSR then form
an orthonormal basis for the corresponding left and right eigenspaces
(deflating subspaces).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w*B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or for both being zero.
A pair of matrices (S,T) is in generalized real Schur form if T is
upper triangular with non-negative diagonal and S is block upper
triangular with 1-by-1 and 2-by-2 blocks.  1-by-1 blocks correspond
to real generalized eigenvalues, while 2-by-2 blocks of S will be
"standardized" by making the corresponding elements of T have the
form:
[  a  0  ]
[  0  b  ]
and the pair of corresponding 2-by-2 blocks in S and T will have a
complex conjugate pair of generalized eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggev.html'>stdlib_sggev</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, and optionally, the left and/or right
generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B .
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggev3.html'>stdlib_sggev3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, and optionally, the left and/or right
generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B .
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggevx.html'>stdlib_sggevx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the generalized eigenvalues, and optionally, the left and/or right
generalized eigenvectors.
Optionally also, it computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
LSCALE, RSCALE, ABNRM, and BBNRM), reciprocal condition numbers for
the eigenvalues (RCONDE), and reciprocal condition numbers for the
right eigenvectors (RCONDV).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j) .
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B.
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggglm.html'>stdlib_sggglm</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>minimize || y ||_2   subject to   d = A<em>x + B</em>y
x
where A is an N-by-M matrix, B is an N-by-P matrix, and d is a
given N-vector. It is assumed that M &lt;= N &lt;= M+P, and
rank(A) = M    and    rank( A B ) = N.
Under these assumptions, the constrained equation is always
consistent, and there is a unique solution x and a minimal 2-norm
solution y, which is obtained using a generalized QR factorization
of the matrices (A, B) given by
A = Q<em>(R),   B = Q</em>T<em>Z.
(0)
In particular, if matrix B is square nonsingular, then the problem
GLM is equivalent to the following weighted linear least squares
problem
minimize || inv(B)</em>(d-A*x) ||_2
x
where inv(B) denotes the inverse of B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgghd3.html'>stdlib_sgghd3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Hessenberg form using orthogonal transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the orthogonal matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>T</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>T</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>T*x.
The orthogonal matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>T = (Q1<em>Q) * H * (Z1</em>Z)<strong>T
Q1 * B * Z1</strong>T = (Q1<em>Q) * T * (Z1</em>Z)<em><em>T
If Q1 is the orthogonal matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then SGGHD3 reduces the original
problem to generalized Hessenberg form.
This is a blocked variant of SGGHRD, using matrix-matrix
multiplications for parts of the computation to enhance performance.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgghrd.html'>stdlib_sgghrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Hessenberg form using orthogonal transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the orthogonal matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>T</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>T</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>T*x.
The orthogonal matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>T = (Q1<em>Q) * H * (Z1</em>Z)<strong>T
Q1 * B * Z1</strong>T = (Q1<em>Q) * T * (Z1</em>Z)<em><em>T
If Q1 is the orthogonal matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then SGGHRD reduces the original
problem to generalized Hessenberg form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgglse.html'>stdlib_sgglse</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>minimize || c - A<em>x ||_2   subject to   B</em>x = d
where A is an M-by-N matrix, B is a P-by-N matrix, c is a given
M-vector, and d is a given P-vector. It is assumed that
P &lt;= N &lt;= M+P, and
rank(B) = P and  rank( (A) ) = N.
( (B) )
These conditions ensure that the LSE problem has a unique solution,
which is obtained using a generalized RQ factorization of the
matrices (B, A) given by
B = (0 R)<em>Q,   A = Z</em>T*Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggqrf.html'>stdlib_sggqrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>and an N-by-P matrix B:
A = Q<em>R,        B = Q</em>T<em>Z,
where Q is an N-by-N orthogonal matrix, Z is a P-by-P orthogonal
matrix, and R and T assume one of the forms:
if N &gt;= M,  R = ( R11 ) M  ,   or if N &lt; M,  R = ( R11  R12 ) N,
(  0  ) N-M                         N   M-N
M
where R11 is upper triangular, and
if N &lt;= P,  T = ( 0  T12 ) N,   or if N &gt; P,  T = ( T11 ) N-P,
P-N  N                           ( T21 ) P
P
where T12 or T21 is upper triangular.
In particular, if B is square and nonsingular, the GQR factorization
of A and B implicitly gives the QR factorization of inv(B)</em>A:
inv(B)<em>A = Z</em><em>T</em>(inv(T)<em>R)
where inv(B) denotes the inverse of the matrix B, and Z</em>*T denotes the
transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sggrqf.html'>stdlib_sggrqf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>and a P-by-N matrix B:
A = R<em>Q,        B = Z</em>T<em>Q,
where Q is an N-by-N orthogonal matrix, Z is a P-by-P orthogonal
matrix, and R and T assume one of the forms:
if M &lt;= N,  R = ( 0  R12 ) M,   or if M &gt; N,  R = ( R11 ) M-N,
N-M  M                           ( R21 ) N
N
where R12 or R21 is upper triangular, and
if P &gt;= N,  T = ( T11 ) N  ,   or if P &lt; N,  T = ( T11  T12 ) P,
(  0  ) P-N                         P   N-P
N
where T11 is upper triangular.
In particular, if B is square and nonsingular, the GRQ factorization
of A and B implicitly gives the RQ factorization of A</em>inv(B):
A<em>inv(B) = (R</em>inv(T))<em>Z</em><em>T
where inv(B) denotes the inverse of the matrix B, and Z</em>*T denotes the
transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgsvj0.html'>stdlib_sgsvj0</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as SGESVJ does, but
it does not check convergence (stopping criterion). Few tuning
parameters (marked by [TP]) are available for the implementer.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgsvj1.html'>stdlib_sgsvj1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as SGESVJ does, but
it targets only particular pivots and it does not check convergence
(stopping criterion). Few tuning parameters (marked by [TP]) are
available for the implementer.
Further Details
~~~~~~~~~~~~~~~
SGSVJ1 applies few sweeps of Jacobi rotations in the column space of
the input M-by-N matrix A. The pivot pairs are taken from the (1,2)
off-diagonal block in the corresponding N-by-N Gram matrix A^T * A. The
block-entries (tiles) of the (1,2) off-diagonal block are marked by the
[x]'s in the following scheme:
| *  *  * [x] [x] [x]|
| *  *  * [x] [x] [x]|    Row-cycling in the nblr-by-nblc [x] blocks.
| *  *  * [x] [x] [x]|    Row-cyclic pivoting inside each [x] block.
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
In terms of the columns of A, the first N1 columns are rotated 'against'
the remaining N-N1 columns, trying to increase the angle between the
corresponding subspaces. The off-diagonal block is N1-by(N-N1) and it is
tiled using quadratic tiles of side KBL. Here, KBL is a tuning parameter.
The number of sweeps is given in NSWEEP and the orthogonality threshold
is given in TOL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgtcon.html'>stdlib_sgtcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>tridiagonal matrix A using the LU factorization as computed by
SGTTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgtrfs.html'>stdlib_sgtrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is tridiagonal, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgtsv.html'>stdlib_sgtsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A<em>X = B,
where A is an n by n tridiagonal matrix, by Gaussian elimination with
partial pivoting.
Note that the equation  A</em><em>T</em>X = B  may be solved by interchanging the
order of the arguments DU and DL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgtsvx.html'>stdlib_sgtsvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B or A**T * X = B,
where A is a tridiagonal matrix of order N and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgttrf.html'>stdlib_sgttrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using elimination with partial pivoting and row interchanges.
The factorization has the form
A = L * U
where L is a product of permutation and unit lower bidiagonal
matrices and U is upper triangular with nonzeros in only the main
diagonal and first two superdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgttrs.html'>stdlib_sgttrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A<em>X = B  or  A</em><em>T</em>X = B,
with a tridiagonal matrix A using the LU factorization computed
by SGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sgtts2.html'>stdlib_sgtts2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A<em>X = B  or  A</em><em>T</em>X = B,
with a tridiagonal matrix A using the LU factorization computed
by SGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_shgeqz.html'>stdlib_shgeqz</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a real matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>T,  B = Q1<em>T</em>Z1</strong>T,
as computed by SGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>T,  T = Q<em>P</em>Z</strong>T,
where Q and Z are orthogonal matrices, P is an upper triangular
matrix, and S is a quasi-triangular matrix with 1-by-1 and 2-by-2
diagonal blocks.
The 1-by-1 blocks correspond to real eigenvalues of the matrix pair
(H,T) and the 2-by-2 blocks correspond to complex conjugate pairs of
eigenvalues.
Additionally, the 2-by-2 upper triangular diagonal blocks of P
corresponding to 2-by-2 blocks of S are reduced to positive diagonal
form, i.e., if S(j+1,j) is non-zero, then P(j+1,j) = P(j,j+1) = 0,
P(j,j) &gt; 0, and P(j+1,j+1) &gt; 0.
Optionally, the orthogonal matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
orthogonal matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the orthogonal matrices from SGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the orthogonal factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>T,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>T.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Real eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_shsein.html'>stdlib_shsein</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvectors of a real upper Hessenberg matrix H.
The right eigenvector x and the left eigenvector y of the matrix H
corresponding to an eigenvalue w are defined by:
H * x = w * x,     y<strong>h * H = w * y</strong>h
where y**h denotes the conjugate transpose of the vector y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_shseqr.html'>stdlib_shseqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>T, where T is an upper quasi-triangular matrix (the
Schur form), and Z is the orthogonal matrix of Schur vectors.
Optionally Z may be postmultiplied into an input orthogonal
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the orthogonal matrix Q:  A = Q<em>H</em>Q</strong>T = (QZ)<em>T</em>(QZ)**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sisnan.html'>stdlib_sisnan</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>otherwise.  To be replaced by the Fortran 2003 intrinsic in the
future.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_gbamv.html'>stdlib_sla_gbamv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_gbrcond.html'>stdlib_sla_gbrcond</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number  cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_gbrpvgrw.html'>stdlib_sla_gbrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_geamv.html'>stdlib_sla_geamv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_gercond.html'>stdlib_sla_gercond</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_gerpvgrw.html'>stdlib_sla_gerpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_lin_berr.html'>stdlib_sla_lin_berr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the formula
max(i) ( abs(R(i)) / ( abs(op(A_s))*abs(Y) + abs(B_s) )(i) )
where abs(Z) is the componentwise absolute value of the matrix
or vector Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_porcond.html'>stdlib_sla_porcond</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number  cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_porpvgrw.html'>stdlib_sla_porpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_syamv.html'>stdlib_sla_syamv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_syrcond.html'>stdlib_sla_syrcond</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>where op2 is determined by CMODE as follows
CMODE =  1    op2(C) = C
CMODE =  0    op2(C) = I
CMODE = -1    op2(C) = inv(C)
The Skeel condition number cond(A) = norminf( |inv(A)||A| )
is computed by computing scaling factors R such that
diag(R)<em>A</em>op2(C) is row equilibrated and computing the standard
infinity-norm condition number.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_syrpvgrw.html'>stdlib_sla_syrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sla_wwaddw.html'>stdlib_sla_wwaddw</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>This works for all extant IBM's hex and binary floating point
arithmetic, but not for decimal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slabad.html'>stdlib_slabad</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>overflow, and returns the square root of each of these values if the
log of LARGE is sufficiently large.  This subroutine is intended to
identify machines with a large exponent range, such as the Crays, and
redefine the underflow and overflow limits to be the square roots of
the values computed by SLAMCH.  This subroutine is needed because
SLAMCH does not compensate for poor arithmetic in the upper half of
the exponent range, as is found on a Cray.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slabrd.html'>stdlib_slabrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>m by n matrix A to upper or lower bidiagonal form by an orthogonal
transformation Q**T * A * P, and returns the matrices X and Y which
are needed to apply the transformation to the unreduced part of A.
If m &gt;= n, A is reduced to upper bidiagonal form; if m &lt; n, to lower
bidiagonal form.
This is an auxiliary routine called by SGEBRD</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slacn2.html'>stdlib_slacn2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slacon.html'>stdlib_slacon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slacpy.html'>stdlib_slacpy</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sladiv.html'>stdlib_sladiv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a + i<em>b
p + i</em>q = ---------
c + i*d
The algorithm is due to Michael Baudin and Robert L. Smith
and can be found in the paper
"A Robust Complex Division in Scilab"</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sladiv1.html'>stdlib_sladiv1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_sladiv2.html'>stdlib_sladiv2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_slae2.html'>stdlib_slae2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>[  A   B  ]
[  B   C  ].
On return, RT1 is the eigenvalue of larger absolute value, and RT2
is the eigenvalue of smaller absolute value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaebz.html'>stdlib_slaebz</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>function N(w), which is the count of eigenvalues of a symmetric
tridiagonal matrix T less than or equal to its argument  w.  It
performs a choice of two types of loops:
IJOB=1, followed by
IJOB=2: It takes as input a list of intervals and returns a list of
sufficiently small intervals whose union contains the same
eigenvalues as the union of the original intervals.
The input intervals are (AB(j,1),AB(j,2)], j=1,...,MINP.
The output interval (AB(j,1),AB(j,2)] will contain
eigenvalues NAB(j,1)+1,...,NAB(j,2), where 1 &lt;= j &lt;= MOUT.
IJOB=3: It performs a binary search in each input interval
(AB(j,1),AB(j,2)] for a point  w(j)  such that
N(w(j))=NVAL(j), and uses  C(j)  as the starting point of
the search.  If such a w(j) is found, then on output
AB(j,1)=AB(j,2)=w.  If no such w(j) is found, then on output
(AB(j,1),AB(j,2)] will be a small interval containing the
point where N(w) jumps through NVAL(j), unless that point
lies outside the initial interval.
Note that the intervals are in all cases half-open intervals,
i.e., of the form  (a,b] , which includes  b  but not  a .
To avoid underflow, the matrix should be scaled so that its largest
element is no greater than  overflow<strong>(1/2) * underflow</strong>(1/4)
in absolute value.  To assure the most accurate computation
of small eigenvalues, the matrix should be scaled to be
not much smaller than that, either.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966
Note: the arguments are, in general, <em>not</em> checked for unreasonable
values.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed0.html'>stdlib_slaed0</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed1.html'>stdlib_slaed1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix after modification by a rank-one symmetric matrix.  This
routine is used only for the eigenproblem which requires all
eigenvalues and eigenvectors of a tridiagonal matrix.  SLAED7 handles
the case in which eigenvalues only or eigenvalues and eigenvectors
of a full symmetric matrix (which was reduced to tridiagonal form)
are desired.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>T ) Q</em><em>T(in) = Q(out) * D(out) * Q</em><em>T(out)
where Z = Q</em><em>T</em>u, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine SLAED2.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine SLAED4 (as called by SLAED3).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed2.html'>stdlib_slaed2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny entry in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed3.html'>stdlib_slaed3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>values in D, W, and RHO, between 1 and K.  It makes the
appropriate calls to SLAED4 and then updates the eigenvectors by
multiplying the matrix of eigenvectors of the pair of eigensystems
being combined by the matrix of eigenvectors of the K-by-K system
which is solved here.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed4.html'>stdlib_slaed4</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>This subroutine computes the I-th updated eigenvalue of a symmetric
rank-one modification to a diagonal matrix whose elements are
given in the array d, and that
D(i) &lt; D(j)  for  i &lt; j
and that RHO &gt; 0.  This is arranged by the calling routine, and is
no loss in generality.  The rank-one modified system is thus
diag( D )  +  RHO * Z * Z_transpose.
where we assume the Euclidean norm of Z is 1.
The method consists of approximating the rational functions in the
secular equation by simpler interpolating rational functions.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed5.html'>stdlib_slaed5</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>This subroutine computes the I-th eigenvalue of a symmetric rank-one
modification of a 2-by-2 diagonal matrix
diag( D )  +  RHO * Z * transpose(Z) .
The diagonal elements in the array D are assumed to satisfy
D(i) &lt; D(j)  for  i &lt; j .
We also assume RHO &gt; 0 and that the Euclidean norm of the vector
Z is one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed6.html'>stdlib_slaed6</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of
z(1)        z(2)        z(3)
f(x) =   rho + --------- + ---------- + ---------
d(1)-x      d(2)-x      d(3)-x
It is assumed that
if ORGATI = .true. the root is between d(2) and d(3);
otherwise it is between d(1) and d(2)
This routine will be called by SLAED4 when necessary. In most cases,
the root sought is the smallest in magnitude, though it might not be
in some extremely rare situations.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed7.html'>stdlib_slaed7</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix after modification by a rank-one symmetric matrix. This
routine is used only for the eigenproblem which requires all
eigenvalues and optionally eigenvectors of a dense symmetric matrix
that has been reduced to tridiagonal form.  SLAED1 handles
the case in which all eigenvalues and eigenvectors of a symmetric
tridiagonal matrix are desired.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>T ) Q</em><em>T(in) = Q(out) * D(out) * Q</em><em>T(out)
where Z = Q</em>*Tu, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine SLAED8.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine SLAED4 (as called by SLAED9).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed8.html'>stdlib_slaed8</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny element in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaed9.html'>stdlib_slaed9</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>values in D, Z, and RHO, between KSTART and KSTOP.  It makes the
appropriate calls to SLAED4 and then stores the new matrix of
eigenvectors for use in calculating the next level of Z vectors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaeda.html'>stdlib_slaeda</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>CURLVLth step of the merge process with TLVLS steps for the CURPBMth
problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaein.html'>stdlib_slaein</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>corresponding to the eigenvalue (WR,WI) of a real upper Hessenberg
matrix H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaev2.html'>stdlib_slaev2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>[  A   B  ]
[  B   C  ].
On return, RT1 is the eigenvalue of larger absolute value, RT2 is the
eigenvalue of smaller absolute value, and (CS1,SN1) is the unit right
eigenvector for RT1, giving the decomposition
[ CS1  SN1 ] [  A   B  ] [ CS1 -SN1 ]  =  [ RT1  0  ]
[-SN1  CS1 ] [  B   C  ] [ SN1  CS1 ]     [  0  RT2 ].</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaexc.html'>stdlib_slaexc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>an upper quasi-triangular matrix T by an orthogonal similarity
transformation.
T must be in Schur canonical form, that is, block upper triangular
with 1-by-1 and 2-by-2 diagonal blocks; each 2-by-2 diagonal block
has its diagonal elements equal and its off-diagonal elements of
opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slag2.html'>stdlib_slag2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>problem  A - w B, with scaling as necessary to avoid over-/underflow.
The scaling factor "s" results in a modified eigenvalue equation
s A - w B
where  s  is a non-negative scaling factor chosen so that  w,  w B,
and  s A  do not overflow and, if possible, do not underflow, either.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slag2d.html'>stdlib_slag2d</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>PRECISION matrix, A.
Note that while it is possible to overflow while converting
from double to single, it is not possible to overflow when
converting from single to double.
This is an auxiliary routine so there is no argument checking.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slags2.html'>stdlib_slags2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>that if ( UPPER ) then
U<strong>T <em>A</em>Q = U</strong>T <em>( A1 A2 )</em>Q = ( x  0  )
( 0  A3 )     ( x  x  )
and
V<strong>T<em>B</em>Q = V</strong>T <em>( B1 B2 )</em>Q = ( x  0  )
( 0  B3 )     ( x  x  )
or if ( .NOT.UPPER ) then
U<strong>T <em>A</em>Q = U</strong>T <em>( A1 0  )</em>Q = ( x  x  )
( A2 A3 )     ( 0  x  )
and
V<strong>T<em>B</em>Q = V</strong>T<em>( B1 0  )</em>Q = ( x  x  )
( B2 B3 )     ( 0  x  )
The rows of the transformed A and B are parallel, where
U = (  CSU  SNU ), V = (  CSV SNV ), Q = (  CSQ   SNQ )
( -SNU  CSU )      ( -SNV CSV )      ( -SNQ   CSQ )
Z**T denotes the transpose of Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slagtf.html'>stdlib_slagtf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>tridiagonal matrix and lambda is a scalar, as
T - lambda*I = PLU,
where P is a permutation matrix, L is a unit lower tridiagonal matrix
with at most one non-zero sub-diagonal elements per column and U is
an upper triangular matrix with at most two non-zero super-diagonal
elements per column.
The factorization is obtained by Gaussian elimination with partial
pivoting and implicit row scaling.
The parameter LAMBDA is included in the routine so that SLAGTF may
be used, in conjunction with SLAGTS, to obtain eigenvectors of T by
inverse iteration.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slagtm.html'>stdlib_slagtm</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>B := alpha * A * X + beta * B
where A is a tridiagonal matrix of order N, B and X are N by NRHS
matrices, and alpha and beta are real scalars, each of which may be
0., 1., or -1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slagts.html'>stdlib_slagts</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>(T - lambda<em>I)</em>x = y   or   (T - lambda<em>I)</em><em>T</em>x = y,
where T is an n by n tridiagonal matrix, for x, following the
factorization of (T - lambda<em>I) as
(T - lambda</em>I) = P<em>L</em>U ,
by routine SLAGTF. The choice of equation to be solved is
controlled by the argument JOB, and in each case there is an option
to perturb zero or very small diagonal elements of U, this option
being intended for use in applications such as inverse iteration.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slagv2.html'>stdlib_slagv2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix pencil (A,B) where B is upper triangular. This routine
computes orthogonal (rotation) matrices given by CSL, SNL and CSR,
SNR such that
1) if the pencil (A,B) has two real eigenvalues (include 0/0 or 1/0
types), then
[ a11 a12 ] := [  CSL  SNL ] [ a11 a12 ] [  CSR -SNR ]
[  0  a22 ]    [ -SNL  CSL ] [ a21 a22 ] [  SNR  CSR ]
[ b11 b12 ] := [  CSL  SNL ] [ b11 b12 ] [  CSR -SNR ]
[  0  b22 ]    [ -SNL  CSL ] [  0  b22 ] [  SNR  CSR ],
2) if the pencil (A,B) has a pair of complex conjugate eigenvalues,
then
[ a11 a12 ] := [  CSL  SNL ] [ a11 a12 ] [  CSR -SNR ]
[ a21 a22 ]    [ -SNL  CSL ] [ a21 a22 ] [  SNR  CSR ]
[ b11  0  ] := [  CSL  SNL ] [ b11 b12 ] [  CSR -SNR ]
[  0  b22 ]    [ -SNL  CSL ] [  0  b22 ] [  SNR  CSR ]
where b11 &gt;= b22 &gt; 0.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slahqr.html'>stdlib_slahqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues and Schur decomposition already computed by SHSEQR, by
dealing with the Hessenberg submatrix in rows and columns ILO to
IHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slahr2.html'>stdlib_slahr2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A so that elements below the k-th subdiagonal are zero. The
reduction is performed by an orthogonal similarity transformation
Q<strong>T * A * Q. The routine returns the matrices V and T which determine
Q as a block reflector I - V<em>T</em>V</strong>T, and also the matrix Y = A * V * T.
This is an auxiliary routine called by SGEHRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaic1.html'>stdlib_slaic1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>its simplest version:
Let x, twonorm(x) = 1, be an approximate singular vector of an j-by-j
lower triangular matrix L, such that
twonorm(L<em>x) = sest
Then SLAIC1 computes sestpr, s, c such that
the vector
[ s</em>x ]
xhat = [  c  ]
is an approximate singular vector of
[ L      0  ]
Lhat = [ w<strong>T gamma ]
in the sense that
twonorm(Lhat*xhat) = sestpr.
Depending on JOB, an estimate for the largest or smallest singular
value is computed.
Note that [s c]</strong>T and sestpr<strong>2 is an eigenpair of the system
diag(sest*sest, 0) + [alpha  gamma] * [ alpha ]
[ gamma ]
where  alpha =  x</strong>T*w.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaisnan.html'>stdlib_slaisnan</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>This routine is not for general use.  It exists solely to avoid
over-optimization in SISNAN.
SLAISNAN: checks for NaNs by comparing its two arguments for
inequality.  NaN is the only floating-point value where NaN != NaN
returns .TRUE.  To check for NaNs, pass the same variable as both
arguments.
A compiler must assume that the two arguments are
not the same variable, and the test will not be optimized away.
Interprocedural or whole-program optimization may delete this
test.  The ISNAN functions will be replaced by the correct
Fortran 03 intrinsic once the intrinsic is widely available.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaln2.html'>stdlib_slaln2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>or (ca A<strong>T - w D) X = s B   with possible scaling ("s") and
perturbation of A.  (A</strong>T means A-transpose.)
A is an NA x NA real matrix, ca is a real scalar, D is an NA x NA
real diagonal matrix, w is a real or complex value, and X and B are
NA x 1 matrices -- real if w is real, complex if w is complex.  NA
may be 1 or 2.
If w is complex, X and B are represented as NA x 2 matrices,
the first column of each being the real part and the second
being the imaginary part.
"s" is a scaling factor (&lt;= 1), computed by SLALN2, which is
so chosen that X can be computed without overflow.  X is further
scaled if necessary to assure that norm(ca A - w D)<em>norm(X) is less
than overflow.
If both singular values of (ca A - w D) are less than SMIN,
SMIN</em>identity will be used instead of (ca A - w D).  If only one
singular value is less than SMIN, one element of (ca A - w D) will be
perturbed enough to make the smallest singular value roughly SMIN.
If both singular values are at least SMIN, (ca A - w D) will not be
perturbed.  In any case, the perturbation will be at most some small
multiple of max( SMIN, ulp*norm(ca A - w D) ).  The singular values
are computed by infinity-norm approximations, and thus will only be
correct to a factor of 2 or so.
Note: all input quantities are assumed to be smaller than overflow
by a reasonable factor.  (See BIGNUM.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slals0.html'>stdlib_slals0</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>right singular vector matrix of a diagonal matrix appended by a row
to the right hand side matrix B in solving the least squares problem
using the divide-and-conquer SVD approach.
For the left singular vector matrix, three types of orthogonal
matrices are involved:
(1L) Givens rotations: the number of such rotations is GIVPTR; the
pairs of columns/rows they were applied to are stored in GIVCOL;
and the C- and S-values of these rotations are stored in GIVNUM.
(2L) Permutation. The (NL+1)-st row of B is to be moved to the first
row, and for J=2:N, PERM(J)-th row of B is to be moved to the
J-th row.
(3L) The left singular vector matrix of the remaining matrix.
For the right singular vector matrix, four types of orthogonal
matrices are involved:
(1R) The right singular vector matrix of the remaining matrix.
(2R) If SQRE = 1, one extra Givens rotation to generate the right
null space.
(3R) The inverse transformation of (2L).
(4R) The inverse transformation of (1L).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slalsa.html'>stdlib_slalsa</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>by computing the SVD of the coefficient matrix in compact form (The
singular vectors are computed as products of simple orthorgonal
matrices.).
If ICOMPQ = 0, SLALSA applies the inverse of the left singular vector
matrix of an upper bidiagonal matrix to the right hand side; and if
ICOMPQ = 1, SLALSA applies the right singular vector matrix to the
right hand side. The singular vector matrices were generated in
compact form by SLALSA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slalsd.html'>stdlib_slalsd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>squares problem of finding X to minimize the Euclidean norm of each
column of A*X-B, where A is N-by-N upper bidiagonal, and X and B
are N-by-NRHS. The solution X overwrites B.
The singular values of A smaller than RCOND times the largest
singular value are treated as zero in solving the least squares
problem; in this case a minimum norm solution is returned.
The actual singular values are returned in D in ascending order.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slamc3.html'>stdlib_slamc3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_slamch.html'>stdlib_slamch</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_slamrg.html'>stdlib_slamrg</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of A (which is composed of two independently sorted sets) into a
single set which is sorted in ascending order.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slamswlq.html'>stdlib_slamswlq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of blocked
elementary reflectors computed by short wide LQ
factorization (SLASWLQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slamtsqr.html'>stdlib_slamtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (SLATSQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaneg.html'>stdlib_slaneg</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>encountered while factoring tridiagonal T - sigma I = L D L^T.
This implementation works directly on the factors without forming
the tridiagonal matrix T.  The Sturm count is also the number of
eigenvalues of T less than sigma.
This routine is called from SLARRB.
The current routine does not use the PIVMIN parameter but rather
requires IEEE-754 propagation of Infinities and NaNs.  This
routine also has no input range restrictions but does require
default exception handling such that x/0 produces Inf when x is
non-zero, and Inf/Inf produces NaN.  For more information, see:
Marques, Riedy, and Voemel, "Benefits of IEEE-754 Features in
Modern Symmetric Tridiagonal Eigensolvers," SIAM Journal on
Scientific Computing, v28, n5, 2006.  DOI 10.1137/050641624
(Tech report version in LAWN 172 with the same title.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slangb.html'>stdlib_slangb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n band matrix  A,  with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slange.html'>stdlib_slange</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slangt.html'>stdlib_slangt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slanhs.html'>stdlib_slanhs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
Hessenberg matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slansb.html'>stdlib_slansb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n symmetric band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slansf.html'>stdlib_slansf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the infinity norm, or the element of largest absolute value of a
real symmetric matrix A in RFP format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slansp.html'>stdlib_slansp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slanst.html'>stdlib_slanst</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slansy.html'>stdlib_slansy</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
real symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slantb.html'>stdlib_slantb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n triangular band matrix A,  with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slantp.html'>stdlib_slantp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
triangular matrix A, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slantr.html'>stdlib_slantr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
trapezoidal or triangular matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slanv2.html'>stdlib_slanv2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix in standard form:
[ A  B ] = [ CS -SN ] [ AA  BB ] [ CS  SN ]
[ C  D ]   [ SN  CS ] [ CC  DD ] [-SN  CS ]
where either
1) CC = 0 so that AA and DD are real eigenvalues of the matrix, or
2) AA = DD and BB<em>CC &lt; 0, so that AA + or - sqrt(BB</em>CC) are complex
conjugate eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaorhr_col_getrfnp.html'>stdlib_slaorhr_col_getrfnp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>pivoting of a real general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is
at least one in absolute value (so that division-by-zero not
not possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine SORHR_COL. In SORHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the blocked right-looking version of the algorithm,
calling Level 3 BLAS to update the submatrix. To factorize a block,
this routine calls the recursive routine SLAORHR_COL_GETRFNP2.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaorhr_col_getrfnp2.html'>stdlib_slaorhr_col_getrfnp2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>pivoting of a real general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is at
least one in absolute value (so that division-by-zero not
possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine SORHR_COL. In SORHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the recursive version of the LU factorization algorithm.
Denote A - S by B. The algorithm divides the matrix B into four
submatrices:
[  B11 | B12  ]  where B11 is n1 by n1,
B = [ -----|----- ]        B21 is (m-n1) by n1,
[  B21 | B22  ]        B12 is n1 by n2,
B22 is (m-n1) by n2,
with n1 = min(m,n)/2, n2 = n-n1.
The subroutine calls itself to factor B11, solves for B21,
solves for B12, updates B22, then calls itself to factor B22.
For more details on the recursive LU algorithm, see [2].
SLAORHR_COL_GETRFNP2 is called to factorize a block by the blocked
routine SLAORHR_COL_GETRFNP, which uses blocked code calling
Level 3 BLAS to update the submatrix. However, SLAORHR_COL_GETRFNP2
is self-sufficient and can be used without SLAORHR_COL_GETRFNP.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.
[2] "Recursion leads to automatic variable blocking for dense linear
algebra algorithms", F. Gustavson, IBM J. of Res. and Dev.,
vol. 41, no. 6, pp. 737-755, 1997.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slapll.html'>stdlib_slapll</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Given two column vectors X and Y, let
A = ( X Y ).
The subroutine first computes the QR factorization of A = Q*R,
and then computes the SVD of the 2-by-2 upper triangular matrix R.
The smaller singular value of R is returned in SSMIN, which is used
as the measurement of the linear dependency of the vectors X and Y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slapmr.html'>stdlib_slapmr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(M) of the integers 1,...,M.
If FORWRD = .TRUE.,  forward permutation:
X(K(I),<em>) is moved X(I,</em>) for I = 1,2,...,M.
If FORWRD = .FALSE., backward permutation:
X(I,<em>) is moved to X(K(I),</em>) for I = 1,2,...,M.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slapmt.html'>stdlib_slapmt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(N) of the integers 1,...,N.
If FORWRD = .TRUE.,  forward permutation:
X(<em>,K(J)) is moved X(</em>,J) for J = 1,2,...,N.
If FORWRD = .FALSE., backward permutation:
X(<em>,J) is moved to X(</em>,K(J)) for J = 1,2,...,N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slapy2.html'>stdlib_slapy2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>overflow and unnecessary underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slapy3.html'>stdlib_slapy3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Function</td><td><p>unnecessary overflow and unnecessary underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqgb.html'>stdlib_slaqgb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>subdiagonals and KU superdiagonals using the row and scaling factors
in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqge.html'>stdlib_slaqge</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>column scaling factors in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqp2.html'>stdlib_slaqp2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the block A(OFFSET+1:M,1:N).
The block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqps.html'>stdlib_slaqps</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real M-by-N matrix A by using Blas-3.  It tries to factorize
NB columns from A starting from the row OFFSET+1, and updates all
of the matrix with Blas-3 xGEMM.
In some cases, due to catastrophic cancellations, it cannot
factorize NB columns.  Hence, the actual number of factorized
columns is returned in KB.
Block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqr0.html'>stdlib_slaqr0</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>T, where T is an upper quasi-triangular matrix (the
Schur form), and Z is the orthogonal matrix of Schur vectors.
Optionally Z may be postmultiplied into an input orthogonal
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the orthogonal matrix Q:  A = Q<em>H</em>Q</strong>T = (QZ)<em>T</em>(QZ)**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqr1.html'>stdlib_slaqr1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Given a 2-by-2 or 3-by-3 matrix H, SLAQR1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (H - (sr1 + i</em>si1)<em>I)</em>(H - (sr2 + i<em>si2)</em>I)
scaling to avoid overflows and most underflows. It
is assumed that either
1) sr1 = sr2 and si1 = -si2
or
2) si1 = si2 = 0.
This is useful for starting double implicit shift bulges
in the QR algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqr2.html'>stdlib_slaqr2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>recursion by calling SLAHQR instead of SLAQR4.
Aggressive early deflation:
This subroutine accepts as input an upper Hessenberg matrix
H and performs an orthogonal similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an orthogonal similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqr3.html'>stdlib_slaqr3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Aggressive early deflation:
SLAQR3: accepts as input an upper Hessenberg matrix
H and performs an orthogonal similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an orthogonal similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqr4.html'>stdlib_slaqr4</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>It is a complete implementation of the small bulge multi-shift
QR algorithm.  It may be called by SLAQR0 and, for large enough
deflation window size, it may be called by SLAQR3.  This
subroutine is identical to SLAQR0 except that it calls SLAQR2
instead of SLAQR3.
SLAQR4 computes the eigenvalues of a Hessenberg matrix H
and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>T, where T is an upper quasi-triangular matrix (the
Schur form), and Z is the orthogonal matrix of Schur vectors.
Optionally Z may be postmultiplied into an input orthogonal
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the orthogonal matrix Q:  A = Q<em>H</em>Q</strong>T = (QZ)<em>T</em>(QZ)**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqr5.html'>stdlib_slaqr5</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>single small-bulge multi-shift QR sweep.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqsb.html'>stdlib_slaqsb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqsp.html'>stdlib_slaqsp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqsy.html'>stdlib_slaqsy</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqtr.html'>stdlib_slaqtr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>op(T)<em>p = scale</em>c,               if LREAL = .TRUE.
or the complex quasi-triangular systems
op(T + iB)<em>(p+iq) = scale</em>(c+id),  if LREAL = .FALSE.
in real arithmetic, where T is upper quasi-triangular.
If LREAL = .FALSE., then the first diagonal block of T must be
1 by 1, B is the specially structured matrix
B = [ b(1) b(2) ... b(n) ]
[       w            ]
[           w        ]
[              .     ]
[                 w  ]
op(A) = A or A<strong>T, A</strong>T denotes the transpose of
matrix A.
On input, X = [ c ].  On output, X = [ p ].
[ d ]                  [ q ]
This subroutine is designed for the condition number estimation
in routine STRSNA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqz0.html'>stdlib_slaqz0</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a real matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>T,  B = Q1<em>T</em>Z1</strong>T,
as computed by SGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>T,  T = Q<em>P</em>Z</strong>T,
where Q and Z are orthogonal matrices, P is an upper triangular
matrix, and S is a quasi-triangular matrix with 1-by-1 and 2-by-2
diagonal blocks.
The 1-by-1 blocks correspond to real eigenvalues of the matrix pair
(H,T) and the 2-by-2 blocks correspond to complex conjugate pairs of
eigenvalues.
Additionally, the 2-by-2 upper triangular diagonal blocks of P
corresponding to 2-by-2 blocks of S are reduced to positive diagonal
form, i.e., if S(j+1,j) is non-zero, then P(j+1,j) = P(j,j+1) = 0,
P(j,j) &gt; 0, and P(j+1,j+1) &gt; 0.
Optionally, the orthogonal matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
orthogonal matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the orthogonal matrices from SGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the orthogonal factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>T,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>T.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Real eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.
Ref: B. Kagstrom, D. Kressner, "Multishift Variants of the QZ
Algorithm with Aggressive Early Deflation", SIAM J. Numer.
Anal., 29(2006), pp. 199--227.
Ref: T. Steel, D. Camps, K. Meerbergen, R. Vandebril "A multishift,
multipole rational QZ method with agressive early deflation"</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqz1.html'>stdlib_slaqz1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Given a 3-by-3 matrix pencil (A,B), SLAQZ1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (A - (beta2</em>sr2 - i<em>si)</em>B)<em>B^(-1)</em>(beta1<em>A - (sr2 + i</em>si2)<em>B)</em>B^(-1).
It is assumed that either
1) sr1 = sr2
or
2) si = 0.
This is useful for starting double implicit shift bulges
in the QZ algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqz2.html'>stdlib_slaqz2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SLAQZ2: chases a 2x2 shift bulge in a matrix pencil down a single position</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqz3.html'>stdlib_slaqz3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SLAQZ3: performs AED</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaqz4.html'>stdlib_slaqz4</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SLAQZ4: Executes a single multishift QZ sweep</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slar1v.html'>stdlib_slar1v</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the sumbmatrix in rows B1 through BN of the tridiagonal matrix
L D L<strong>T - sigma I. When sigma is close to an eigenvalue, the
computed vector is an accurate eigenvector. Usually, r corresponds
to the index where the eigenvector is largest in magnitude.
The following steps accomplish this computation :
(a) Stationary qd transform,  L D L</strong>T - sigma I = L(+) D(+) L(+)<strong>T,
(b) Progressive qd transform, L D L</strong>T - sigma I = U(-) D(-) U(-)<strong>T,
(c) Computation of the diagonal elements of the inverse of
L D L</strong>T - sigma I by combining the above transforms, and choosing
r as the index where the diagonal of the inverse is (one of the)
largest in magnitude.
(d) Computation of the (scaled) r-th column of the inverse using the
twisted factorization obtained by combining the top part of the
the stationary and the bottom part of the progressive transform.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slar2v.html'>stdlib_slar2v</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a sequence of 2-by-2 real symmetric matrices, defined by the elements
of the vectors x, y and z. For i = 1,2,...,n
( x(i)  z(i) ) := (  c(i)  s(i) ) ( x(i)  z(i) ) ( c(i) -s(i) )
( z(i)  y(i) )    ( -s(i)  c(i) ) ( z(i)  y(i) ) ( s(i)  c(i) )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarf.html'>stdlib_slarf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>C, from either the left or the right. H is represented in the form
H = I - tau * v * v**T
where tau is a real scalar and v is a real vector.
If tau = 0, then H is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarfb.html'>stdlib_slarfb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real m by n matrix C, from either the left or the right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarfb_gett.html'>stdlib_slarfb_gett</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>left to a real (K+M)-by-N  "triangular-pentagonal" matrix
composed of two block matrices: an upper trapezoidal K-by-N matrix A
stored in the array A, and a rectangular M-by-(N-K) matrix B, stored
in the array B. The block reflector H is stored in a compact
WY-representation, where the elementary reflectors are in the
arrays A, B and T. See Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarfg.html'>stdlib_slarfg</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>that
H * ( alpha ) = ( beta ),   H<strong>T * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, and x is an (n-1)-element real
vector. H is represented in the form
H = I - tau * ( 1 ) * ( 1 v</strong>T ) ,
( v )
where tau is a real scalar and v is a real (n-1)-element
vector.
If the elements of x are all zero, then tau = 0 and H is taken to be
the unit matrix.
Otherwise  1 &lt;= tau &lt;= 2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarfgp.html'>stdlib_slarfgp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>that
H * ( alpha ) = ( beta ),   H<strong>T * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, beta is non-negative, and x is
an (n-1)-element real vector.  H is represented in the form
H = I - tau * ( 1 ) * ( 1 v</strong>T ) ,
( v )
where tau is a real scalar and v is a real (n-1)-element
vector.
If the elements of x are all zero, then tau = 0 and H is taken to be
the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarft.html'>stdlib_slarft</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of order n, which is defined as a product of k elementary reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>T
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>T * T * V</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarfx.html'>stdlib_slarfx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v**T
where tau is a real scalar and v is a real vector.
If tau = 0, then H is taken to be the unit matrix
This version uses inline code if H has order &lt; 11.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarfy.html'>stdlib_slarfy</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to an n x n symmetric matrix C, from both the left and the right.
H is represented in the form
H = I - tau * v * v'
where  tau  is a scalar and  v  is a vector.
If  tau  is  zero, then  H  is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slargv.html'>stdlib_slargv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>elements of the real vectors x and y. For i = 1,2,...,n
(  c(i)  s(i) ) ( x(i) ) = ( a(i) )
( -s(i)  c(i) ) ( y(i) ) = (   0  )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarnv.html'>stdlib_slarnv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>normal distribution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarra.html'>stdlib_slarra</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Compute the splitting points with threshold SPLTOL.
SLARRA: sets any "small" off-diagonal elements to zero.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrb.html'>stdlib_slarrb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Given the relatively robust representation(RRR) L D L^T, SLARRB:
does "limited" bisection to refine the eigenvalues of L D L^T,
W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial
guesses for these eigenvalues are input in W, the corresponding estimate
of the error in these guesses and their gaps are input in WERR
and WGAP, respectively. During bisection, intervals
[left, right] are maintained by storing their mid-points and
semi-widths in the arrays W and WERR respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrc.html'>stdlib_slarrc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Find the number of eigenvalues of the symmetric tridiagonal matrix T
that are in the interval (VL,VU] if JOBT = 'T', and of L D L^T
if JOBT = 'L'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrd.html'>stdlib_slarrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix T to suitable accuracy. This is an auxiliary code to be
called from SSTEMR.
The user may ask for all eigenvalues, all eigenvalues
in the half-open interval (VL, VU], or the IL-th through IU-th
eigenvalues.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarre.html'>stdlib_slarre</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>To find the desired eigenvalues of a given real symmetric
tridiagonal matrix T, SLARRE: sets any "small" off-diagonal
elements to zero, and for each unreduced block T_i, it finds
(a) a suitable shift at one end of the block's spectrum,
(b) the base representation, T_i - sigma_i I = L_i D_i L_i^T, and
(c) eigenvalues of each L_i D_i L_i^T.
The representations and eigenvalues found are then used by
SSTEMR to compute the eigenvectors of T.
The accuracy varies depending on whether bisection is used to
find a few eigenvalues or the dqds algorithm (subroutine SLASQ2) to
conpute all and then discard any unwanted one.
As an added benefit, SLARRE also outputs the n
Gerschgorin intervals for the matrices L_i D_i L_i^T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrf.html'>stdlib_slarrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Given the initial representation L D L^T and its cluster of close
eigenvalues (in a relative measure), W( CLSTRT ), W( CLSTRT+1 ), ...
W( CLEND ), SLARRF: finds a new relatively robust representation
L D L^T - SIGMA I = L(+) D(+) L(+)^T such that at least one of the
eigenvalues of L(+) D(+) L(+)^T is relatively isolated.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrj.html'>stdlib_slarrj</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Given the initial eigenvalue approximations of T, SLARRJ:
does  bisection to refine the eigenvalues of T,
W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial
guesses for these eigenvalues are input in W, the corresponding estimate
of the error in these guesses in WERR. During bisection, intervals
[left, right] are maintained by storing their mid-points and
semi-widths in the arrays W and WERR respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrk.html'>stdlib_slarrk</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix T to suitable accuracy. This is an auxiliary code to be
called from SSTEMR.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrr.html'>stdlib_slarrr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Perform tests to decide whether the symmetric tridiagonal matrix T
warrants expensive computations which guarantee high relative accuracy
in the eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarrv.html'>stdlib_slarrv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>T = L D L<strong>T given L, D and APPROXIMATIONS to the eigenvalues of L D L</strong>T.
The input eigenvalues should have been computed by SLARRE.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slartg.html'>stdlib_slartg</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_slartg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_slartgp.html'>stdlib_slartgp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>[  CS  SN  ]  .  [ F ]  =  [ R ]   where CS<strong>2 + SN</strong>2 = 1.
[ -SN  CS  ]     [ G ]     [ 0 ]
This is a slower, more accurate version of the Level 1 BLAS routine SROTG,
with the following other differences:
F and G are unchanged on return.
If G=0, then CS=(+/-)1 and SN=0.
If F=0 and (G .ne. 0), then CS=0 and SN=(+/-)1.
The sign is chosen so that R &gt;= 0.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slartgs.html'>stdlib_slartgs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Golub-Reinsch-style implicit QR iteration for the bidiagonal SVD
problem. X and Y are the top-row entries, and SIGMA is the shift.
The computed CS and SN define a plane rotation satisfying
[  CS  SN  ]  .  [ X^2 - SIGMA ]  =  [ R ],
[ -SN  CS  ]     [    X * Y    ]     [ 0 ]
with R nonnegative.  If X^2 - SIGMA and X * Y are 0, then the
rotation is by PI/2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slartv.html'>stdlib_slartv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real vectors x and y. For i = 1,2,...,n
( x(i) ) := (  c(i)  s(i) ) ( x(i) )
( y(i) )    ( -s(i)  c(i) ) ( y(i) )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaruv.html'>stdlib_slaruv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>distribution (n &lt;= 128).
This is an auxiliary routine called by SLARNV and CLARNV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarz.html'>stdlib_slarz</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v**T
where tau is a real scalar and v is a real vector.
If tau = 0, then H is taken to be the unit matrix.
H is a product of k elementary reflectors as returned by STZRZF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarzb.html'>stdlib_slarzb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real distributed M-by-N  C from the left or the right.
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slarzt.html'>stdlib_slarzt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>H of order &gt; n, which is defined as a product of k elementary
reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>T
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>T * T * V
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slas2.html'>stdlib_slas2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>[  F   G  ]
[  0   H  ].
On return, SSMIN is the smaller singular value and SSMAX is the
larger singular value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slascl.html'>stdlib_slascl</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>CTO/CFROM.  This is done without over/underflow as long as the final
result CTO*A(I,J)/CFROM does not over/underflow. TYPE specifies that
A may be full, upper triangular, lower triangular, upper Hessenberg,
or banded.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd0.html'>stdlib_slasd0</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Using a divide and conquer approach, SLASD0: computes the singular
value decomposition (SVD) of a real upper bidiagonal N-by-M
matrix B with diagonal D and offdiagonal E, where M = N + SQRE.
The algorithm computes orthogonal matrices U and VT such that
B = U * S * VT. The singular values S are overwritten on D.
A related subroutine, SLASDA, computes only the singular values,
and optionally, the singular vectors in compact form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd1.html'>stdlib_slasd1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>where N = NL + NR + 1 and M = N + SQRE. SLASD1 is called from SLASD0.
A related subroutine SLASD7 handles the case in which the singular
values (and the singular vectors in factored form) are desired.
SLASD1 computes the SVD as follows:
( D1(in)    0    0       0 )
B = U(in) * (   Z1<strong>T   a   Z2</strong>T    b ) * VT(in)
(   0       0   D2(in)   0 )
= U(out) * ( D(out) 0) * VT(out)
where Z<strong>T = (Z1</strong>T a Z2<strong>T b) = u</strong>T VT**T, and u is a vector of dimension M
with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros
elsewhere; and the entry b is empty if SQRE = 0.
The left singular vectors of the original matrix are stored in U, and
the transpose of the right singular vectors are stored in VT, and the
singular values are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple singular values or when there are zeros in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine SLASD2.
The second stage consists of calculating the updated
singular values. This is done by finding the square roots of the
roots of the secular equation via the routine SLASD4 (as called
by SLASD3). This routine also calculates the singular vectors of
the current problem.
The final stage consists of computing the updated singular vectors
directly using the updated singular values.  The singular vectors
for the current problem are multiplied with the singular vectors
from the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd2.html'>stdlib_slasd2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
singular values are close together or if there is a tiny entry in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.
SLASD2 is called from SLASD1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd3.html'>stdlib_slasd3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equation, as defined by the values in D and Z.  It makes the
appropriate calls to SLASD4 and then updates the singular
vectors by matrix multiplication.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.
SLASD3 is called from SLASD1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd4.html'>stdlib_slasd4</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>This subroutine computes the square root of the I-th updated
eigenvalue of a positive symmetric rank-one modification to
a positive diagonal matrix whose entries are given as the squares
of the corresponding entries in the array d, and that
0 &lt;= D(i) &lt; D(j)  for  i &lt; j
and that RHO &gt; 0. This is arranged by the calling routine, and is
no loss in generality.  The rank-one modified system is thus
diag( D ) * diag( D ) +  RHO * Z * Z_transpose.
where we assume the Euclidean norm of Z is 1.
The method consists of approximating the rational functions in the
secular equation by simpler interpolating rational functions.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd5.html'>stdlib_slasd5</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>This subroutine computes the square root of the I-th eigenvalue
of a positive symmetric rank-one modification of a 2-by-2 diagonal
matrix
diag( D ) * diag( D ) +  RHO * Z * transpose(Z) .
The diagonal entries in the array D are assumed to satisfy
0 &lt;= D(i) &lt; D(j)  for  i &lt; j .
We also assume RHO &gt; 0 and that the Euclidean norm of the vector
Z is one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd6.html'>stdlib_slasd6</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>obtained by merging two smaller ones by appending a row. This
routine is used only for the problem which requires all singular
values and optionally singular vector matrices in factored form.
B is an N-by-M matrix with N = NL + NR + 1 and M = N + SQRE.
A related subroutine, SLASD1, handles the case in which all singular
values and singular vectors of the bidiagonal matrix are desired.
SLASD6 computes the SVD as follows:
( D1(in)    0    0       0 )
B = U(in) * (   Z1<strong>T   a   Z2</strong>T    b ) * VT(in)
(   0       0   D2(in)   0 )
= U(out) * ( D(out) 0) * VT(out)
where Z<strong>T = (Z1</strong>T a Z2<strong>T b) = u</strong>T VT**T, and u is a vector of dimension M
with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros
elsewhere; and the entry b is empty if SQRE = 0.
The singular values of B can be computed using D1, D2, the first
components of all the right singular vectors of the lower block, and
the last components of all the right singular vectors of the upper
block. These components are stored and updated in VF and VL,
respectively, in SLASD6. Hence U and VT are not explicitly
referenced.
The singular values are stored in D. The algorithm consists of two
stages:
The first stage consists of deflating the size of the problem
when there are multiple singular values or if there is a zero
in the Z vector. For each such occurrence the dimension of the
secular equation problem is reduced by one. This stage is
performed by the routine SLASD7.
The second stage consists of calculating the updated
singular values. This is done by finding the roots of the
secular equation via the routine SLASD4 (as called by SLASD8).
This routine also updates VF and VL and computes the distances
between the updated singular values and the old singular
values.
SLASD6 is called from SLASDA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd7.html'>stdlib_slasd7</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>sorted set. Then it tries to deflate the size of the problem. There
are two ways in which deflation can occur:  when two or more singular
values are close together or if there is a tiny entry in the Z
vector. For each such occurrence the order of the related
secular equation problem is reduced by one.
SLASD7 is called from SLASD6.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasd8.html'>stdlib_slasd8</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>as defined by the values in DSIGMA and Z. It makes the appropriate
calls to SLASD4, and stores, for each  element in D, the distance
to its two nearest poles (elements in DSIGMA). It also updates
the arrays VF and VL, the first and last components of all the
right singular vectors of the original bidiagonal matrix.
SLASD8 is called from SLASD6.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasda.html'>stdlib_slasda</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Using a divide and conquer approach, SLASDA: computes the singular
value decomposition (SVD) of a real upper bidiagonal N-by-M matrix
B with diagonal D and offdiagonal E, where M = N + SQRE. The
algorithm computes the singular values in the SVD B = U * S * VT.
The orthogonal matrices U and VT are optionally computed in
compact form.
A related subroutine, SLASD0, computes the singular values and
the singular vectors in explicit form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasdq.html'>stdlib_slasdq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>(upper or lower) bidiagonal matrix with diagonal D and offdiagonal
E, accumulating the transformations if desired. Letting B denote
the input bidiagonal matrix, the algorithm computes orthogonal
matrices Q and P such that B = Q * S * P<strong>T (P</strong>T denotes the transpose
of P). The singular values S are overwritten on D.
The input matrix U  is changed to U  * Q  if desired.
The input matrix VT is changed to P<strong>T * VT if desired.
The input matrix C  is changed to Q</strong>T * C  if desired.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3, for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasdt.html'>stdlib_slasdt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>conquer.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaset.html'>stdlib_slaset</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>ALPHA on the offdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasq1.html'>stdlib_slasq1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix with diagonal D and off-diagonal E. The singular values
are computed to high relative accuracy, in the absence of
denormalization, underflow and overflow. The algorithm was first
presented in
"Accurate singular values and differential qd algorithms" by K. V.
Fernando and B. N. Parlett, Numer. Math., Vol-67, No. 2, pp. 191-230,
1994,
and the present implementation is described in "An implementation of
the dqds Algorithm (Positive Case)", LAPACK Working Note.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasq2.html'>stdlib_slasq2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>definite tridiagonal matrix associated with the qd array Z to high
relative accuracy are computed to high relative accuracy, in the
absence of denormalization, underflow and overflow.
To see the relation of Z to the tridiagonal matrix, let L be a
unit lower bidiagonal matrix with subdiagonals Z(2,4,6,,..) and
let U be an upper bidiagonal matrix with 1's above and diagonal
Z(1,3,5,,..). The tridiagonal is L*U or, if you prefer, the
symmetric tridiagonal to which it is similar.
Note : SLASQ2 defines a logical variable, IEEE, which is true
on machines which follow ieee-754 floating-point standard in their
handling of infinities and NaNs, and false otherwise. This variable
is passed to SLASQ3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasq3.html'>stdlib_slasq3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>In case of failure it changes shifts, and tries again until output
is positive.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasq4.html'>stdlib_slasq4</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using values of d from the previous transform.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasq5.html'>stdlib_slasq5</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>version for IEEE machines another for non IEEE machines.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasq6.html'>stdlib_slasq6</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>ping-pong form, with protection against underflow and overflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasr.html'>stdlib_slasr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>from either the left or the right.
When SIDE = 'L', the transformation takes the form
A := P<em>A
and when SIDE = 'R', the transformation takes the form
A := A</em>P<strong>T
where P is an orthogonal matrix consisting of a sequence of z plane
rotations, with z = M when SIDE = 'L' and z = N when SIDE = 'R',
and P</strong>T is the transpose of P.
When DIRECT = 'F' (Forward sequence), then
P = P(z-1) * ... * P(2) * P(1)
and when DIRECT = 'B' (Backward sequence), then
P = P(1) * P(2) * ... * P(z-1)
where P(k) is a plane rotation matrix defined by the 2-by-2 rotation
R(k) = (  c(k)  s(k) )
= ( -s(k)  c(k) ).
When PIVOT = 'V' (Variable pivot), the rotation is performed
for the plane (k,k+1), i.e., P(k) has the form
P(k) = (  1                                            )
(       ...                                     )
(              1                                )
(                   c(k)  s(k)                  )
(                  -s(k)  c(k)                  )
(                                1              )
(                                     ...       )
(                                            1  )
where R(k) appears as a rank-2 modification to the identity matrix in
rows and columns k and k+1.
When PIVOT = 'T' (Top pivot), the rotation is performed for the
plane (1,k+1), so P(k) has the form
P(k) = (  c(k)                    s(k)                 )
(         1                                     )
(              ...                              )
(                     1                         )
( -s(k)                    c(k)                 )
(                                 1             )
(                                      ...      )
(                                             1 )
where R(k) appears in rows and columns 1 and k+1.
Similarly, when PIVOT = 'B' (Bottom pivot), the rotation is
performed for the plane (k,z), giving P(k) the form
P(k) = ( 1                                             )
(      ...                                      )
(             1                                 )
(                  c(k)                    s(k) )
(                         1                     )
(                              ...              )
(                                     1         )
(                 -s(k)                    c(k) )
where R(k) appears in rows and columns k and z.  The rotations are
performed without ever forming P(k) explicitly.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasrt.html'>stdlib_slasrt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Sort the numbers in D in increasing order (if ID = 'I') or
in decreasing order (if ID = 'D' ).
Use Quick Sort, reverting to Insertion sort on arrays of
size &lt;= 20. Dimension of STACK limits N to about 2**32.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slassq.html'>stdlib_slassq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_slassq.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_slasv2.html'>stdlib_slasv2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>triangular matrix
[  F   G  ]
[  0   H  ].
On return, abs(SSMAX) is the larger singular value, abs(SSMIN) is the
smaller singular value, and (CSL,SNL) and (CSR,SNR) are the left and
right singular vectors for abs(SSMAX), giving the decomposition
[ CSL  SNL ] [  F   G  ] [ CSR -SNR ]  =  [ SSMAX   0   ]
[-SNL  CSL ] [  0   H  ] [ SNR  CSR ]     [  0    SSMIN ].</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaswlq.html'>stdlib_slaswlq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real M-by-N matrix A for M &lt;= N:
A = ( L 0 ) *  Q,
where:
Q is a n-by-N orthogonal matrix, stored on exit in an implicit
form in the elements above the diagonal of the array A and in
the elements of the array T;
L is a lower-triangular M-by-M matrix stored on exit in
the elements on and below the diagonal of the array A.
0 is a M-by-(N-M) zero matrix, if M &lt; N, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slaswp.html'>stdlib_slaswp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>One row interchange is initiated for each of rows K1 through K2 of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasy2.html'>stdlib_slasy2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>op(TL)<em>X + ISGN</em>X<em>op(TR) = SCALE</em>B,
where TL is N1 by N1, TR is N2 by N2, B is N1 by N2, and ISGN = 1 or
-1.  op(T) = T or T<strong>T, where T</strong>T denotes the transpose of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasyf.html'>stdlib_slasyf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method. The partial
factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
SLASYF is an auxiliary routine called by SSYTRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasyf_aa.html'>stdlib_slasyf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>DLATRF_AA factorizes a panel of a real symmetric matrix A using
the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasyf_rk.html'>stdlib_slasyf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
SLASYF_RK is an auxiliary routine called by SSYTRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slasyf_rook.html'>stdlib_slasyf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
SLASYF_ROOK is an auxiliary routine called by SSYTRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatbs.html'>stdlib_slatbs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A <em>x = s</em>b  or  A<strong>T<em>x = s</em>b
with scaling to prevent overflow, where A is an upper or lower
triangular band matrix.  Here A</strong>T denotes the transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine STBSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatdf.html'>stdlib_slatdf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SGETC2 and computes a contribution to the reciprocal Dif-estimate
by solving Z * x = b for x, and choosing the r.h.s. b such that
the norm of x is as large as possible. On entry RHS = b holds the
contribution from earlier solved sub-systems, and on return RHS = x.
The factorization of Z returned by SGETC2 has the form Z = P<em>L</em>U*Q,
where P and Q are permutation matrices. L is lower triangular with
unit diagonal elements and U is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatps.html'>stdlib_slatps</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A <em>x = s</em>b  or  A<strong>T<em>x = s</em>b
with scaling to prevent overflow, where A is an upper or lower
triangular matrix stored in packed form.  Here A</strong>T denotes the
transpose of A, x and b are n-element vectors, and s is a scaling
factor, usually less than or equal to 1, chosen so that the
components of x will be less than the overflow threshold.  If the
unscaled problem will not cause overflow, the Level 2 BLAS routine
STPSV is called. If the matrix A is singular (A(j,j) = 0 for some j),
then s is set to 0 and a non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatrd.html'>stdlib_slatrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric tridiagonal form by an orthogonal similarity
transformation Q**T * A * Q, and returns the matrices V and W which are
needed to apply the transformation to the unreduced part of A.
If UPLO = 'U', SLATRD reduces the last NB rows and columns of a
matrix, of which the upper triangle is supplied;
if UPLO = 'L', SLATRD reduces the first NB rows and columns of a
matrix, of which the lower triangle is supplied.
This is an auxiliary routine called by SSYTRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatrs.html'>stdlib_slatrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A <em>x = s</em>b  or  A<strong>T<em>x = s</em>b
with scaling to prevent overflow.  Here A is an upper or lower
triangular matrix, A</strong>T denotes the transpose of A, x and b are
n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine STRSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatrz.html'>stdlib_slatrz</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>[ A1 A2 ] = [ A(1:M,1:M) A(1:M,N-L+1:N) ] as ( R  0 ) * Z, by means
of orthogonal transformations.  Z is an (M+L)-by-(M+L) orthogonal
matrix and, R and A1 are M-by-M upper triangular matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slatsqr.html'>stdlib_slatsqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real M-by-N matrix A for M &gt;= N:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix, stored on exit in an implicit
form in the elements below the diagonal of the array A and in
the elements of the array T;
R is an upper-triangular N-by-N matrix, stored on exit in
the elements on and above the diagonal of the array A.
0 is a (M-N)-by-N zero matrix, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slauu2.html'>stdlib_slauu2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the unblocked form of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_slauum.html'>stdlib_slauum</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the blocked form of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_snrm2.html'>stdlib_snrm2</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Function</td><td><p>!</p><a href="../proc/stdlib_snrm2.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_sopgtr.html'>stdlib_sopgtr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors H(i) of order n, as returned by
SSPTRD using packed storage:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sopmtr.html'>stdlib_sopmtr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by SSPTRD using packed
storage:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb.html'>stdlib_sorbdb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>partitioned orthogonal matrix X:
[ B11 | B12 0  0 ]
[ X11 | X12 ]   [ P1 |    ] [  0  |  0 -I  0 ] [ Q1 |    ]**T
X = [-----------] = [---------] [----------------] [---------]   .
[ X21 | X22 ]   [    | P2 ] [ B21 | B22 0  0 ] [    | Q2 ]
[  0  |  0  0  I ]
X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is
not the case, then X must be transposed and/or permuted. This can be
done in constant time using the TRANS and SIGNS options. See SORCSD
for details.)
The orthogonal matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by-
(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are
represented implicitly by Householder vectors.
B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb1.html'>stdlib_sorbdb1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P,
M-P, or M-Q. Routines SORBDB2, SORBDB3, and SORBDB4 handle cases in
which Q is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb2.html'>stdlib_sorbdb2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P,
Q, or M-Q. Routines SORBDB1, SORBDB3, and SORBDB4 handle cases in
which P is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are P-by-P bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb3.html'>stdlib_sorbdb3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P,
Q, or M-Q. Routines SORBDB1, SORBDB2, and SORBDB4 handle cases in
which M-P is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb4.html'>stdlib_sorbdb4</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P,
M-P, or Q. Routines SORBDB1, SORBDB2, and SORBDB3 handle cases in
which M-Q is not the minimum dimension.
The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb5.html'>stdlib_sorbdb5</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then some other vector from the orthogonal complement
is returned. This vector is chosen in an arbitrary but deterministic
way.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorbdb6.html'>stdlib_sorbdb6</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then the zero vector is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorcsd.html'>stdlib_sorcsd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>orthogonal matrix X:
[  I  0  0 |  0  0  0 ]
[  0  C  0 |  0 -S  0 ]
[ X11 | X12 ]   [ U1 |    ] [  0  0  0 |  0  0 -I ] [ V1 |    ]**T
X = [-----------] = [---------] [---------------------] [---------]   .
[ X21 | X22 ]   [    | U2 ] [  0  0  0 |  I  0  0 ] [    | V2 ]
[  0  S  0 |  0  C  0 ]
[  0  0  I |  0  0  0 ]
X11 is P-by-Q. The orthogonal matrices U1, U2, V1, and V2 are P-by-P,
(M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are
R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in
which R = MIN(P,M-P,Q,M-Q).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorcsd2by1.html'>stdlib_sorcsd2by1</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>orthonormal columns that has been partitioned into a 2-by-1 block
structure:
[  I1 0  0 ]
[  0  C  0 ]
[ X11 ]   [ U1 |    ] [  0  0  0 ]
X = [-----] = [---------] [----------] V1**T .
[ X21 ]   [    | U2 ] [  0  0  0 ]
[  0  S  0 ]
[  0  0  I2]
X11 is P-by-Q. The orthogonal matrices U1, U2, and V1 are P-by-P,
(M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R
nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which
R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a
K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorg2l.html'>stdlib_sorg2l</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the last n columns of a product of k elementary
reflectors of order m
Q  =  H(k) . . . H(2) H(1)
as returned by SGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorg2r.html'>stdlib_sorg2r</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the first n columns of a product of k elementary
reflectors of order m
Q  =  H(1) H(2) . . . H(k)
as returned by SGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgbr.html'>stdlib_sorgbr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>determined by SGEBRD when reducing a real matrix A to bidiagonal
form: A = Q * B * P<strong>T.  Q and P</strong>T are defined as products of
elementary reflectors H(i) or G(i) respectively.
If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q
is of order M:
if m &gt;= k, Q = H(1) H(2) . . . H(k) and SORGBR returns the first n
columns of Q, where m &gt;= n &gt;= k;
if m &lt; k, Q = H(1) H(2) . . . H(m-1) and SORGBR returns Q as an
M-by-M matrix.
If VECT = 'P', A is assumed to have been a K-by-N matrix, and P<strong>T
is of order N:
if k &lt; n, P</strong>T = G(k) . . . G(2) G(1) and SORGBR returns the first m
rows of P<strong>T, where n &gt;= m &gt;= k;
if k &gt;= n, P</strong>T = G(n-1) . . . G(2) G(1) and SORGBR returns P**T as
an N-by-N matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorghr.html'>stdlib_sorghr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>product of IHI-ILO elementary reflectors of order N, as returned by
SGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgl2.html'>stdlib_sorgl2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the first m rows of a product of k elementary
reflectors of order n
Q  =  H(k) . . . H(2) H(1)
as returned by SGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorglq.html'>stdlib_sorglq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the first M rows of a product of K elementary
reflectors of order N
Q  =  H(k) . . . H(2) H(1)
as returned by SGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgql.html'>stdlib_sorgql</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the last N columns of a product of K elementary
reflectors of order M
Q  =  H(k) . . . H(2) H(1)
as returned by SGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgqr.html'>stdlib_sorgqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the first N columns of a product of K elementary
reflectors of order M
Q  =  H(1) H(2) . . . H(k)
as returned by SGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgr2.html'>stdlib_sorgr2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the last m rows of a product of k elementary
reflectors of order n
Q  =  H(1) H(2) . . . H(k)
as returned by SGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgrq.html'>stdlib_sorgrq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which is defined as the last M rows of a product of K elementary
reflectors of order N
Q  =  H(1) H(2) . . . H(k)
as returned by SGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgtr.html'>stdlib_sorgtr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors of order N, as returned by
SSYTRD:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgtsqr.html'>stdlib_sorgtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>which are the first N columns of a product of real orthogonal
matrices of order M which are returned by SLATSQR
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
See the documentation for SLATSQR.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorgtsqr_row.html'>stdlib_sorgtsqr_row</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>orthonormal columns from the output of SLATSQR. These N orthonormal
columns are the first N columns of a product of complex unitary
matrices Q(k)_in of order M, which are returned by SLATSQR in
a special format.
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
The input matrices Q(k)_in are stored in row and column blocks in A.
See the documentation of SLATSQR for more details on the format of
Q(k)_in, where each Q(k)_in is represented by block Householder
transformations. This routine calls an auxiliary routine SLARFB_GETT,
where the computation is performed on each individual block. The
algorithm first sweeps NB-sized column blocks from the right to left
starting in the bottom row block and continues to the top row block
(hence _ROW in the routine name). This sweep is in reverse order of
the order in which SLATSQR generates the output blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorhr_col.html'>stdlib_sorhr_col</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>as input, stored in A, and performs Householder Reconstruction (HR),
i.e. reconstructs Householder vectors V(i) implicitly representing
another M-by-N matrix Q_out, with the property that Q_in = Q_out*S,
where S is an N-by-N diagonal matrix with diagonal entries
equal to +1 or -1. The Householder vectors (columns V(i) of V) are
stored in A on output, and the diagonal entries of S are stored in D.
Block reflectors are also returned in T
(same output format as SGEQRT).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorm22.html'>stdlib_sorm22</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_sorm2l.html'>stdlib_sorm2l</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T * C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by SGEQLF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorm2r.html'>stdlib_sorm2r</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by SGEQRF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormbr.html'>stdlib_sormbr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>If VECT = 'Q', SORMBR: overwrites the general real M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
If VECT = 'P', SORMBR overwrites the general real M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      P * C          C * P
TRANS = 'T':      P<strong>T * C       C * P</strong>T
Here Q and P<strong>T are the orthogonal matrices determined by SGEBRD when
reducing a real matrix A to bidiagonal form: A = Q * B * P</strong>T. Q and
P<strong>T are defined as products of elementary reflectors H(i) and G(i)
respectively.
Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the
order of the orthogonal matrix Q or P</strong>T that is applied.
If VECT = 'Q', A is assumed to have been an NQ-by-K matrix:
if nq &gt;= k, Q = H(1) H(2) . . . H(k);
if nq &lt; k, Q = H(1) H(2) . . . H(nq-1).
If VECT = 'P', A is assumed to have been a K-by-NQ matrix:
if k &lt; nq, P = G(1) G(2) . . . G(k);
if k &gt;= nq, P = G(1) G(2) . . . G(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormhr.html'>stdlib_sormhr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
IHI-ILO elementary reflectors, as returned by SGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sorml2.html'>stdlib_sorml2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by SGELQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormlq.html'>stdlib_sormlq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by SGELQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormql.html'>stdlib_sormql</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by SGEQLF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormqr.html'>stdlib_sormqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by SGEQRF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormr2.html'>stdlib_sormr2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'T', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'T',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by SGERQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormr3.html'>stdlib_sormr3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>T* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>T if SIDE = 'R' and TRANS = 'C',
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by STZRZF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormrq.html'>stdlib_sormrq</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by SGERQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormrz.html'>stdlib_sormrz</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by STZRZF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sormtr.html'>stdlib_sormtr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>T * C       C * Q</strong>T
where Q is a real orthogonal matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by SSYTRD:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbcon.html'>stdlib_spbcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite band matrix using the
Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by SPBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbequ.html'>stdlib_spbequ</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric positive definite band matrix A and reduce its condition
number (with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbrfs.html'>stdlib_spbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite
and banded, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbstf.html'>stdlib_spbstf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric positive definite band matrix A.
This routine is designed to be used in conjunction with SSBGST.
The factorization has the form  A = S*<em>T</em>S  where S is a band matrix
of the same bandwidth as A and the following structure:
S = ( U    )
( M  L )
where U is upper triangular of order m = (n+kd)/2, and L is lower
triangular of order n-m.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbsv.html'>stdlib_spbsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite band matrix and X
and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>T * U,  if UPLO = 'U', or
A = L * L</strong>T,  if UPLO = 'L',
where U is an upper triangular band matrix, and L is a lower
triangular band matrix, with the same number of superdiagonals or
subdiagonals as A.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbsvx.html'>stdlib_spbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>compute the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric positive definite band matrix and X
and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbtf2.html'>stdlib_spbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>T * U ,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix, U**T is the transpose of U, and
L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbtrf.html'>stdlib_spbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spbtrs.html'>stdlib_spbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite band matrix A using the Cholesky factorization
A = U<strong>T<em>U or A = L</em>L</strong>T computed by SPBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spftrf.html'>stdlib_spftrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spftri.html'>stdlib_spftri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T
computed by SPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spftrs.html'>stdlib_spftrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>T<em>U or A = L</em>L</strong>T computed by SPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spocon.html'>stdlib_spocon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite matrix using the
Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by SPOTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spoequ.html'>stdlib_spoequ</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spoequb.html'>stdlib_spoequb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.
This routine differs from SPOEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled diagonal entries are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sporfs.html'>stdlib_sporfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite,
and provides error bounds and backward error estimates for the
solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sposv.html'>stdlib_sposv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite matrix and X and B
are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>T* U,  if UPLO = 'U', or
A = L * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sposvx.html'>stdlib_sposvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>compute the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric positive definite matrix and X and B
are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spotf2.html'>stdlib_spotf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>T * U ,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spotrf.html'>stdlib_spotrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spotrf2.html'>stdlib_spotrf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A using the recursive algorithm.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = n/2
[  A21 | A22  ]       n2 = n-n1
The subroutine calls itself to factor A11. Update and scale A21
or A12, update A22 then call itself to factor A22.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spotri.html'>stdlib_spotri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T
computed by SPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spotrs.html'>stdlib_spotrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>T<em>U or A = L</em>L</strong>T computed by SPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sppcon.html'>stdlib_sppcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite packed matrix using
the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by
SPPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sppequ.html'>stdlib_sppequ</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric positive definite matrix A in packed storage and reduce
its condition number (with respect to the two-norm).  S contains the
scale factors, S(i)=1/sqrt(A(i,i)), chosen so that the scaled matrix
B with elements B(i,j)=S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.
This choice of S puts the condition number of B within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spprfs.html'>stdlib_spprfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sppsv.html'>stdlib_sppsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>T* U,  if UPLO = 'U', or
A = L * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sppsvx.html'>stdlib_sppsvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>compute the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spptrf.html'>stdlib_spptrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A stored in packed format.
The factorization has the form
A = U<strong>T * U,  if UPLO = 'U', or
A = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spptri.html'>stdlib_spptri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>T<em>U or A = L</em>L</strong>T
computed by SPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spptrs.html'>stdlib_spptrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite matrix A in packed storage using the Cholesky
factorization A = U<strong>T<em>U or A = L</em>L</strong>T computed by SPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spstf2.html'>stdlib_spstf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>pivoting of a real symmetric positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>T * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spstrf.html'>stdlib_spstrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>pivoting of a real symmetric positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>T * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>T,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sptcon.html'>stdlib_sptcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric positive definite tridiagonal matrix
using the factorization A = L<em>D</em>L<strong>T or A = U</strong>T<em>D</em>U computed by
SPTTRF.
Norm(inv(A)) is computed by a direct method, and the reciprocal of
the condition number is computed as
RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spteqr.html'>stdlib_spteqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric positive definite tridiagonal matrix by first factoring the
matrix using SPTTRF, and then calling SBDSQR to compute the singular
values of the bidiagonal factor.
This routine computes the eigenvalues of the positive definite
tridiagonal matrix to high relative accuracy.  This means that if the
eigenvalues range over many orders of magnitude in size, then the
small eigenvalues and corresponding eigenvectors will be computed
more accurately than, for example, with the standard QR method.
The eigenvectors of a full or band symmetric positive definite matrix
can also be found if SSYTRD, SSPTRD, or SSBTRD has been used to
reduce this matrix to tridiagonal form. (The reduction to tridiagonal
form, however, may preclude the possibility of obtaining high
relative accuracy in the small eigenvalues of the original matrix, if
these eigenvalues range over many orders of magnitude.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sptrfs.html'>stdlib_sptrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric positive definite
and tridiagonal, and provides error bounds and backward error
estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sptsv.html'>stdlib_sptsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A<em>X = B, where A is an N-by-N symmetric positive definite tridiagonal
matrix, and X and B are N-by-NRHS matrices.
A is factored as A = L</em>D<em>L</em>*T, and the factored form of A is then
used to solve the system of equations.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sptsvx.html'>stdlib_sptsvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to a real system of linear equations A*X = B, where A is an N-by-N
symmetric positive definite tridiagonal matrix and X and B are
N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spttrf.html'>stdlib_spttrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>positive definite tridiagonal matrix A.  The factorization may also
be regarded as having the form A = U<em><em>T</em>D</em>U.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_spttrs.html'>stdlib_spttrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B
using the L<em>D</em>L**T factorization of A computed by SPTTRF.  D is a
diagonal matrix specified in the vector D, L is a unit bidiagonal
matrix whose subdiagonal is specified in the vector E, and X and B
are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sptts2.html'>stdlib_sptts2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B
using the L<em>D</em>L**T factorization of A computed by SPTTRF.  D is a
diagonal matrix specified in the vector D, L is a unit bidiagonal
matrix whose subdiagonal is specified in the vector E, and X and B
are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_srot.html'>stdlib_srot</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>applies a plane rotation.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_srotg.html'>stdlib_srotg</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_srotg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_srotm.html'>stdlib_srotm</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>APPLY THE MODIFIED GIVENS TRANSFORMATION, H, TO THE 2 BY N MATRIX
(SX<strong>T) , WHERE </strong>T INDICATES TRANSPOSE. THE ELEMENTS OF SX ARE IN
(SX<em><em>T)
SX(LX+I</em>INCX), I = 0 TO N-1, WHERE LX = 1 IF INCX &gt;= 0, ELSE
LX = (-INCX)</em>N, AND SIMILARLY FOR SY USING USING LY AND INCY.
WITH SPARAM(1)=SFLAG, H HAS ONE OF THE FOLLOWING FORMS..
SFLAG=-1._sp     SFLAG=0._sp        SFLAG=1._sp     SFLAG=-2.E0
(SH11  SH12)    (1._sp  SH12)    (SH11  1._sp)    (1._sp  0._sp)
H=(          )    (          )    (          )    (          )
(SH21  SH22),   (SH21  1._sp),   (-1._sp SH22),   (0._sp  1._sp).
SEE  SROTMG FOR A DESCRIPTION OF DATA STORAGE IN SPARAM.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_srotmg.html'>stdlib_srotmg</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>CONSTRUCT THE MODIFIED GIVENS TRANSFORMATION MATRIX H WHICH ZEROS
THE SECOND COMPONENT OF THE 2-VECTOR  (SQRT(SD1)<em>SX1,SQRT(SD2)    SY2)</em>*T.
WITH SPARAM(1)=SFLAG, H HAS ONE OF THE FOLLOWING FORMS..
SFLAG=-1._sp     SFLAG=0._sp        SFLAG=1._sp     SFLAG=-2.E0
(SH11  SH12)    (1._sp  SH12)    (SH11  1._sp)    (1._sp  0._sp)
H=(          )    (          )    (          )    (          )
(SH21  SH22),   (SH21  1._sp),   (-1._sp SH22),   (0._sp  1._sp).
LOCATIONS 2-4 OF SPARAM CONTAIN SH11,SH21,SH12, AND SH22
RESPECTIVELY. (VALUES OF 1._sp, -1._sp, OR 0._sp IMPLIED BY THE
VALUE OF SPARAM(1) ARE NOT STORED IN SPARAM.)
THE VALUES OF GAMSQ AND RGAMSQ SET IN THE DATA STATEMENT MAY BE
INEXACT.  THIS IS OK AS THEY ARE ONLY USED FOR TESTING THE SIZE
OF SD1 AND SD2.  ALL ACTUAL SCALING OF DATA IS DONE USING GAM.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sroundup_lwork.html'>stdlib_sroundup_lwork</a></td><td><a href='../module/stdlib_linalg_lapack_aux.html'>stdlib_linalg_lapack_aux</a></td><td>Function</td><td><p>This routine guarantees it is rounded up instead of down by
multiplying LWORK by 1+eps when it is necessary, where eps is the relative machine precision.
E.g.,
float( 16777217            ) == 16777216
float( 16777217 ) * (1.+eps) == 16777218
\return SROUNDUP_LWORK</p><a href="../proc/stdlib_sroundup_lwork.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_srscl.html'>stdlib_srscl</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>This is done without overflow or underflow as long as
the final result x/a does not overflow or underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssb2st_kernels.html'>stdlib_ssb2st_kernels</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>subroutine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbev.html'>stdlib_ssbev</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real symmetric band matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbevd.html'>stdlib_ssbevd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real symmetric band matrix A. If eigenvectors are desired, it uses
a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbevx.html'>stdlib_ssbevx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric band matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbgst.html'>stdlib_ssbgst</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenproblem  A<em>x = lambda</em>B<em>x  to standard form  C</em>y = lambda<em>y,
such that C has the same bandwidth as A.
B must have been previously factorized as S</em><em>T</em>S by SPBSTF, using a
split Cholesky factorization. A is overwritten by C = X<strong>T<em>A</em>X, where
X = S</strong>(-1)*Q and Q is an orthogonal matrix chosen to preserve the
bandwidth of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbgv.html'>stdlib_ssbgv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be symmetric
and banded, and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbgvd.html'>stdlib_ssbgvd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of the
form A<em>x=(lambda)</em>B*x.  Here A and B are assumed to be symmetric and
banded, and B is also positive definite.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbgvx.html'>stdlib_ssbgvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x.  Here A and B are assumed to be symmetric
and banded, and B is also positive definite.  Eigenvalues and
eigenvectors can be selected by specifying either all eigenvalues,
a range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbmv.html'>stdlib_ssbmv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric band matrix, with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssbtrd.html'>stdlib_ssbtrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>tridiagonal form T by an orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sscal.html'>stdlib_sscal</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>uses unrolled loops for increment equal to 1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssfrk.html'>stdlib_ssfrk</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for C in RFP Format.
SSFRK: performs one of the symmetric rank--k operations
C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where alpha and beta are real scalars, C is an n--by--n symmetric
matrix and A is an n--by--k matrix in the first case and a k--by--n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspcon.html'>stdlib_sspcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric packed matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by SSPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspev.html'>stdlib_sspev</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real symmetric matrix A in packed storage.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspevd.html'>stdlib_sspevd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A in packed storage. If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspevx.html'>stdlib_sspevx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A in packed storage.  Eigenvalues/vectors
can be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspgst.html'>stdlib_sspgst</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to standard form, using packed storage.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T</em>A<em>L.
B must have been previously factorized as U</em><em>T</em>U or L<em>L</em>*T by SPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspgv.html'>stdlib_sspgv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be symmetric, stored in packed format,
and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspgvd.html'>stdlib_sspgvd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be symmetric, stored in packed format, and B is also
positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspgvx.html'>stdlib_sspgvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A
and B are assumed to be symmetric, stored in packed storage, and B
is also positive definite.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of indices
for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspmv.html'>stdlib_sspmv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspr.html'>stdlib_sspr</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**T + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspr2.html'>stdlib_sspr2</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>T + alpha<em>y</em>x</strong>T + A,
where alpha is a scalar, x and y are n element vectors and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssprfs.html'>stdlib_ssprfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspsv.html'>stdlib_sspsv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is symmetric and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sspsvx.html'>stdlib_sspsvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = L<em>D</em>L**T to compute the solution to a real system of linear
equations A * X = B, where A is an N-by-N symmetric matrix stored
in packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssptrd.html'>stdlib_ssptrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric tridiagonal form T by an orthogonal similarity
transformation: Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssptrf.html'>stdlib_ssptrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>in packed format using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssptri.html'>stdlib_ssptri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by SSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssptrs.html'>stdlib_ssptrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by SSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstebz.html'>stdlib_sstebz</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix T.  The user may ask for all eigenvalues, all eigenvalues
in the half-open interval (VL, VU], or the IL-th through IU-th
eigenvalues.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstedc.html'>stdlib_sstedc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.
The eigenvectors of a full or band real symmetric matrix can also be
found if SSYTRD or SSPTRD or SSBTRD has been used to reduce this
matrix to tridiagonal form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See SLAED3 for details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstegr.html'>stdlib_sstegr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
SSTEGR is a compatibility wrapper around the improved SSTEMR routine.
See SSTEMR for further details.
One important change is that the ABSTOL parameter no longer provides any
benefit and hence is no longer used.
Note : SSTEGR and SSTEMR work only on machines which follow
IEEE-754 floating-point standard in their handling of infinities and
NaNs.  Normal execution may create these exceptiona values and hence
may abort due to a floating point exception in environments which
do not conform to the IEEE-754 standard.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstein.html'>stdlib_sstein</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix T corresponding to specified eigenvalues, using inverse
iteration.
The maximum number of iterations allowed for each eigenvector is
specified by an internal parameter MAXITS (currently set to 5).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstemr.html'>stdlib_sstemr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
Depending on the number of desired eigenvalues, these are computed either
by bisection or the dqds algorithm. Numerically orthogonal eigenvectors are
computed by the use of various suitable L D L^T factorizations near clusters
of close eigenvalues (referred to as RRRs, Relatively Robust
Representations). An informal sketch of the algorithm follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
For more details, see:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Further Details
1.SSTEMR works only on machines which follow IEEE-754
floating-point standard in their handling of infinities and NaNs.
This permits the use of efficient inner loops avoiding a check for
zero divisors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssteqr.html'>stdlib_ssteqr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the implicit QL or QR method.
The eigenvectors of a full or band symmetric matrix can also be found
if SSYTRD or SSPTRD or SSBTRD has been used to reduce this matrix to
tridiagonal form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssterf.html'>stdlib_ssterf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the Pal-Walker-Kahan variant of the QL or QR algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstev.html'>stdlib_sstev</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real symmetric tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstevd.html'>stdlib_sstevd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real symmetric tridiagonal matrix. If eigenvectors are desired, it
uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstevr.html'>stdlib_sstevr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T.  Eigenvalues and
eigenvectors can be selected by specifying either a range of values
or a range of indices for the desired eigenvalues.
Whenever possible, SSTEVR calls SSTEMR to compute the
eigenspectrum using Relatively Robust Representations.  SSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows. For the i-th
unreduced block of T,
(a) Compute T - sigma_i = L_i D_i L_i^T, such that L_i D_i L_i^T
is a relatively robust representation,
(b) Compute the eigenvalues, lambda_j, of L_i D_i L_i^T to high
relative accuracy by the dqds algorithm,
(c) If there is a cluster of close eigenvalues, "choose" sigma_i
close to the cluster, and go to step (a),
(d) Given the approximate eigenvalue lambda_j of L_i D_i L_i^T,
compute the corresponding eigenvector by forming a
rank-revealing twisted factorization.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem", by Inderjit Dhillon,
Computer Science Division Technical Report No. UCB//CSD-97-971,
UC Berkeley, May 1997.
Note 1 : SSTEVR calls SSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
SSTEVR calls SSTEBZ and SSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of SSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sstevx.html'>stdlib_sstevx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix A.  Eigenvalues and
eigenvectors can be selected by specifying either a range of values
or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_sswap.html'>stdlib_sswap</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>uses unrolled loops for increments equal to 1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssycon.html'>stdlib_ssycon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by SSYTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssycon_rook.html'>stdlib_ssycon_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>1-norm) of a real symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by SSYTRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyconv.html'>stdlib_ssyconv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Get Non-diag elements of D (returned in workspace) and
apply or reverse permutation done in TRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyconvf.html'>stdlib_ssyconvf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
SSYCONVF: converts the factorization output format used in
SSYTRF provided on entry in parameter A into the factorization
output format used in SSYTRF_RK (or SSYTRF_BK) that is stored
on exit in parameters A and E. It also converts in place details of
the intechanges stored in IPIV from the format used in SSYTRF into
the format used in SSYTRF_RK (or SSYTRF_BK).
If parameter WAY = 'R':
SSYCONVF performs the conversion in reverse direction, i.e.
converts the factorization output format used in SSYTRF_RK
(or SSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in SSYTRF that is stored
on exit in parameter A. It also converts in place details of
the intechanges stored in IPIV from the format used in SSYTRF_RK
(or SSYTRF_BK) into the format used in SSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyconvf_rook.html'>stdlib_ssyconvf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
SSYCONVF_ROOK: converts the factorization output format used in
SSYTRF_ROOK provided on entry in parameter A into the factorization
output format used in SSYTRF_RK (or SSYTRF_BK) that is stored
on exit in parameters A and E. IPIV format for SSYTRF_ROOK and
SSYTRF_RK (or SSYTRF_BK) is the same and is not converted.
If parameter WAY = 'R':
SSYCONVF_ROOK performs the conversion in reverse direction, i.e.
converts the factorization output format used in SSYTRF_RK
(or SSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in SSYTRF_ROOK that is stored
on exit in parameter A. IPIV format for SSYTRF_ROOK and
SSYTRF_RK (or SSYTRF_BK) is the same and is not converted.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyequb.html'>stdlib_ssyequb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyev.html'>stdlib_ssyev</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyevd.html'>stdlib_ssyevd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>real symmetric matrix A. If eigenvectors are desired, it uses a
divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.
Because of large use of BLAS of level 3, SSYEVD needs N**2 more
workspace than SSYEVX.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyevr.html'>stdlib_ssyevr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of
indices for the desired eigenvalues.
SSYEVR first reduces the matrix A to tridiagonal form T with a call
to SSYTRD.  Then, whenever possible, SSYEVR calls SSTEMR to compute
the eigenspectrum using Relatively Robust Representations.  SSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see SSTEMR's documentation and:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Note 1 : SSYEVR calls SSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
SSYEVR calls SSTEBZ and SSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of SSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyevx.html'>stdlib_ssyevx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real symmetric matrix A.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of indices
for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssygs2.html'>stdlib_ssygs2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T </em>A<em>L.
B must have been previously factorized as U</em><em>T </em>U or L<em>L</em>*T by SPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssygst.html'>stdlib_ssygst</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T</em>A<em>L.
B must have been previously factorized as U</em><em>T</em>U or L<em>L</em>*T by SPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssygv.html'>stdlib_ssygv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be symmetric and B is also
positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssygvd.html'>stdlib_ssygvd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be symmetric and B is also positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssygvx.html'>stdlib_ssygvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A
and B are assumed to be symmetric and B is also positive definite.
Eigenvalues and eigenvectors can be selected by specifying either a
range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssymm.html'>stdlib_ssymm</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where alpha and beta are scalars,  A is a symmetric matrix and  B and
C are  m by n matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssymv.html'>stdlib_ssymv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyr.html'>stdlib_ssyr</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**T + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyr2.html'>stdlib_ssyr2</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>T + alpha<em>y</em>x</strong>T + A,
where alpha is a scalar, x and y are n element vectors and A is an n
by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyr2k.html'>stdlib_ssyr2k</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B<strong>T + alpha<em>B</em>A</strong>T + beta<em>C,
or
C := alpha</em>A<strong>T<em>B + alpha</em>B</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars, C is an  n by n  symmetric matrix
and  A and B  are  n by k  matrices  in the  first  case  and  k by n
matrices in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyrfs.html'>stdlib_ssyrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyrk.html'>stdlib_ssyrk</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars, C is an  n by n  symmetric matrix
and  A  is an  n by k  matrix in the first case and a  k by n  matrix
in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssysv.html'>stdlib_ssysv</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssysv_aa.html'>stdlib_ssysv_aa</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>SSYSV computes the solution to a real system of linear equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>T * T * U,  if UPLO = 'U', or
A = L * T * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is symmetric tridiagonal. The factored
form of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssysv_rk.html'>stdlib_ssysv_rk</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations A * X = B, where A is an N-by-N symmetric matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
SSYTRF_RK is called to compute the factorization of a real
symmetric matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine SSYTRS_3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssysv_rook.html'>stdlib_ssysv_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
SSYTRF_ROOK is called to compute the factorization of a real
symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling SSYTRS_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssysvx.html'>stdlib_ssysvx</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>solution to a real system of linear equations A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssyswapr.html'>stdlib_ssyswapr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytd2.html'>stdlib_ssytd2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>form T by an orthogonal similarity transformation: Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytf2.html'>stdlib_ssytf2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytf2_rk.html'>stdlib_ssytf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytf2_rook.html'>stdlib_ssytf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrd.html'>stdlib_ssytrd</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>tridiagonal form T by an orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrd_sb2st.html'>stdlib_ssytrd_sb2st</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>tridiagonal form T by a orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrd_sy2sb.html'>stdlib_ssytrd_sy2sb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>band-diagonal form AB by a orthogonal similarity transformation:
Q**T * A * Q = AB.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrf.html'>stdlib_ssytrf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<strong>T<em>D</em>U  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrf_aa.html'>stdlib_ssytrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>T<em>T</em>U  or  A = L<em>T</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a symmetric tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrf_rk.html'>stdlib_ssytrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrf_rook.html'>stdlib_ssytrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytri.html'>stdlib_ssytri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by
SSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytri_rook.html'>stdlib_ssytri_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T
computed by SSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrs.html'>stdlib_ssytrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by SSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrs2.html'>stdlib_ssytrs2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by SSYTRF and converted by SSYCONV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrs_3.html'>stdlib_ssytrs_3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization computed
by SSYTRF_RK or SSYTRF_BK:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrs_aa.html'>stdlib_ssytrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<strong>T<em>T</em>U or
A = L<em>T</em>L</strong>T computed by SSYTRF_AA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ssytrs_rook.html'>stdlib_ssytrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by SSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stbcon.html'>stdlib_stbcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>triangular band matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stbmv.html'>stdlib_stbmv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular band matrix, with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stbrfs.html'>stdlib_stbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular band
coefficient matrix.
The solution matrix X must be computed by STBTRS or some other
means before entering this routine.  STBRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stbsv.html'>stdlib_stbsv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular band matrix, with ( k + 1 )
diagonals.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stbtrs.html'>stdlib_stbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B,
where A is a triangular band matrix of order N, and B is an
N-by NRHS matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stfsm.html'>stdlib_stfsm</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for A in RFP Format.
STFSM:  solves the matrix equation
op( A )<em>X = alpha</em>B  or  X<em>op( A ) = alpha</em>B
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**T.
A is in Rectangular Full Packed (RFP) Format.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stftri.html'>stdlib_stftri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>format.
This is a Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stfttp.html'>stdlib_stfttp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>format (TF) to standard packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stfttr.html'>stdlib_stfttr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>format (TF) to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgevc.html'>stdlib_stgevc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a pair of real matrices (S,P), where S is a quasi-triangular matrix
and P is upper triangular.  Matrix pairs of this type are produced by
the generalized Schur factorization of a matrix pair (A,B):
A = Q<em>S</em>Z<strong>T,  B = Q<em>P</em>Z</strong>T
as computed by SGGHRD + SHGEQZ.
The right eigenvector x and the left eigenvector y of (S,P)
corresponding to an eigenvalue w are defined by:
S<em>x = w</em>P<em>x,  (y</em><em>H)</em>S = w<em>(y</em><em>H)</em>P,
where y<em><em>H denotes the conjugate tranpose of y.
The eigenvalues are not input to this routine, but are computed
directly from the diagonal blocks of S and P.
This routine returns the matrices X and/or Y of right and left
eigenvectors of (S,P), or the products Z</em>X and/or Q</em>Y,
where Z and Q are input matrices.
If Q and Z are the orthogonal factors from the generalized Schur
factorization of a matrix pair (A,B), then Z<em>X and Q</em>Y
are the matrices of right and left eigenvectors of (A,B).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgex2.html'>stdlib_stgex2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of size 1-by-1 or 2-by-2 in an upper (quasi) triangular matrix pair
(A, B) by an orthogonal equivalence transformation.
(A, B) must be in generalized real Schur canonical form (as returned
by SGGES), i.e. A is block upper triangular with 1-by-1 and 2-by-2
diagonal blocks. B is upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)<strong>T = Q(out) * A(out) * Z(out)</strong>T
Q(in) * B(in) * Z(in)<strong>T = Q(out) * B(out) * Z(out)</strong>T</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgexc.html'>stdlib_stgexc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix pair (A,B) using an orthogonal equivalence transformation
(A, B) = Q * (A, B) * Z<strong>T,
so that the diagonal block of (A, B) with row index IFST is moved
to row ILST.
(A, B) must be in generalized real Schur canonical form (as returned
by SGGES), i.e. A is block upper triangular with 1-by-1 and 2-by-2
diagonal blocks. B is upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)</strong>T = Q(out) * A(out) * Z(out)<strong>T
Q(in) * B(in) * Z(in)</strong>T = Q(out) * B(out) * Z(out)**T</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgsen.html'>stdlib_stgsen</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix pair (A, B) (in terms of an orthonormal equivalence trans-
formation Q*<em>T * (A, B) * Z), so that a selected cluster of eigenvalues
appears in the leading diagonal blocks of the upper quasi-triangular
matrix A and the upper triangular B. The leading columns of Q and
Z form orthonormal bases of the corresponding left and right eigen-
spaces (deflating subspaces). (A, B) must be in generalized real
Schur canonical form (as returned by SGGES), i.e. A is block upper
triangular with 1-by-1 and 2-by-2 diagonal blocks. B is upper
triangular.
STGSEN also computes the generalized eigenvalues
w(j) = (ALPHAR(j) + i</em>ALPHAI(j))/BETA(j)
of the reordered matrix pair (A, B).
Optionally, STGSEN computes the estimates of reciprocal condition
numbers for eigenvalues and eigenspaces. These are Difu[(A11,B11),
(A22,B22)] and Difl[(A11,B11), (A22,B22)], i.e. the separation(s)
between the matrix pairs (A11, B11) and (A22,B22) that correspond to
the selected cluster and the eigenvalues outside the cluster, resp.,
and norms of "projections" onto left and right eigenspaces w.r.t.
the selected cluster in the (1,1)-block.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgsja.html'>stdlib_stgsja</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>of two real upper triangular (or trapezoidal) matrices A and B.
On entry, it is assumed that matrices A and B have the following
forms, which may be obtained by the preprocessing subroutine SGGSVP
from a general M-by-N matrix A and P-by-N matrix B:
N-K-L  K    L
A =    K ( 0    A12  A13 ) if M-K-L &gt;= 0;
L ( 0     0   A23 )
M-K-L ( 0     0    0  )
N-K-L  K    L
A =  K ( 0    A12  A13 ) if M-K-L &lt; 0;
M-K ( 0     0   A23 )
N-K-L  K    L
B =  L ( 0     0   B13 )
P-L ( 0     0    0  )
where the K-by-K matrix A12 and L-by-L matrix B13 are nonsingular
upper triangular; A23 is L-by-L upper triangular if M-K-L &gt;= 0,
otherwise A23 is (M-K)-by-L upper trapezoidal.
On exit,
U<strong>T <em>A</em>Q = D1*( 0 R ),    V</strong>T <em>B</em>Q = D2<em>( 0 R ),
where U, V and Q are orthogonal matrices.
R is a nonsingular upper triangular matrix, and D1 and D2 are
``diagonal'' matrices, which are of the following structures:
If M-K-L &gt;= 0,
K  L
D1 =     K ( I  0 )
L ( 0  C )
M-K-L ( 0  0 )
K  L
D2 = L   ( 0  S )
P-L ( 0  0 )
N-K-L  K    L
( 0 R ) = K (  0   R11  R12 ) K
L (  0    0   R22 ) L
where
C = diag( ALPHA(K+1), ... , ALPHA(K+L) ),
S = diag( BETA(K+1),  ... , BETA(K+L) ),
C</em><em>2 + S</em><em>2 = I.
R is stored in A(1:K+L,N-K-L+1:N) on exit.
If M-K-L &lt; 0,
K M-K K+L-M
D1 =   K ( I  0    0   )
M-K ( 0  C    0   )
K M-K K+L-M
D2 =   M-K ( 0  S    0   )
K+L-M ( 0  0    I   )
P-L ( 0  0    0   )
N-K-L  K   M-K  K+L-M
( 0 R ) =    K ( 0    R11  R12  R13  )
M-K ( 0     0   R22  R23  )
K+L-M ( 0     0    0   R33  )
where
C = diag( ALPHA(K+1), ... , ALPHA(M) ),
S = diag( BETA(K+1),  ... , BETA(M) ),
C</em><em>2 + S</em>*2 = I.
R = ( R11 R12 R13 ) is stored in A(1:M, N-K-L+1:N) and R33 is stored
(  0  R22 R23 )
in B(M-K+1:L,N+M-K-L+1:N) on exit.
The computation of the orthogonal transformation matrices U, V or Q
is optional.  These matrices may either be formed explicitly, or they
may be postmultiplied into input matrices U1, V1, or Q1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgsna.html'>stdlib_stgsna</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues and/or eigenvectors of a matrix pair (A, B) in
generalized real Schur canonical form (or of any matrix pair
(Q<em>A</em>Z<strong>T, Q<em>B</em>Z</strong>T) with orthogonal matrices Q and Z, where
Z**T denotes the transpose of Z.
(A, B) must be in generalized real Schur form (as returned by SGGES),
i.e. A is block upper triangular with 1-by-1 and 2-by-2 diagonal
blocks. B is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgsy2.html'>stdlib_stgsy2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C                (1)
D * R - L * E = scale * F,
using Level 1 and 2 BLAS. where R and L are unknown M-by-N matrices,
(A, D), (B, E) and (C, F) are given matrix pairs of size M-by-M,
N-by-N and M-by-N, respectively, with real entries. (A, D) and (B, E)
must be in generalized Schur canonical form, i.e. A, B are upper
quasi triangular and D, E are upper triangular. The solution (R, L)
overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output scaling factor
chosen to avoid overflow.
In matrix notation solving equation (1) corresponds to solve
Z<em>x = scale</em>b, where Z is defined as
Z = [ kron(In, A)  -kron(B<strong>T, Im) ]             (2)
[ kron(In, D)  -kron(E</strong>T, Im) ],
Ik is the identity matrix of size k and X<strong>T is the transpose of X.
kron(X, Y) is the Kronecker product between the matrices X and Y.
In the process of solving (1), we solve a number of such systems
where Dim(In), Dim(In) = 1 or 2.
If TRANS = 'T', solve the transposed system Z</strong>T<em>y = scale</em>b for y,
which is equivalent to solve for R and L in
A<strong>T * R  + D</strong>T * L   = scale * C           (3)
R  * B<strong>T + L  * E</strong>T  = scale * -F
This case is used to compute an estimate of Dif[(A, D), (B, E)] =
sigma_min(Z) using reverse communication with SLACON.
STGSY2 also (IJOB &gt;= 1) contributes to the computation in STGSYL
of an upper bound on the separation between to matrix pairs. Then
the input (A, D), (B, E) are sub-pencils of the matrix pair in
STGSYL. See STGSYL for details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stgsyl.html'>stdlib_stgsyl</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C                 (1)
D * R - L * E = scale * F
where R and L are unknown m-by-n matrices, (A, D), (B, E) and
(C, F) are given matrix pairs of size m-by-m, n-by-n and m-by-n,
respectively, with real entries. (A, D) and (B, E) must be in
generalized (real) Schur canonical form, i.e. A, B are upper quasi
triangular and D, E are upper triangular.
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output
scaling factor chosen to avoid overflow.
In matrix notation (1) is equivalent to solve  Zx = scale b, where
Z is defined as
Z = [ kron(In, A)  -kron(B<strong>T, Im) ]         (2)
[ kron(In, D)  -kron(E</strong>T, Im) ].
Here Ik is the identity matrix of size k and X<strong>T is the transpose of
X. kron(X, Y) is the Kronecker product between the matrices X and Y.
If TRANS = 'T', STGSYL solves the transposed system Z</strong>T<em>y = scale</em>b,
which is equivalent to solve for R and L in
A<strong>T * R + D</strong>T * L = scale * C           (3)
R * B<strong>T + L * E</strong>T = scale * -F
This case (TRANS = 'T') is used to compute an one-norm-based estimate
of Dif[(A,D), (B,E)], the separation between the matrix pairs (A,D)
and (B,E), using SLACON.
If IJOB &gt;= 1, STGSYL computes a Frobenius norm-based estimate
of Dif[(A,D),(B,E)]. That is, the reciprocal of a lower bound on the
reciprocal of the smallest singular value of Z. See [1-2] for more
information.
This is a level 3 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpcon.html'>stdlib_stpcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stplqt.html'>stdlib_stplqt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stplqt2.html'>stdlib_stplqt2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpmlqt.html'>stdlib_stpmlqt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" real block reflector H to a general
real matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpmqrt.html'>stdlib_stpmqrt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" real block reflector H to a general
real matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpmv.html'>stdlib_stpmv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpqrt.html'>stdlib_stpqrt</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpqrt2.html'>stdlib_stpqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stprfb.html'>stdlib_stprfb</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>conjugate transpose H^H to a real matrix C, which is composed of two
blocks A and B, either from the left or right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stprfs.html'>stdlib_stprfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular packed
coefficient matrix.
The solution matrix X must be computed by STPTRS or some other
means before entering this routine.  STPRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpsv.html'>stdlib_stpsv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix, supplied in packed form.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stptri.html'>stdlib_stptri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A stored in packed format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stptrs.html'>stdlib_stptrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B,
where A is a triangular matrix of order N stored in packed format,
and B is an N-by-NRHS matrix.  A check is made to verify that A is
nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpttf.html'>stdlib_stpttf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stpttr.html'>stdlib_stpttr</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strcon.html'>stdlib_strcon</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strevc.html'>stdlib_strevc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real upper quasi-triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a real general matrix:  A = Q<em>T</em>Q<strong>T, as computed by SHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal blocks of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix.  If Q is the orthogonal factor that reduces a matrix
A to Schur form T, then Q<em>X and Q</em>Y are the matrices of right and
left eigenvectors of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strevc3.html'>stdlib_strevc3</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>a real upper quasi-triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a real general matrix:  A = Q<em>T</em>Q<strong>T, as computed by SHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>T)<em>T = w</em>(y<strong>T)
where y</strong>T denotes the transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal blocks of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix. If Q is the orthogonal factor that reduces a matrix
A to Schur form T, then Q<em>X and Q</em>Y are the matrices of right and
left eigenvectors of A.
This uses a Level 3 BLAS version of the back transformation.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strexc.html'>stdlib_strexc</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q<strong>T, so that the diagonal block of T with row index IFST is
moved to row ILST.
The real Schur form T is reordered by an orthogonal similarity
transformation Z</strong>T<em>T</em>Z, and optionally the matrix Q of Schur vectors
is updated by postmultiplying it with Z.
T must be in Schur canonical form (as returned by SHSEQR), that is,
block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each
2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strmm.html'>stdlib_strmm</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>B := alpha<em>op( A )</em>B,   or   B := alpha<em>B</em>op( A ),
where  alpha  is a scalar,  B  is an m by n matrix,  A  is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strmv.html'>stdlib_strmv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strrfs.html'>stdlib_strrfs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular
coefficient matrix.
The solution matrix X must be computed by STRTRS or some other
means before entering this routine.  STRRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strsen.html'>stdlib_strsen</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q**T, so that a selected cluster of eigenvalues appears in
the leading diagonal blocks of the upper quasi-triangular matrix T,
and the leading columns of Q form an orthonormal basis of the
corresponding right invariant subspace.
Optionally the routine computes the reciprocal condition numbers of
the cluster of eigenvalues and/or the invariant subspace.
T must be in Schur canonical form (as returned by SHSEQR), that is,
block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each
2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strsm.html'>stdlib_strsm</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>op( A )<em>X = alpha</em>B,   or   X<em>op( A ) = alpha</em>B,
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**T.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strsna.html'>stdlib_strsna</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>eigenvalues and/or right eigenvectors of a real upper
quasi-triangular matrix T (or of any matrix Q<em>T</em>Q**T with Q
orthogonal).
T must be in Schur canonical form (as returned by SHSEQR), that is,
block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each
2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strsv.html'>stdlib_strsv</a></td><td><a href='../module/stdlib_linalg_blas_s.html'>stdlib_linalg_blas_s</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strsyl.html'>stdlib_strsyl</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>op(A)<em>X + X</em>op(B) = scale<em>C or
op(A)</em>X - X<em>op(B) = scale</em>C,
where op(A) = A or A**T, and  A and B are both upper quasi-
triangular. A is M-by-M and B is N-by-N; the right hand side C and
the solution X are M-by-N; and scale is an output scale factor, set
&lt;= 1 to avoid overflow in X.
A and B must be in Schur canonical form (as returned by SHSEQR), that
is, block upper triangular with 1-by-1 and 2-by-2 diagonal blocks;
each 2-by-2 diagonal block has its diagonal elements equal and its
off-diagonal elements of opposite sign.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strti2.html'>stdlib_strti2</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix.
This is the Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strtri.html'>stdlib_strtri</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>matrix A.
This is the Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strtrs.html'>stdlib_strtrs</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>A * X = B  or  A**T * X = B,
where A is a triangular matrix of order N, and B is an N-by-NRHS
matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strttf.html'>stdlib_strttf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF) .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_strttp.html'>stdlib_strttp</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_stzrzf.html'>stdlib_stzrzf</a></td><td><a href='../module/stdlib_linalg_lapack_s.html'>stdlib_linalg_lapack_s</a></td><td>Subroutine</td><td><p>to upper triangular form by means of orthogonal transformations.
The upper trapezoidal matrix A is factored as
A = ( R  0 ) * Z,
where Z is an N-by-N orthogonal matrix and R is an M-by-M upper
triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_xerbla.html'>stdlib_xerbla</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Subroutine</td><td><p>It is called by an LAPACK routine if an input parameter has an
invalid value.  A message is printed and execution stops.
Installers may consider modifying the STOP statement in order to
call system-specific exception-handling facilities.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_xerbla_array.html'>stdlib_xerbla_array</a></td><td><a href='../module/stdlib_linalg_blas_aux.html'>stdlib_linalg_blas_aux</a></td><td>Subroutine</td><td><p>and BLAS error handler.  Rather than taking a Fortran string argument
as the function's name, XERBLA_ARRAY takes an array of single
characters along with the array's length.  XERBLA_ARRAY then copies
up to 32 characters of that array into a Fortran string and passes
that to XERBLA.  If called with a non-positive SRNAME_LEN,
XERBLA_ARRAY will call XERBLA with a string of all blank characters.
Say some macro or other device makes XERBLA_ARRAY available to C99
by a name lapack_xerbla and with a common Fortran calling convention.
Then a C99 program could invoke XERBLA via:
{
int flen = strlen(<strong>func</strong>);
lapack_xerbla(<strong>func</strong>,
}
Providing XERBLA_ARRAY is not necessary for intercepting LAPACK
errors.  XERBLA_ARRAY calls XERBLA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zaxpy.html'>stdlib_zaxpy</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zbbcsd.html'>stdlib_zbbcsd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>bidiagonal-block form,
[ B11 | B12 0  0 ]
[  0  |  0 -I  0 ]
X = [----------------]
[ B21 | B22 0  0 ]
[  0  |  0  0  I ]
[  C | -S  0  0 ]
[ U1 |    ] [  0 |  0 -I  0 ] [ V1 |    ]**H
= [---------] [---------------] [---------]   .
[    | U2 ] [  S |  C  0  0 ] [    | V2 ]
[  0 |  0  0  I ]
X is M-by-M, its top-left block is P-by-Q, and Q must be no larger
than P, M-P, or M-Q. (If Q is not the smallest index, then X must be
transposed and/or permuted. This can be done in constant time using
the TRANS and SIGNS options. See ZUNCSD for details.)
The bidiagonal matrices B11, B12, B21, and B22 are represented
implicitly by angles THETA(1:Q) and PHI(1:Q-1).
The unitary matrices U1, U2, V1T, and V2T are input/output.
The input matrices are pre- or post-multiplied by the appropriate
singular vector matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zbdsqr.html'>stdlib_zbdsqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>left singular vectors from the singular value decomposition (SVD) of
a real N-by-N (upper or lower) bidiagonal matrix B using the implicit
zero-shift QR algorithm.  The SVD of B has the form
B = Q * S * P<strong>H
where S is the diagonal matrix of singular values, Q is an orthogonal
matrix of left singular vectors, and P is an orthogonal matrix of
right singular vectors.  If left singular vectors are requested, this
subroutine actually returns U*Q instead of Q, and, if right singular
vectors are requested, this subroutine returns P</strong>H<em>VT instead of
P</em><em>H, for given complex input matrices U and VT.  When U and VT are
the unitary matrices that reduce a general matrix A to bidiagonal
form: A = U</em>B<em>VT, as computed by ZGEBRD, then
A = (U</em>Q) * S * (P<strong>H*VT)
is the SVD of A.  Optionally, the subroutine may also compute Q</strong>H*C
for a given complex input matrix C.
See "Computing  Small Singular Values of Bidiagonal Matrices With
Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan,
LAPACK Working Note #3 (or SIAM J. Sci. Statist. Comput. vol. 11,
no. 5, pp. 873-912, Sept 1990) and
"Accurate singular values and differential qd algorithms," by
B. Parlett and V. Fernando, Technical Report CPAM-554, Mathematics
Department, University of California at Berkeley, July 1992
for a detailed description of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zcgesv.html'>stdlib_zcgesv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
ZCGESV first attempts to factorize the matrix in COMPLEX and use this
factorization within an iterative refinement procedure to produce a
solution with COMPLEX<em>16 normwise backward error quality (see below).
If the approach fails the method switches to a COMPLEX</em>16
factorization and solve.
The iterative refinement is not going to be a winning strategy if
the ratio COMPLEX performance over COMPLEX<em>16 performance is too
small. A reasonable strategy should take the number of right-hand
sides and the size of the matrix into account. This might be done
with a call to ILAENV in the future. Up to now, we always try
iterative refinement.
The iterative refinement process is stopped if
ITER &gt; ITERMAX
or for all the RHS we have:
RNRM &lt; SQRT(N)</em>XNRM<em>ANRM</em>EPS*BWDMAX
where
o ITER is the number of the current iteration in the iterative
refinement process
o RNRM is the infinity-norm of the residual
o XNRM is the infinity-norm of the solution
o ANRM is the infinity-operator-norm of the matrix A
o EPS is the machine epsilon returned by DLAMCH('Epsilon')
The value ITERMAX and BWDMAX are fixed to 30 and 1.0D+00
respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zcopy.html'>stdlib_zcopy</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zcposv.html'>stdlib_zcposv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix and X and B
are N-by-NRHS matrices.
ZCPOSV first attempts to factorize the matrix in COMPLEX and use this
factorization within an iterative refinement procedure to produce a
solution with COMPLEX<em>16 normwise backward error quality (see below).
If the approach fails the method switches to a COMPLEX</em>16
factorization and solve.
The iterative refinement is not going to be a winning strategy if
the ratio COMPLEX performance over COMPLEX<em>16 performance is too
small. A reasonable strategy should take the number of right-hand
sides and the size of the matrix into account. This might be done
with a call to ILAENV in the future. Up to now, we always try
iterative refinement.
The iterative refinement process is stopped if
ITER &gt; ITERMAX
or for all the RHS we have:
RNRM &lt; SQRT(N)</em>XNRM<em>ANRM</em>EPS*BWDMAX
where
o ITER is the number of the current iteration in the iterative
refinement process
o RNRM is the infinity-norm of the residual
o XNRM is the infinity-norm of the solution
o ANRM is the infinity-operator-norm of the matrix A
o EPS is the machine epsilon returned by DLAMCH('Epsilon')
The value ITERMAX and BWDMAX are fixed to 30 and 1.0D+00
respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zdotc.html'>stdlib_zdotc</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Function</td><td><p>ZDOTC = X^H * Y</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zdotu.html'>stdlib_zdotu</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Function</td><td><p>ZDOTU = X^T * Y</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zdrot.html'>stdlib_zdrot</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>Applies a plane rotation, where the cos and sin (c and s) are real
and the vectors cx and cy are complex.
jack dongarra, linpack, 3/11/78.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zdrscl.html'>stdlib_zdrscl</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1/a.  This is done without overflow or underflow as long as
the final result x/a does not overflow or underflow.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zdscal.html'>stdlib_zdscal</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbbrd.html'>stdlib_zgbbrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>bidiagonal form B by a unitary transformation: Q<strong>H * A * P = B.
The routine computes B, and optionally forms Q or P</strong>H, or computes
Q*<em>H</em>C for a given matrix C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbcon.html'>stdlib_zgbcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>general band matrix A, in either the 1-norm or the infinity-norm,
using the LU factorization computed by ZGBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbequ.html'>stdlib_zgbequ</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N band matrix A and reduce its condition number.  R returns the
row scale factors and C the column scale factors, chosen to try to
make the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbequb.html'>stdlib_zgbequb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from ZGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbmv.html'>stdlib_zgbmv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<strong>T<em>x + beta</em>y,   or
y := alpha*A</strong>H<em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n band matrix, with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbrfs.html'>stdlib_zgbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is banded, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbsv.html'>stdlib_zgbsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B, where A is a band matrix of order N with KL subdiagonals
and KU superdiagonals, and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as A = L * U, where L is a product of permutation
and unit lower triangular matrices with KL subdiagonals, and U is
upper triangular with KL+KU superdiagonals.  The factored form of A
is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbsvx.html'>stdlib_zgbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B, A<strong>T * X = B, or A</strong>H * X = B,
where A is a band matrix of order N with KL subdiagonals and KU
superdiagonals, and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbtf2.html'>stdlib_zgbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A using partial pivoting with row interchanges.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbtrf.html'>stdlib_zgbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgbtrs.html'>stdlib_zgbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B
with a general band matrix A using the LU factorization computed
by ZGBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgebak.html'>stdlib_zgebak</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix by backward transformation on the computed eigenvectors of the
balanced matrix output by ZGEBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgebal.html'>stdlib_zgebal</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>permuting A by a similarity transformation to isolate eigenvalues
in the first 1 to ILO-1 and last IHI+1 to N elements on the
diagonal; and second, applying a diagonal similarity transformation
to rows and columns ILO to IHI to make the rows and columns as
close in norm as possible.  Both steps are optional.
Balancing may reduce the 1-norm of the matrix, and improve the
accuracy of the computed eigenvalues and/or eigenvectors.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgebd2.html'>stdlib_zgebd2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>real bidiagonal form B by a unitary transformation: Q**H * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgebrd.html'>stdlib_zgebrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>bidiagonal form B by a unitary transformation: Q**H * A * P = B.
If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgecon.html'>stdlib_zgecon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>complex matrix A, in either the 1-norm or the infinity-norm, using
the LU factorization computed by ZGETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeequ.html'>stdlib_zgeequ</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have absolute value 1.
R(i) and C(j) are restricted to be between SMLNUM = smallest safe
number and BIGNUM = largest safe number.  Use of these scaling
factors is not guaranteed to reduce the condition number of A but
works well in practice.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeequb.html'>stdlib_zgeequb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix A and reduce its condition number.  R returns the row
scale factors and C the column scale factors, chosen to try to make
the largest element in each row and column of the matrix B with
elements B(i,j)=R(i)<em>A(i,j)</em>C(j) have an absolute value of at most
the radix.
R(i) and C(j) are restricted to be a power of the radix between
SMLNUM = smallest safe number and BIGNUM = largest safe number.  Use
of these scaling factors is not guaranteed to reduce the condition
number of A but works well in practice.
This routine differs from ZGEEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled entries' magnitudes are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgees.html'>stdlib_zgees</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues, the Schur form T, and, optionally, the matrix of Schur
vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z**H).
Optionally, it also orders the eigenvalues on the diagonal of the
Schur form so that selected eigenvalues are at the top left.
The leading columns of Z then form an orthonormal basis for the
invariant subspace corresponding to the selected eigenvalues.
A complex matrix is in Schur form if it is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeesx.html'>stdlib_zgeesx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues, the Schur form T, and, optionally, the matrix of Schur
vectors Z.  This gives the Schur factorization A = Z<em>T</em>(Z**H).
Optionally, it also orders the eigenvalues on the diagonal of the
Schur form so that selected eigenvalues are at the top left;
computes a reciprocal condition number for the average of the
selected eigenvalues (RCONDE); and computes a reciprocal condition
number for the right invariant subspace corresponding to the
selected eigenvalues (RCONDV).  The leading columns of Z form an
orthonormal basis for this invariant subspace.
For further explanation of the reciprocal condition numbers RCONDE
and RCONDV, see Section 4.10_dp of the LAPACK Users' Guide (where
these quantities are called s and sep respectively).
A complex matrix is in Schur form if it is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeev.html'>stdlib_zgeev</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)**H denotes the conjugate transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeevx.html'>stdlib_zgeevx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues and, optionally, the left and/or right eigenvectors.
Optionally also, it computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
SCALE, and ABNRM), reciprocal condition numbers for the eigenvalues
(RCONDE), and reciprocal condition numbers for the right
eigenvectors (RCONDV).
The right eigenvector v(j) of A satisfies
A * v(j) = lambda(j) * v(j)
where lambda(j) is its eigenvalue.
The left eigenvector u(j) of A satisfies
u(j)<strong>H * A = lambda(j) * u(j)</strong>H
where u(j)<strong>H denotes the conjugate transpose of u(j).
The computed eigenvectors are normalized to have Euclidean norm
equal to 1 and largest component real.
Balancing a matrix means permuting the rows and columns to make it
more nearly upper triangular, and applying a diagonal similarity
transformation D * A * D</strong>(-1), where D is a diagonal matrix, to
make its rows and columns closer in norm and the condition numbers
of its eigenvalues and eigenvectors smaller.  The computed
reciprocal condition numbers correspond to the balanced matrix.
Permuting rows and columns will not change the condition numbers
(in exact arithmetic) but diagonal scaling will.  For further
explanation of balancing, see section 4.10.2_dp of the LAPACK
Users' Guide.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgehd2.html'>stdlib_zgehd2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>by a unitary similarity transformation:  Q**H * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgehrd.html'>stdlib_zgehrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>an unitary similarity transformation:  Q**H * A * Q = H .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgejsv.html'>stdlib_zgejsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix [A], where M &gt;= N. The SVD of [A] is written as
[A] = [U] * [SIGMA] * [V]^*,
where [SIGMA] is an N-by-N (M-by-N) matrix which is zero except for its N
diagonal elements, [U] is an M-by-N (or M-by-M) unitary matrix, and
[V] is an N-by-N unitary matrix. The diagonal elements of [SIGMA] are
the singular values of [A]. The columns of [U] and [V] are the left and
the right singular vectors of [A], respectively. The matrices [U] and [V]
are computed and stored in the arrays U and V, respectively. The diagonal
of [SIGMA] is computed and stored in the array SVA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelq.html'>stdlib_zgelq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelq2.html'>stdlib_zgelq2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a n-by-n orthogonal matrix;
L is a lower-triangular m-by-m matrix;
0 is a m-by-(n-m) zero matrix, if m &lt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelqf.html'>stdlib_zgelqf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = ( L 0 ) *  Q
where:
Q is a N-by-N orthogonal matrix;
L is a lower-triangular M-by-M matrix;
0 is a M-by-(N-M) zero matrix, if M &lt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelqt.html'>stdlib_zgelqt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelqt3.html'>stdlib_zgelqt3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgels.html'>stdlib_zgels</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, or its conjugate-transpose, using a QR
or LQ factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'C' and m &gt;= n:  find the minimum norm solution of
an underdetermined system A</em><em>H * X = B.
4. If TRANS = 'C' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*H * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelsd.html'>stdlib_zgelsd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>squares problem:
minimize 2-norm(| b - A*x |)
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The problem is solved in three steps:
(1) Reduce the coefficient matrix A to bidiagonal form with
Householder transformations, reducing the original problem
into a "bidiagonal least squares problem" (BLS)
(2) Solve the BLS using a divide and conquer approach.
(3) Apply back all the Householder transformations to solve
the original least squares problem.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelss.html'>stdlib_zgelss</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>least squares problem:
Minimize 2-norm(| b - A*x |).
using the singular value decomposition (SVD) of A. A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix
X.
The effective rank of A is determined by treating as zero those
singular values which are less than RCOND times the largest singular
value.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgelsy.html'>stdlib_zgelsy</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>squares problem:
minimize || A * X - B ||
using a complete orthogonal factorization of A.  A is an M-by-N
matrix which may be rank-deficient.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.
The routine first computes a QR factorization with column pivoting:
A * P = Q * [ R11 R12 ]
[  0  R22 ]
with R11 defined as the largest leading submatrix whose estimated
condition number is less than 1/RCOND.  The order of R11, RANK,
is the effective rank of A.
Then, R22 is considered to be negligible, and R12 is annihilated
by unitary transformations from the right, arriving at the
complete orthogonal factorization:
A * P = Q * [ T11 0 ] * Z
[  0  0 ]
The minimum-norm solution is then
X = P * Z<strong>H [ inv(T11)*Q1</strong>H*B ]
[        0         ]
where Q1 consists of the first RANK columns of Q.
This routine is basically identical to the original xGELSX except
three differences:
o The permutation of matrix B (the right hand side) is faster and
more simple.
o The call to the subroutine xGEQPF has been substituted by the
the call to the subroutine xGEQP3. This subroutine is a Blas-3
version of the QR factorization with column pivoting.
o Matrix B (the right hand side) is updated with Blas-3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgemlq.html'>stdlib_zgemlq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by short wide
LQ factorization (ZGELQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgemlqt.html'>stdlib_zgemlqt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'C':   Q<strong>H C            C Q</strong>H
where Q is a complex unitary matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**H
generated using the compact WY representation as returned by ZGELQT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgemm.html'>stdlib_zgemm</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>op( A )</em>op( B ) + beta<em>C,
where  op( X ) is one of
op( X ) = X   or   op( X ) = X</em><em>T   or   op( X ) = X</em>*H,
alpha and beta are scalars, and A, B and C are matrices, with op( A )
an m by k matrix,  op( B )  a  k by n matrix and  C an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgemqr.html'>stdlib_zgemqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'T':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (ZGEQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgemqrt.html'>stdlib_zgemqrt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q C            C Q
TRANS = 'C':    Q<strong>H C            C Q</strong>H
where Q is a complex orthogonal matrix defined as the product of K
elementary reflectors:
Q = H(1) H(2) . . . H(K) = I - V T V**H
generated using the compact WY representation as returned by ZGEQRT.
Q is of order M if SIDE = 'L' and of order N  if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgemv.html'>stdlib_zgemv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta<em>y,   or   y := alpha</em>A<strong>T<em>x + beta</em>y,   or
y := alpha*A</strong>H<em>x + beta</em>y,
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeql2.html'>stdlib_zgeql2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqlf.html'>stdlib_zgeqlf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q * L.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqp3.html'>stdlib_zgeqp3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A:  A<em>P = Q</em>R  using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqr.html'>stdlib_zgeqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqr2.html'>stdlib_zgeqr2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqr2p.html'>stdlib_zgeqr2p</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a m-by-m orthogonal matrix;
R is an upper-triangular n-by-n matrix with nonnegative diagonal
entries;
0 is a (m-n)-by-n zero matrix, if m &gt; n.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqrf.html'>stdlib_zgeqrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqrfp.html'>stdlib_zgeqrfp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZGEQR2P computes a QR factorization of a complex M-by-N matrix A:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix;
R is an upper-triangular N-by-N matrix with nonnegative diagonal
entries;
0 is a (M-N)-by-N zero matrix, if M &gt; N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqrt.html'>stdlib_zgeqrt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqrt2.html'>stdlib_zgeqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the compact WY representation of Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeqrt3.html'>stdlib_zgeqrt3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A, using the compact WY representation of Q.
Based on the algorithm of Elmroth and Gustavson,
IBM J. Res. Develop. Vol 44 No. 4 July 2000.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgerc.html'>stdlib_zgerc</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y**H + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgerfs.html'>stdlib_zgerfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations and provides error bounds and backward error estimates for
the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgerq2.html'>stdlib_zgerq2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgerqf.html'>stdlib_zgerqf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = R * Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgeru.html'>stdlib_zgeru</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y**T + A,
where alpha is a scalar, x is an m element vector, y is an n element
vector and A is an m by n matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesc2.html'>stdlib_zgesc2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = scale* RHS
with a general N-by-N matrix A using the LU factorization with
complete pivoting computed by ZGETC2.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesdd.html'>stdlib_zgesdd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors, by using divide-and-conquer method. The SVD is written
A = U * SIGMA * conjugate-transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M unitary matrix, and
V is an N-by-N unitary matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns VT = V**H, not V.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesv.html'>stdlib_zgesv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
The LU decomposition with partial pivoting and row interchanges is
used to factor A as
A = P * L * U,
where P is a permutation matrix, L is unit lower triangular, and U is
upper triangular.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesvd.html'>stdlib_zgesvd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix A, optionally computing the left and/or right singular
vectors. The SVD is written
A = U * SIGMA * conjugate-transpose(V)
where SIGMA is an M-by-N matrix which is zero except for its
min(m,n) diagonal elements, U is an M-by-M unitary matrix, and
V is an N-by-N unitary matrix.  The diagonal elements of SIGMA
are the singular values of A; they are real and non-negative, and
are returned in descending order.  The first min(m,n) columns of
U and V are the left and right singular vectors of A.
Note that the routine returns V**H, not V.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesvdq.html'>stdlib_zgesvdq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZCGESVDQ computes the singular value decomposition (SVD) of a complex
M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N unitary matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesvj.html'>stdlib_zgesvj</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix A, where M &gt;= N. The SVD of A is written as
[++]   [xx]   [x0]   [xx]
A = U * SIGMA * V^*,  [++] = [xx] * [ox] * [xx]
[++]   [xx]
where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal
matrix, and V is an N-by-N unitary matrix. The diagonal elements
of SIGMA are the singular values of A. The columns of U and V are the
left and the right singular vectors of A, respectively.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgesvx.html'>stdlib_zgesvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>system of linear equations
A * X = B,
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetc2.html'>stdlib_zgetc2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>n-by-n matrix A. The factorization has the form A = P * L * U * Q,
where P and Q are permutation matrices, L is lower triangular with
unit diagonal elements and U is upper triangular.
This is a level 1 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetf2.html'>stdlib_zgetf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetrf.html'>stdlib_zgetrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the right-looking Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetrf2.html'>stdlib_zgetrf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using partial pivoting with row interchanges.
The factorization has the form
A = P * L * U
where P is a permutation matrix, L is lower triangular with unit
diagonal elements (lower trapezoidal if m &gt; n), and U is upper
triangular (upper trapezoidal if m &lt; n).
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = min(m,n)/2
[  A21 | A22  ]       n2 = n-n1
[ A11 ]
The subroutine calls itself to factor [ --- ],
[ A12 ]
[ A12 ]
do the swaps on [ --- ], solve A12, update A22,
[ A22 ]
then calls itself to factor A22 and do the swaps on A21.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetri.html'>stdlib_zgetri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>computed by ZGETRF.
This method inverts U and then computes inv(A) by solving the system
inv(A)*L = inv(U) for inv(A).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetrs.html'>stdlib_zgetrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B
with a general N-by-N matrix A using the LU factorization computed
by ZGETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetsls.html'>stdlib_zgetsls</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>involving an M-by-N matrix A, using a tall skinny QR or short wide LQ
factorization of A.  It is assumed that A has full rank.
The following options are provided:
1. If TRANS = 'N' and m &gt;= n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A<em>X ||.
2. If TRANS = 'N' and m &lt; n:  find the minimum norm solution of
an underdetermined system A * X = B.
3. If TRANS = 'C' and m &gt;= n:  find the minimum norm solution of
an undetermined system A</em><em>T * X = B.
4. If TRANS = 'C' and m &lt; n:  find the least squares solution of
an overdetermined system, i.e., solve the least squares problem
minimize || B - A</em>*T * X ||.
Several right hand side vectors b and solution vectors x can be
handled in a single call; they are stored as the columns of the
M-by-NRHS right hand side matrix B and the N-by-NRHS solution
matrix X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgetsqrhrt.html'>stdlib_zgetsqrhrt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex M-by-N matrix A with M &gt;= N,
A = Q * R.
The routine uses internally a NB1-sized column blocked and MB1-sized
row blocked TSQR-factorization and perfors the reconstruction
of the Householder vectors from the TSQR output. The routine also
converts the R_tsqr factor from the TSQR-factorization output into
the R factor that corresponds to the Householder QR-factorization,
A = Q_tsqr * R_tsqr = Q * R.
The output Q and R factors are stored in the same format as in ZGEQRT
(Q is in blocked compact WY-representation). See the documentation
of ZGEQRT for more details on the format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggbak.html'>stdlib_zggbak</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalue problem A<em>x = lambda</em>B*x, by backward transformation on
the computed eigenvectors of the balanced pair of matrices output by
ZGGBAL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggbal.html'>stdlib_zggbal</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>involves, first, permuting A and B by similarity transformations to
isolate eigenvalues in the first 1 to ILO$-$1 and last IHI+1 to N
elements on the diagonal; and second, applying a diagonal similarity
transformation to rows and columns ILO to IHI to make the rows
and columns as close in norm as possible. Both steps are optional.
Balancing may reduce the 1-norm of the matrices, and improve the
accuracy of the computed eigenvalues and/or eigenvectors in the
generalized eigenvalue problem A<em>x = lambda</em>B*x.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgges.html'>stdlib_zgges</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the generalized complex Schur
form (S, T), and optionally left and/or right Schur vectors (VSL
and VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>H, (VSL)<em>T</em>(VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T. The leading
columns of VSL and VSR then form an unitary basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
ZGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0, and even for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if S
and T are upper triangular and, in addition, the diagonal elements
of T are non-negative real numbers.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgges3.html'>stdlib_zgges3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the generalized complex Schur
form (S, T), and optionally left and/or right Schur vectors (VSL
and VSR). This gives the generalized Schur factorization
(A,B) = ( (VSL)<em>S</em>(VSR)<strong>H, (VSL)<em>T</em>(VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T. The leading
columns of VSL and VSR then form an unitary basis for the
corresponding left and right eigenspaces (deflating subspaces).
(If only the generalized eigenvalues are needed, use the driver
ZGGEV instead, which is faster.)
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0, and even for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if S
and T are upper triangular and, in addition, the diagonal elements
of T are non-negative real numbers.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggesx.html'>stdlib_zggesx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, the complex Schur form (S,T),
and, optionally, the left and/or right matrices of Schur vectors (VSL
and VSR).  This gives the generalized Schur factorization
(A,B) = ( (VSL) S (VSR)<strong>H, (VSL) T (VSR)</strong>H )
where (VSR)*<em>H is the conjugate-transpose of VSR.
Optionally, it also orders the eigenvalues so that a selected cluster
of eigenvalues appears in the leading diagonal blocks of the upper
triangular matrix S and the upper triangular matrix T; computes
a reciprocal condition number for the average of the selected
eigenvalues (RCONDE); and computes a reciprocal condition number for
the right and left deflating subspaces corresponding to the selected
eigenvalues (RCONDV). The leading columns of VSL and VSR then form
an orthonormal basis for the corresponding left and right eigenspaces
(deflating subspaces).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar w
or a ratio alpha/beta = w, such that  A - w</em>B is singular.  It is
usually represented as the pair (alpha,beta), as there is a
reasonable interpretation for beta=0 or for both being zero.
A pair of matrices (S,T) is in generalized complex Schur form if T is
upper triangular with non-negative diagonal and S is upper
triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggev.html'>stdlib_zggev</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right generalized eigenvector v(j) corresponding to the
generalized eigenvalue lambda(j) of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left generalized eigenvector u(j) corresponding to the
generalized eigenvalues lambda(j) of (A,B) satisfies
u(j)</em><em>H * A = lambda(j) * u(j)</em><em>H * B
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggev3.html'>stdlib_zggev3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(A,B), the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right generalized eigenvector v(j) corresponding to the
generalized eigenvalue lambda(j) of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j).
The left generalized eigenvector u(j) corresponding to the
generalized eigenvalues lambda(j) of (A,B) satisfies
u(j)</em><em>H * A = lambda(j) * u(j)</em><em>H * B
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggevx.html'>stdlib_zggevx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(A,B) the generalized eigenvalues, and optionally, the left and/or
right generalized eigenvectors.
Optionally, it also computes a balancing transformation to improve
the conditioning of the eigenvalues and eigenvectors (ILO, IHI,
LSCALE, RSCALE, ABNRM, and BBNRM), reciprocal condition numbers for
the eigenvalues (RCONDE), and reciprocal condition numbers for the
right eigenvectors (RCONDV).
A generalized eigenvalue for a pair of matrices (A,B) is a scalar
lambda or a ratio alpha/beta = lambda, such that A - lambda<em>B is
singular. It is usually represented as the pair (alpha,beta), as
there is a reasonable interpretation for beta=0, and even for both
being zero.
The right eigenvector v(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
A * v(j) = lambda(j) * B * v(j) .
The left eigenvector u(j) corresponding to the eigenvalue lambda(j)
of (A,B) satisfies
u(j)</em><em>H * A  = lambda(j) * u(j)</em><em>H * B.
where u(j)</em>*H is the conjugate-transpose of u(j).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggglm.html'>stdlib_zggglm</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>minimize || y ||_2   subject to   d = A<em>x + B</em>y
x
where A is an N-by-M matrix, B is an N-by-P matrix, and d is a
given N-vector. It is assumed that M &lt;= N &lt;= M+P, and
rank(A) = M    and    rank( A B ) = N.
Under these assumptions, the constrained equation is always
consistent, and there is a unique solution x and a minimal 2-norm
solution y, which is obtained using a generalized QR factorization
of the matrices (A, B) given by
A = Q<em>(R),   B = Q</em>T<em>Z.
(0)
In particular, if matrix B is square nonsingular, then the problem
GLM is equivalent to the following weighted linear least squares
problem
minimize || inv(B)</em>(d-A*x) ||_2
x
where inv(B) denotes the inverse of B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgghd3.html'>stdlib_zgghd3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hessenberg form using unitary transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the unitary matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>H</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>H</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>H*x.
The unitary matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>H = (Q1<em>Q) * H * (Z1</em>Z)<strong>H
Q1 * B * Z1</strong>H = (Q1<em>Q) * T * (Z1</em>Z)<em><em>H
If Q1 is the unitary matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then ZGGHD3 reduces the original
problem to generalized Hessenberg form.
This is a blocked variant of CGGHRD, using matrix-matrix
multiplications for parts of the computation to enhance performance.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgghrd.html'>stdlib_zgghrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hessenberg form using unitary transformations, where A is a
general matrix and B is upper triangular.  The form of the
generalized eigenvalue problem is
A<em>x = lambda</em>B<em>x,
and B is typically made upper triangular by computing its QR
factorization and moving the unitary matrix Q to the left side
of the equation.
This subroutine simultaneously reduces A to a Hessenberg matrix H:
Q</em><em>H</em>A<em>Z = H
and transforms B to another upper triangular matrix T:
Q</em><em>H</em>B<em>Z = T
in order to reduce the problem to its standard form
H</em>y = lambda<em>T</em>y
where y = Z<strong>H*x.
The unitary matrices Q and Z are determined as products of Givens
rotations.  They may either be formed explicitly, or they may be
postmultiplied into input matrices Q1 and Z1, so that
Q1 * A * Z1</strong>H = (Q1<em>Q) * H * (Z1</em>Z)<strong>H
Q1 * B * Z1</strong>H = (Q1<em>Q) * T * (Z1</em>Z)<em><em>H
If Q1 is the unitary matrix from the QR factorization of B in the
original equation A</em>x = lambda</em>B*x, then ZGGHRD reduces the original
problem to generalized Hessenberg form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgglse.html'>stdlib_zgglse</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>minimize || c - A<em>x ||_2   subject to   B</em>x = d
where A is an M-by-N matrix, B is a P-by-N matrix, c is a given
M-vector, and d is a given P-vector. It is assumed that
P &lt;= N &lt;= M+P, and
rank(B) = P and  rank( (A) ) = N.
( (B) )
These conditions ensure that the LSE problem has a unique solution,
which is obtained using a generalized RQ factorization of the
matrices (B, A) given by
B = (0 R)<em>Q,   A = Z</em>T*Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggqrf.html'>stdlib_zggqrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>and an N-by-P matrix B:
A = Q<em>R,        B = Q</em>T<em>Z,
where Q is an N-by-N unitary matrix, Z is a P-by-P unitary matrix,
and R and T assume one of the forms:
if N &gt;= M,  R = ( R11 ) M  ,   or if N &lt; M,  R = ( R11  R12 ) N,
(  0  ) N-M                         N   M-N
M
where R11 is upper triangular, and
if N &lt;= P,  T = ( 0  T12 ) N,   or if N &gt; P,  T = ( T11 ) N-P,
P-N  N                           ( T21 ) P
P
where T12 or T21 is upper triangular.
In particular, if B is square and nonsingular, the GQR factorization
of A and B implicitly gives the QR factorization of inv(B)</em>A:
inv(B)<em>A = Z</em><em>H * (inv(T)</em>R)
where inv(B) denotes the inverse of the matrix B, and Z**H denotes the
conjugate transpose of matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zggrqf.html'>stdlib_zggrqf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>and a P-by-N matrix B:
A = R<em>Q,        B = Z</em>T<em>Q,
where Q is an N-by-N unitary matrix, Z is a P-by-P unitary
matrix, and R and T assume one of the forms:
if M &lt;= N,  R = ( 0  R12 ) M,   or if M &gt; N,  R = ( R11 ) M-N,
N-M  M                           ( R21 ) N
N
where R12 or R21 is upper triangular, and
if P &gt;= N,  T = ( T11 ) N  ,   or if P &lt; N,  T = ( T11  T12 ) P,
(  0  ) P-N                         P   N-P
N
where T11 is upper triangular.
In particular, if B is square and nonsingular, the GRQ factorization
of A and B implicitly gives the RQ factorization of A</em>inv(B):
A<em>inv(B) = (R</em>inv(T))<em>Z</em><em>H
where inv(B) denotes the inverse of the matrix B, and Z</em>*H denotes the
conjugate transpose of the matrix Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgsvj0.html'>stdlib_zgsvj0</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as ZGESVJ does, but
it does not check convergence (stopping criterion). Few tuning
parameters (marked by [TP]) are available for the implementer.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgsvj1.html'>stdlib_zgsvj1</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>purpose. It applies Jacobi rotations in the same way as ZGESVJ does, but
it targets only particular pivots and it does not check convergence
(stopping criterion). Few tuning parameters (marked by [TP]) are
available for the implementer.
Further Details
~~~~~~~~~~~~~~~
ZGSVJ1 applies few sweeps of Jacobi rotations in the column space of
the input M-by-N matrix A. The pivot pairs are taken from the (1,2)
off-diagonal block in the corresponding N-by-N Gram matrix A^T * A. The
block-entries (tiles) of the (1,2) off-diagonal block are marked by the
[x]'s in the following scheme:
| *  *  * [x] [x] [x]|
| *  *  * [x] [x] [x]|    Row-cycling in the nblr-by-nblc [x] blocks.
| *  *  * [x] [x] [x]|    Row-cyclic pivoting inside each [x] block.
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
|[x] [x] [x] *  *  * |
In terms of the columns of A, the first N1 columns are rotated 'against'
the remaining N-N1 columns, trying to increase the angle between the
corresponding subspaces. The off-diagonal block is N1-by(N-N1) and it is
tiled using quadratic tiles of side KBL. Here, KBL is a tuning parameter.
The number of sweeps is given in NSWEEP and the orthogonality threshold
is given in TOL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgtcon.html'>stdlib_zgtcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>tridiagonal matrix A using the LU factorization as computed by
ZGTTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgtrfs.html'>stdlib_zgtrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is tridiagonal, and provides
error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgtsv.html'>stdlib_zgtsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A<em>X = B,
where A is an N-by-N tridiagonal matrix, by Gaussian elimination with
partial pivoting.
Note that the equation  A</em><em>T </em>X = B  may be solved by interchanging the
order of the arguments DU and DL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgtsvx.html'>stdlib_zgtsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>system of linear equations A * X = B, A<strong>T * X = B, or A</strong>H * X = B,
where A is a tridiagonal matrix of order N and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgttrf.html'>stdlib_zgttrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using elimination with partial pivoting and row interchanges.
The factorization has the form
A = L * U
where L is a product of permutation and unit lower bidiagonal
matrices and U is upper triangular with nonzeros in only the main
diagonal and first two superdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgttrs.html'>stdlib_zgttrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
with a tridiagonal matrix A using the LU factorization computed
by ZGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zgtts2.html'>stdlib_zgtts2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
with a tridiagonal matrix A using the LU factorization computed
by ZGTTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhb2st_kernels.html'>stdlib_zhb2st_kernels</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>subroutine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbev.html'>stdlib_zhbev</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex Hermitian band matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbevd.html'>stdlib_zhbevd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex Hermitian band matrix A.  If eigenvectors are desired, it
uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbevx.html'>stdlib_zhbevx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex Hermitian band matrix A.  Eigenvalues and eigenvectors
can be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbgst.html'>stdlib_zhbgst</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenproblem  A<em>x = lambda</em>B<em>x  to standard form  C</em>y = lambda<em>y,
such that C has the same bandwidth as A.
B must have been previously factorized as S</em><em>H</em>S by ZPBSTF, using a
split Cholesky factorization. A is overwritten by C = X<strong>H<em>A</em>X, where
X = S</strong>(-1)*Q and Q is a unitary matrix chosen to preserve the
bandwidth of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbgv.html'>stdlib_zhbgv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbgvd.html'>stdlib_zhbgvd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbgvx.html'>stdlib_zhbgvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite banded eigenproblem, of
the form A<em>x=(lambda)</em>B*x. Here A and B are assumed to be Hermitian
and banded, and B is also positive definite.  Eigenvalues and
eigenvectors can be selected by specifying either all eigenvalues,
a range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbmv.html'>stdlib_zhbmv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian band matrix, with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhbtrd.html'>stdlib_zhbtrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhecon.html'>stdlib_zhecon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by ZHETRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhecon_rook.html'>stdlib_zhecon_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by CHETRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zheequb.html'>stdlib_zheequb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zheev.html'>stdlib_zheev</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>complex Hermitian matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zheevd.html'>stdlib_zheevd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>complex Hermitian matrix A.  If eigenvectors are desired, it uses a
divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zheevr.html'>stdlib_zheevr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex Hermitian matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.
ZHEEVR first reduces the matrix A to tridiagonal form T with a call
to ZHETRD.  Then, whenever possible, ZHEEVR calls ZSTEMR to compute
eigenspectrum using Relatively Robust Representations.  ZSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see ZSTEMR's documentation and:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Note 1 : ZHEEVR calls ZSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
ZHEEVR calls DSTEBZ and ZSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of ZSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zheevx.html'>stdlib_zheevx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex Hermitian matrix A.  Eigenvalues and eigenvectors can
be selected by specifying either a range of values or a range of
indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhegs2.html'>stdlib_zhegs2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenproblem to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H </em>A<em>L.
B must have been previously factorized as U</em><em>H </em>U or L<em>L</em>*H by ZPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhegst.html'>stdlib_zhegst</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenproblem to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H</em>A<em>L.
B must have been previously factorized as U</em><em>H</em>U or L<em>L</em>*H by ZPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhegv.html'>stdlib_zhegv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be Hermitian and B is also
positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhegvd.html'>stdlib_zhegvd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian and B is also positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhegvx.html'>stdlib_zhegvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian and B is also positive definite.
Eigenvalues and eigenvectors can be selected by specifying either a
range of values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhemm.html'>stdlib_zhemm</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where alpha and beta are scalars, A is an hermitian matrix and  B and
C are m by n matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhemv.html'>stdlib_zhemv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zher.html'>stdlib_zher</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zher2.html'>stdlib_zher2</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>H + conjg( alpha )<em>y</em>x</strong>H + A,
where alpha is a scalar, x and y are n element vectors and A is an n
by n hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zher2k.html'>stdlib_zher2k</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B<strong>H + conjg( alpha )<em>B</em>A</strong>H + beta<em>C,
or
C := alpha</em>A<strong>H<em>B + conjg( alpha )</em>B</strong>H<em>A + beta</em>C,
where  alpha and beta  are scalars with  beta  real,  C is an  n by n
hermitian matrix and  A and B  are  n by k matrices in the first case
and  k by n  matrices in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zherfs.html'>stdlib_zherfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zherk.html'>stdlib_zherk</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>A<strong>H + beta<em>C,
or
C := alpha</em>A</strong>H<em>A + beta</em>C,
where  alpha and beta  are  real scalars,  C is an  n by n  hermitian
matrix and  A  is an  n by k  matrix in the  first case and a  k by n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhesv.html'>stdlib_zhesv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>H,  if UPLO = 'U', or
A = L * D * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhesv_aa.html'>stdlib_zhesv_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>H * T * U,  if UPLO = 'U', or
A = L * T * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is Hermitian and tridiagonal. The factored form
of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhesv_rk.html'>stdlib_zhesv_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations A * X = B, where A is an N-by-N Hermitian matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
ZHETRF_RK is called to compute the factorization of a complex
Hermitian matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine ZHETRS_3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhesv_rook.html'>stdlib_zhesv_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
The bounded Bunch-Kaufman ("rook") diagonal pivoting method is used
to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
ZHETRF_ROOK is called to compute the factorization of a complex
Hermition matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling ZHETRS_ROOK (uses BLAS 2).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhesvx.html'>stdlib_zhesvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>solution to a complex system of linear equations A * X = B,
where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zheswapr.html'>stdlib_zheswapr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a hermitian matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetd2.html'>stdlib_zhetd2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetf2.html'>stdlib_zhetf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**H is the conjugate transpose of U, and D is
Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetf2_rk.html'>stdlib_zhetf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetf2_rook.html'>stdlib_zhetf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**H is the conjugate transpose of U, and D is
Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrd.html'>stdlib_zhetrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrd_hb2st.html'>stdlib_zhetrd_hb2st</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>tridiagonal form T by a unitary similarity transformation:
Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrd_he2hb.html'>stdlib_zhetrd_he2hb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>band-diagonal form AB by a unitary similarity transformation:
Q**H * A * Q = AB.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrf.html'>stdlib_zhetrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrf_aa.html'>stdlib_zhetrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>H<em>T</em>U  or  A = L<em>T</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a hermitian tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrf_rk.html'>stdlib_zhetrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrf_rook.html'>stdlib_zhetrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetri.html'>stdlib_zhetri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by
ZHETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetri_rook.html'>stdlib_zhetri_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by
ZHETRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrs.html'>stdlib_zhetrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by ZHETRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrs2.html'>stdlib_zhetrs2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by ZHETRF and converted by ZSYCONV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrs_3.html'>stdlib_zhetrs_3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization computed
by ZHETRF_RK or ZHETRF_BK:
A = P<em>U</em>D<em>(U</em><em>H)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>H)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>H (or L</em><em>H) is the conjugate of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is Hermitian and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrs_aa.html'>stdlib_zhetrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>hermitian matrix A using the factorization A = U<strong>H<em>T</em>U or
A = L<em>T</em>L</strong>H computed by ZHETRF_AA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhetrs_rook.html'>stdlib_zhetrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by ZHETRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhfrk.html'>stdlib_zhfrk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for C in RFP Format.
ZHFRK: performs one of the Hermitian rank--k operations
C := alpha<em>A</em>A<strong>H + beta<em>C,
or
C := alpha</em>A</strong>H<em>A + beta</em>C,
where alpha and beta are real scalars, C is an n--by--n Hermitian
matrix and A is an n--by--k matrix in the first case and a k--by--n
matrix in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhgeqz.html'>stdlib_zhgeqz</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the single-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a complex matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>H,  B = Q1<em>T</em>Z1</strong>H,
as computed by ZGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>H,  T = Q<em>P</em>Z</strong>H,
where Q and Z are unitary matrices and S and P are upper triangular.
Optionally, the unitary matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
unitary matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the unitary matrices from ZGGHRD that reduced
the matrix pair (A,B) to generalized Hessenberg form, then the output
matrices Q1<em>Q and Z1</em>Z are the unitary factors from the generalized
Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>H,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>H.
To avoid overflow, eigenvalues of the matrix pair (H,T)
(equivalently, of (A,B)) are computed as a pair of complex values
(alpha,beta).  If beta is nonzero, lambda = alpha / beta is an
eigenvalue of the generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
The values of alpha and beta for the i-th eigenvalue can be read
directly from the generalized Schur form:  alpha = S(i,i),
beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpcon.html'>stdlib_zhpcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian packed matrix A using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by ZHPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpev.html'>stdlib_zhpev</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>complex Hermitian matrix in packed storage.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpevd.html'>stdlib_zhpevd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex Hermitian matrix A in packed storage.  If eigenvectors are
desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpevx.html'>stdlib_zhpevx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex Hermitian matrix A in packed storage.
Eigenvalues/vectors can be selected by specifying either a range of
values or a range of indices for the desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpgst.html'>stdlib_zhpgst</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenproblem to standard form, using packed storage.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>H)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>H)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>H or L</em><em>H</em>A<em>L.
B must have been previously factorized as U</em><em>H</em>U or L<em>L</em>*H by ZPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpgv.html'>stdlib_zhpgv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be Hermitian, stored in packed format,
and B is also positive definite.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpgvd.html'>stdlib_zhpgvd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian, stored in packed format, and B is also
positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpgvx.html'>stdlib_zhpgvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex generalized Hermitian-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be Hermitian, stored in packed format, and B is also
positive definite.  Eigenvalues and eigenvectors can be selected by
specifying either a range of values or a range of indices for the
desired eigenvalues.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpmv.html'>stdlib_zhpmv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpr.html'>stdlib_zhpr</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpr2.html'>stdlib_zhpr2</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>y<strong>H + conjg( alpha )<em>y</em>x</strong>H + A,
where alpha is a scalar, x and y are n element vectors and A is an
n by n hermitian matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhprfs.html'>stdlib_zhprfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpsv.html'>stdlib_zhpsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>H,  if UPLO = 'U', or
A = L * D * L</strong>H,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is Hermitian and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhpsvx.html'>stdlib_zhpsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = L<em>D</em>L**H to compute the solution to a complex system of linear
equations A * X = B, where A is an N-by-N Hermitian matrix stored
in packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhptrd.html'>stdlib_zhptrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>real symmetric tridiagonal form T by a unitary similarity
transformation: Q**H * A * Q = T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhptrf.html'>stdlib_zhptrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>H  or  A = L<em>D</em>L</strong>H
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is Hermitian and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhptri.html'>stdlib_zhptri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>H or
A = L<em>D</em>L</strong>H computed by ZHPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhptrs.html'>stdlib_zhptrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>H or A = L<em>D</em>L</strong>H computed by ZHPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhsein.html'>stdlib_zhsein</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvectors of a complex upper Hessenberg matrix H.
The right eigenvector x and the left eigenvector y of the matrix H
corresponding to an eigenvalue w are defined by:
H * x = w * x,     y<strong>h * H = w * y</strong>h
where y**h denotes the conjugate transpose of the vector y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zhseqr.html'>stdlib_zhseqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>T</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_gbamv.html'>stdlib_zla_gbamv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_gbrcond_c.html'>stdlib_zla_gbrcond_c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a DOUBLE PRECISION vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_gbrpvgrw.html'>stdlib_zla_gbrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_geamv.html'>stdlib_zla_geamv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta<em>abs(y),
or   y := alpha</em>abs(A)<em><em>T</em>abs(x) + beta</em>abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
m by n matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_gercond_c.html'>stdlib_zla_gercond_c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a DOUBLE PRECISION vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_gerpvgrw.html'>stdlib_zla_gerpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_heamv.html'>stdlib_zla_heamv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZLA_SYAMV  performs the matrix-vector operation
y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_hercond_c.html'>stdlib_zla_hercond_c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a DOUBLE PRECISION vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_herpvgrw.html'>stdlib_zla_herpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_lin_berr.html'>stdlib_zla_lin_berr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>the formula
max(i) ( abs(R(i)) / ( abs(op(A_s))*abs(Y) + abs(B_s) )(i) )
where abs(Z) is the componentwise absolute value of the matrix
or vector Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_porcond_c.html'>stdlib_zla_porcond_c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a DOUBLE PRECISION vector</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_porpvgrw.html'>stdlib_zla_porpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_syamv.html'>stdlib_zla_syamv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>y := alpha<em>abs(A)</em>abs(x) + beta*abs(y),
where alpha and beta are scalars, x and y are vectors and A is an
n by n symmetric matrix.
This function is primarily used in calculating error bounds.
To protect against underflow during evaluation, components in
the resulting vector are perturbed away from zero by (N+1)
times the underflow threshold.  To prevent unnecessarily large
errors for block-structure embedded in general matrices,
"symbolically" zero components are not perturbed.  A zero
entry is considered "symbolic" if all multiplications involved
in computing that entry have at least one zero multiplicand.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_syrcond_c.html'>stdlib_zla_syrcond_c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>op(A) * inv(diag(C)) where C is a DOUBLE PRECISION vector.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_syrpvgrw.html'>stdlib_zla_syrpvgrw</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>norm(A)/norm(U). The "max absolute element" norm is used. If this is
much less than 1, the stability of the LU factorization of the
(equilibrated) matrix A could be poor. This also means that the
solution X, estimated condition numbers, and error bounds could be
unreliable.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zla_wwaddw.html'>stdlib_zla_wwaddw</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>This works for all extant IBM's hex and binary floating point
arithmetic, but not for decimal.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlabrd.html'>stdlib_zlabrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>m by n matrix A to upper or lower real bidiagonal form by a unitary
transformation Q**H * A * P, and returns the matrices X and Y which
are needed to apply the transformation to the unreduced part of A.
If m &gt;= n, A is reduced to upper bidiagonal form; if m &lt; n, to lower
bidiagonal form.
This is an auxiliary routine called by ZGEBRD</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacgv.html'>stdlib_zlacgv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacn2.html'>stdlib_zlacn2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacon.html'>stdlib_zlacon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Reverse communication is used for evaluating matrix-vector products.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacp2.html'>stdlib_zlacp2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>complex matrix B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacpy.html'>stdlib_zlacpy</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacrm.html'>stdlib_zlacrm</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>C := A * B,
where A is M by N and complex; B is N by N and real;
C is M by N and complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlacrt.html'>stdlib_zlacrt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>(  c  s )( x )  ==&gt; ( x )
( -s  c )( y )      ( y )
where c and s are complex and the vectors x and y are complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zladiv.html'>stdlib_zladiv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>will not overflow on an intermediary step unless the results
overflows.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaed0.html'>stdlib_zlaed0</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Using the divide and conquer method, ZLAED0: computes all eigenvalues
of a symmetric tridiagonal matrix which is one diagonal block of
those from reducing a dense or band Hermitian matrix and
corresponding eigenvectors of the dense or band matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaed7.html'>stdlib_zlaed7</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix after modification by a rank-one symmetric matrix. This
routine is used only for the eigenproblem which requires all
eigenvalues and optionally eigenvectors of a dense or banded
Hermitian matrix that has been reduced to tridiagonal form.
T = Q(in) ( D(in) + RHO * Z<em>Z</em><em>H ) Q</em><em>H(in) = Q(out) * D(out) * Q</em><em>H(out)
where Z = Q</em>*Hu, u is a vector of length N with ones in the
CUTPNT and CUTPNT + 1 th elements and zeros elsewhere.
The eigenvectors of the original matrix are stored in Q, and the
eigenvalues are in D.  The algorithm consists of three stages:
The first stage consists of deflating the size of the problem
when there are multiple eigenvalues or if there is a zero in
the Z vector.  For each such occurrence the dimension of the
secular equation problem is reduced by one.  This stage is
performed by the routine DLAED2.
The second stage consists of calculating the updated
eigenvalues. This is done by finding the roots of the secular
equation via the routine DLAED4 (as called by SLAED3).
This routine also calculates the eigenvectors of the current
problem.
The final stage consists of computing the updated eigenvectors
directly using the updated eigenvalues.  The eigenvectors for
the current problem are multiplied with the eigenvectors from
the overall problem.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaed8.html'>stdlib_zlaed8</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>sorted set.  Then it tries to deflate the size of the problem.
There are two ways in which deflation can occur:  when two or more
eigenvalues are close together or if there is a tiny element in the
Z vector.  For each such occurrence the order of the related secular
equation problem is reduced by one.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaein.html'>stdlib_zlaein</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>corresponding to the eigenvalue W of a complex upper Hessenberg
matrix H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaesy.html'>stdlib_zlaesy</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>( ( A, B );( B, C ) )
provided the norm of the matrix of eigenvectors is larger than
some threshold value.
RT1 is the eigenvalue of larger absolute value, and RT2 of
smaller absolute value.  If the eigenvectors are computed, then
on return ( CS1, SN1 ) is the unit eigenvector for RT1, hence
[  CS1     SN1   ] . [ A  B ] . [ CS1    -SN1   ] = [ RT1  0  ]
[ -SN1     CS1   ]   [ B  C ]   [ SN1     CS1   ]   [  0  RT2 ]</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaev2.html'>stdlib_zlaev2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>[  A         B  ]
[  CONJG(B)  C  ].
On return, RT1 is the eigenvalue of larger absolute value, RT2 is the
eigenvalue of smaller absolute value, and (CS1,SN1) is the unit right
eigenvector for RT1, giving the decomposition
[ CS1  CONJG(SN1) ] [    A     B ] [ CS1 -CONJG(SN1) ] = [ RT1  0  ]
[-SN1     CS1     ] [ CONJG(B) C ] [ SN1     CS1     ]   [  0  RT2 ].</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlag2c.html'>stdlib_zlag2c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>RMAX is the overflow for the SINGLE PRECISION arithmetic
ZLAG2C checks that all the entries of A are between -RMAX and
RMAX. If not the conversion is aborted and a flag is raised.
This is an auxiliary routine so there is no argument checking.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlags2.html'>stdlib_zlags2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>that if ( UPPER ) then
U<strong>H <em>A</em>Q = U</strong>H <em>( A1 A2 )</em>Q = ( x  0  )
( 0  A3 )     ( x  x  )
and
V<strong>H<em>B</em>Q = V</strong>H <em>( B1 B2 )</em>Q = ( x  0  )
( 0  B3 )     ( x  x  )
or if ( .NOT.UPPER ) then
U<strong>H <em>A</em>Q = U</strong>H <em>( A1 0  )</em>Q = ( x  x  )
( A2 A3 )     ( 0  x  )
and
V<strong>H <em>B</em>Q = V</strong>H <em>( B1 0  )</em>Q = ( x  x  )
( B2 B3 )     ( 0  x  )
where
U = (   CSU    SNU ), V = (  CSV    SNV ),
( -SNU<strong>H  CSU )      ( -SNV</strong>H CSV )
Q = (   CSQ    SNQ )
( -SNQ**H  CSQ )
The rows of the transformed A and B are parallel. Moreover, if the
input 2-by-2 matrix A is not zero, then the transformed (1,1) entry
of A is not zero. If the input matrices A and B are both not zero,
then the transformed (2,2) element of B is not zero, except when the
first rows of input A and B are parallel and the second rows are
zero.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlagtm.html'>stdlib_zlagtm</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>B := alpha * A * X + beta * B
where A is a tridiagonal matrix of order N, B and X are N by NRHS
matrices, and alpha and beta are real scalars, each of which may be
0., 1., or -1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlahef.html'>stdlib_zlahef</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the Bunch-Kaufman diagonal pivoting method. The
partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I      0     )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0      I     )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**H denotes the conjugate transpose of U.
ZLAHEF is an auxiliary routine called by ZHETRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlahef_aa.html'>stdlib_zlahef_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>DLAHEF_AA factorizes a panel of a complex hermitian matrix A using
the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlahef_rk.html'>stdlib_zlahef_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
ZLAHEF_RK is an auxiliary routine called by ZHETRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlahef_rook.html'>stdlib_zlahef_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting
method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I      0     )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>H U22</strong>H )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>H L21</strong>H )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0      I     )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**H denotes the conjugate transpose of U.
ZLAHEF_ROOK is an auxiliary routine called by ZHETRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlahqr.html'>stdlib_zlahqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues and Schur decomposition already computed by CHSEQR, by
dealing with the Hessenberg submatrix in rows and columns ILO to
IHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlahr2.html'>stdlib_zlahr2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A so that elements below the k-th subdiagonal are zero. The
reduction is performed by an unitary similarity transformation
Q<strong>H * A * Q. The routine returns the matrices V and T which determine
Q as a block reflector I - V<em>T</em>V</strong>H, and also the matrix Y = A * V * T.
This is an auxiliary routine called by ZGEHRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaic1.html'>stdlib_zlaic1</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>its simplest version:
Let x, twonorm(x) = 1, be an approximate singular vector of an j-by-j
lower triangular matrix L, such that
twonorm(L<em>x) = sest
Then ZLAIC1 computes sestpr, s, c such that
the vector
[ s</em>x ]
xhat = [  c  ]
is an approximate singular vector of
[ L       0  ]
Lhat = [ w<strong>H gamma ]
in the sense that
twonorm(Lhat*xhat) = sestpr.
Depending on JOB, an estimate for the largest or smallest singular
value is computed.
Note that [s c]</strong>H and sestpr<strong>2 is an eigenpair of the system
diag(sest*sest, 0) + [alpha  gamma] * [ conjg(alpha) ]
[ conjg(gamma) ]
where  alpha =  x</strong>H * w.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlals0.html'>stdlib_zlals0</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>right singular vector matrix of a diagonal matrix appended by a row
to the right hand side matrix B in solving the least squares problem
using the divide-and-conquer SVD approach.
For the left singular vector matrix, three types of orthogonal
matrices are involved:
(1L) Givens rotations: the number of such rotations is GIVPTR; the
pairs of columns/rows they were applied to are stored in GIVCOL;
and the C- and S-values of these rotations are stored in GIVNUM.
(2L) Permutation. The (NL+1)-st row of B is to be moved to the first
row, and for J=2:N, PERM(J)-th row of B is to be moved to the
J-th row.
(3L) The left singular vector matrix of the remaining matrix.
For the right singular vector matrix, four types of orthogonal
matrices are involved:
(1R) The right singular vector matrix of the remaining matrix.
(2R) If SQRE = 1, one extra Givens rotation to generate the right
null space.
(3R) The inverse transformation of (2L).
(4R) The inverse transformation of (1L).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlalsa.html'>stdlib_zlalsa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>by computing the SVD of the coefficient matrix in compact form (The
singular vectors are computed as products of simple orthorgonal
matrices.).
If ICOMPQ = 0, ZLALSA applies the inverse of the left singular vector
matrix of an upper bidiagonal matrix to the right hand side; and if
ICOMPQ = 1, ZLALSA applies the right singular vector matrix to the
right hand side. The singular vector matrices were generated in
compact form by ZLALSA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlalsd.html'>stdlib_zlalsd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>squares problem of finding X to minimize the Euclidean norm of each
column of A*X-B, where A is N-by-N upper bidiagonal, and X and B
are N-by-NRHS. The solution X overwrites B.
The singular values of A smaller than RCOND times the largest
singular value are treated as zero in solving the least squares
problem; in this case a minimum norm solution is returned.
The actual singular values are returned in D in ascending order.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlamswlq.html'>stdlib_zlamswlq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of blocked
elementary reflectors computed by short wide LQ
factorization (ZLASWLQ)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlamtsqr.html'>stdlib_zlamtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product
of blocked elementary reflectors computed by tall skinny
QR factorization (ZLATSQR)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlangb.html'>stdlib_zlangb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n band matrix  A,  with kl sub-diagonals and ku super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlange.html'>stdlib_zlange</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlangt.html'>stdlib_zlangt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlanhb.html'>stdlib_zlanhb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n hermitian band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlanhe.html'>stdlib_zlanhe</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex hermitian matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlanhf.html'>stdlib_zlanhf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex Hermitian matrix A in RFP format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlanhp.html'>stdlib_zlanhp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex hermitian matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlanhs.html'>stdlib_zlanhs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
Hessenberg matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlanht.html'>stdlib_zlanht</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex Hermitian tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlansb.html'>stdlib_zlansb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n symmetric band matrix A,  with k super-diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlansp.html'>stdlib_zlansp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex symmetric matrix A,  supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlansy.html'>stdlib_zlansy</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
complex symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlantb.html'>stdlib_zlantb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the element of  largest absolute value  of an
n by n triangular band matrix A,  with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlantp.html'>stdlib_zlantp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
triangular matrix A, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlantr.html'>stdlib_zlantr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Function</td><td><p>the  infinity norm,  or the  element of  largest absolute value  of a
trapezoidal or triangular matrix A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlapll.html'>stdlib_zlapll</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Given two column vectors X and Y, let
A = ( X Y ).
The subroutine first computes the QR factorization of A = Q*R,
and then computes the SVD of the 2-by-2 upper triangular matrix R.
The smaller singular value of R is returned in SSMIN, which is used
as the measurement of the linear dependency of the vectors X and Y.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlapmr.html'>stdlib_zlapmr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(M) of the integers 1,...,M.
If FORWRD = .TRUE.,  forward permutation:
X(K(I),<em>) is moved X(I,</em>) for I = 1,2,...,M.
If FORWRD = .FALSE., backward permutation:
X(I,<em>) is moved to X(K(I),</em>) for I = 1,2,...,M.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlapmt.html'>stdlib_zlapmt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>by the permutation K(1),K(2),...,K(N) of the integers 1,...,N.
If FORWRD = .TRUE.,  forward permutation:
X(<em>,K(J)) is moved X(</em>,J) for J = 1,2,...,N.
If FORWRD = .FALSE., backward permutation:
X(<em>,J) is moved to X(</em>,K(J)) for J = 1,2,...,N.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqgb.html'>stdlib_zlaqgb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>subdiagonals and KU superdiagonals using the row and scaling factors
in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqge.html'>stdlib_zlaqge</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>column scaling factors in the vectors R and C.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqhb.html'>stdlib_zlaqhb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the scaling factors in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqhe.html'>stdlib_zlaqhe</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqhp.html'>stdlib_zlaqhp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqp2.html'>stdlib_zlaqp2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>the block A(OFFSET+1:M,1:N).
The block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqps.html'>stdlib_zlaqps</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a complex M-by-N matrix A by using Blas-3.  It tries to factorize
NB columns from A starting from the row OFFSET+1, and updates all
of the matrix with Blas-3 xGEMM.
In some cases, due to catastrophic cancellations, it cannot
factorize NB columns.  Hence, the actual number of factorized
columns is returned in KB.
Block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqr0.html'>stdlib_zlaqr0</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>H</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqr1.html'>stdlib_zlaqr1</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Given a 2-by-2 or 3-by-3 matrix H, ZLAQR1: sets v to a
scalar multiple of the first column of the product
(<em>)  K = (H - s1</em>I)<em>(H - s2</em>I)
scaling to avoid overflows and most underflows.
This is useful for starting double implicit shift bulges
in the QR algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqr2.html'>stdlib_zlaqr2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>recursion by calling ZLAHQR instead of ZLAQR4.
Aggressive early deflation:
ZLAQR2 accepts as input an upper Hessenberg matrix
H and performs an unitary similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an unitary similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqr3.html'>stdlib_zlaqr3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Aggressive early deflation:
ZLAQR3: accepts as input an upper Hessenberg matrix
H and performs an unitary similarity transformation
designed to detect and deflate fully converged eigenvalues from
a trailing principal submatrix.  On output H has been over-
written by a new Hessenberg matrix that is a perturbation of
an unitary similarity transformation of H.  It is to be
hoped that the final version of H has many zero subdiagonal
entries.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqr4.html'>stdlib_zlaqr4</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>It is a complete implementation of the small bulge multi-shift
QR algorithm.  It may be called by ZLAQR0 and, for large enough
deflation window size, it may be called by ZLAQR3.  This
subroutine is identical to ZLAQR0 except that it calls ZLAQR2
instead of ZLAQR3.
ZLAQR4 computes the eigenvalues of a Hessenberg matrix H
and, optionally, the matrices T and Z from the Schur decomposition
H = Z T Z<strong>H, where T is an upper triangular matrix (the
Schur form), and Z is the unitary matrix of Schur vectors.
Optionally Z may be postmultiplied into an input unitary
matrix Q so that this routine can give the Schur factorization
of a matrix A which has been reduced to the Hessenberg form H
by the unitary matrix Q:  A = Q<em>H</em>Q</strong>H = (QZ)<em>H</em>(QZ)**H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqr5.html'>stdlib_zlaqr5</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>single small-bulge multi-shift QR sweep.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqsb.html'>stdlib_zlaqsb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>factors in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqsp.html'>stdlib_zlaqsp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqsy.html'>stdlib_zlaqsy</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>in the vector S.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqz0.html'>stdlib_zlaqz0</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>where H is an upper Hessenberg matrix and T is upper triangular,
using the double-shift QZ method.
Matrix pairs of this type are produced by the reduction to
generalized upper Hessenberg form of a real matrix pair (A,B):
A = Q1<em>H</em>Z1<strong>H,  B = Q1<em>T</em>Z1</strong>H,
as computed by ZGGHRD.
If JOB='S', then the Hessenberg-triangular pair (H,T) is
also reduced to generalized Schur form,
H = Q<em>S</em>Z<strong>H,  T = Q<em>P</em>Z</strong>H,
where Q and Z are unitary matrices, P and S are an upper triangular
matrices.
Optionally, the unitary matrix Q from the generalized Schur
factorization may be postmultiplied into an input matrix Q1, and the
unitary matrix Z may be postmultiplied into an input matrix Z1.
If Q1 and Z1 are the unitary matrices from ZGGHRD that reduced
the matrix pair (A,B) to generalized upper Hessenberg form, then the
output matrices Q1<em>Q and Z1</em>Z are the unitary factors from the
generalized Schur factorization of (A,B):
A = (Q1<em>Q)</em>S<em>(Z1</em>Z)<strong>H,  B = (Q1<em>Q)</em>P<em>(Z1</em>Z)</strong>H.
To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently,
of (A,B)) are computed as a pair of values (alpha,beta), where alpha is
complex and beta real.
If beta is nonzero, lambda = alpha / beta is an eigenvalue of the
generalized nonsymmetric eigenvalue problem (GNEP)
A<em>x = lambda</em>B<em>x
and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the
alternate form of the GNEP
mu</em>A<em>y = B</em>y.
Eigenvalues can be read directly from the generalized Schur
form:
alpha = S(i,i), beta = P(i,i).
Ref: C.B. Moler
Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
pp. 241--256.
Ref: B. Kagstrom, D. Kressner, "Multishift Variants of the QZ
Algorithm with Aggressive Early Deflation", SIAM J. Numer.
Anal., 29(2006), pp. 199--227.
Ref: T. Steel, D. Camps, K. Meerbergen, R. Vandebril "A multishift,
multipole rational QZ method with agressive early deflation"</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqz1.html'>stdlib_zlaqz1</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZLAQZ1: chases a 1x1 shift bulge in a matrix pencil down a single position</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqz2.html'>stdlib_zlaqz2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZLAQZ2: performs AED</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaqz3.html'>stdlib_zlaqz3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZLAQZ3: Executes a single multishift QZ sweep</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlar1v.html'>stdlib_zlar1v</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>the sumbmatrix in rows B1 through BN of the tridiagonal matrix
L D L<strong>T - sigma I. When sigma is close to an eigenvalue, the
computed vector is an accurate eigenvector. Usually, r corresponds
to the index where the eigenvector is largest in magnitude.
The following steps accomplish this computation :
(a) Stationary qd transform,  L D L</strong>T - sigma I = L(+) D(+) L(+)<strong>T,
(b) Progressive qd transform, L D L</strong>T - sigma I = U(-) D(-) U(-)<strong>T,
(c) Computation of the diagonal elements of the inverse of
L D L</strong>T - sigma I by combining the above transforms, and choosing
r as the index where the diagonal of the inverse is (one of the)
largest in magnitude.
(d) Computation of the (scaled) r-th column of the inverse using the
twisted factorization obtained by combining the top part of the
the stationary and the bottom part of the progressive transform.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlar2v.html'>stdlib_zlar2v</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>from both sides to a sequence of 2-by-2 complex Hermitian matrices,
defined by the elements of the vectors x, y and z. For i = 1,2,...,n
(       x(i)  z(i) ) :=
( conjg(z(i)) y(i) )
(  c(i) conjg(s(i)) ) (       x(i)  z(i) ) ( c(i) -conjg(s(i)) )
( -s(i)       c(i)  ) ( conjg(z(i)) y(i) ) ( s(i)        c(i)  )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarcm.html'>stdlib_zlarcm</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>C := A * B,
where A is M by M and real; B is M by N and complex;
C is M by N and complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarf.html'>stdlib_zlarf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v<strong>H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix.
To apply H</strong>H, supply conjg(tau) instead
tau.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarfb.html'>stdlib_zlarfb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>complex M-by-N matrix C, from either the left or the right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarfb_gett.html'>stdlib_zlarfb_gett</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>left to a complex (K+M)-by-N  "triangular-pentagonal" matrix
composed of two block matrices: an upper trapezoidal K-by-N matrix A
stored in the array A, and a rectangular M-by-(N-K) matrix B, stored
in the array B. The block reflector H is stored in a compact
WY-representation, where the elementary reflectors are in the
arrays A, B and T. See Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarfg.html'>stdlib_zlarfg</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>that
H<strong>H * ( alpha ) = ( beta ),   H</strong>H * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, with beta real, and x is an
(n-1)-element complex vector. H is represented in the form
H = I - tau * ( 1 ) * ( 1 v**H ) ,
( v )
where tau is a complex scalar and v is a complex (n-1)-element
vector. Note that H is not hermitian.
If the elements of x are all zero and alpha is real, then tau = 0
and H is taken to be the unit matrix.
Otherwise  1 &lt;= real(tau) &lt;= 2  and  abs(tau-1) &lt;= 1 .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarfgp.html'>stdlib_zlarfgp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>that
H<strong>H * ( alpha ) = ( beta ),   H</strong>H * H = I.
(   x   )   (   0  )
where alpha and beta are scalars, beta is real and non-negative, and
x is an (n-1)-element complex vector.  H is represented in the form
H = I - tau * ( 1 ) * ( 1 v**H ) ,
( v )
where tau is a complex scalar and v is a complex (n-1)-element
vector. Note that H is not hermitian.
If the elements of x are all zero and alpha is real, then tau = 0
and H is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarft.html'>stdlib_zlarft</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of order n, which is defined as a product of k elementary reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>H
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>H * T * V</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarfx.html'>stdlib_zlarfx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix C, from either the left or the right. H is represented in the
form
H = I - tau * v * v**H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix
This version uses inline code if H has order &lt; 11.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarfy.html'>stdlib_zlarfy</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to an n x n Hermitian matrix C, from both the left and the right.
H is represented in the form
H = I - tau * v * v'
where  tau  is a scalar and  v  is a vector.
If  tau  is  zero, then  H  is taken to be the unit matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlargv.html'>stdlib_zlargv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>cosines, determined by elements of the complex vectors x and y.
For i = 1,2,...,n
(        c(i)   s(i) ) ( x(i) ) = ( r(i) )
( -conjg(s(i))  c(i) ) ( y(i) ) = (   0  )
where c(i)<strong>2 + ABS(s(i))</strong>2 = 1
The following conventions are used (these are the same as in ZLARTG,
but differ from the BLAS1 routine ZROTG):
If y(i)=0, then c(i)=1 and s(i)=0.
If x(i)=0, then c(i)=0 and s(i) is chosen so that r(i) is real.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarnv.html'>stdlib_zlarnv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>normal distribution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarrv.html'>stdlib_zlarrv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>T = L D L<strong>T given L, D and APPROXIMATIONS to the eigenvalues of L D L</strong>T.
The input eigenvalues should have been computed by DLARRE.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlartg.html'>stdlib_zlartg</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_zlartg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_zlartv.html'>stdlib_zlartv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to elements of the complex vectors x and y. For i = 1,2,...,n
( x(i) ) := (        c(i)   s(i) ) ( x(i) )
( y(i) )    ( -conjg(s(i))  c(i) ) ( y(i) )</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarz.html'>stdlib_zlarz</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>M-by-N matrix C, from either the left or the right. H is represented
in the form
H = I - tau * v * v<strong>H
where tau is a complex scalar and v is a complex vector.
If tau = 0, then H is taken to be the unit matrix.
To apply H</strong>H (the conjugate transpose of H), supply conjg(tau) instead
tau.
H is a product of k elementary reflectors as returned by ZTZRZF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarzb.html'>stdlib_zlarzb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to a complex distributed M-by-N  C from the left or the right.
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlarzt.html'>stdlib_zlarzt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>H of order &gt; n, which is defined as a product of k elementary
reflectors.
If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular;
If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular.
If STOREV = 'C', the vector which defines the elementary reflector
H(i) is stored in the i-th column of the array V, and
H  =  I - V * T * V<strong>H
If STOREV = 'R', the vector which defines the elementary reflector
H(i) is stored in the i-th row of the array V, and
H  =  I - V</strong>H * T * V
Currently, only STOREV = 'R' and DIRECT = 'B' are supported.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlascl.html'>stdlib_zlascl</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>CTO/CFROM.  This is done without over/underflow as long as the final
result CTO*A(I,J)/CFROM does not over/underflow. TYPE specifies that
A may be full, upper triangular, lower triangular, upper Hessenberg,
or banded.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaset.html'>stdlib_zlaset</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ALPHA on the offdiagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlasr.html'>stdlib_zlasr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A, from either the left or the right.
When SIDE = 'L', the transformation takes the form
A := P<em>A
and when SIDE = 'R', the transformation takes the form
A := A</em>P<strong>T
where P is an orthogonal matrix consisting of a sequence of z plane
rotations, with z = M when SIDE = 'L' and z = N when SIDE = 'R',
and P</strong>T is the transpose of P.
When DIRECT = 'F' (Forward sequence), then
P = P(z-1) * ... * P(2) * P(1)
and when DIRECT = 'B' (Backward sequence), then
P = P(1) * P(2) * ... * P(z-1)
where P(k) is a plane rotation matrix defined by the 2-by-2 rotation
R(k) = (  c(k)  s(k) )
= ( -s(k)  c(k) ).
When PIVOT = 'V' (Variable pivot), the rotation is performed
for the plane (k,k+1), i.e., P(k) has the form
P(k) = (  1                                            )
(       ...                                     )
(              1                                )
(                   c(k)  s(k)                  )
(                  -s(k)  c(k)                  )
(                                1              )
(                                     ...       )
(                                            1  )
where R(k) appears as a rank-2 modification to the identity matrix in
rows and columns k and k+1.
When PIVOT = 'T' (Top pivot), the rotation is performed for the
plane (1,k+1), so P(k) has the form
P(k) = (  c(k)                    s(k)                 )
(         1                                     )
(              ...                              )
(                     1                         )
( -s(k)                    c(k)                 )
(                                 1             )
(                                      ...      )
(                                             1 )
where R(k) appears in rows and columns 1 and k+1.
Similarly, when PIVOT = 'B' (Bottom pivot), the rotation is
performed for the plane (k,z), giving P(k) the form
P(k) = ( 1                                             )
(      ...                                      )
(             1                                 )
(                  c(k)                    s(k) )
(                         1                     )
(                              ...              )
(                                     1         )
(                 -s(k)                    c(k) )
where R(k) appears in rows and columns k and z.  The rotations are
performed without ever forming P(k) explicitly.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlassq.html'>stdlib_zlassq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_zlassq.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaswlq.html'>stdlib_zlaswlq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complexx M-by-N matrix A for M &lt;= N:
A = ( L 0 ) *  Q,
where:
Q is a n-by-N orthogonal matrix, stored on exit in an implicit
form in the elements above the diagonal of the array A and in
the elements of the array T;
L is a lower-triangular M-by-M matrix stored on exit in
the elements on and below the diagonal of the array A.
0 is a M-by-(N-M) zero matrix, if M &lt; N, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaswp.html'>stdlib_zlaswp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>One row interchange is initiated for each of rows K1 through K2 of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlasyf.html'>stdlib_zlasyf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A using the Bunch-Kaufman diagonal pivoting method. The partial
factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) ( D    0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) ( 0   A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
Note that U**T denotes the transpose of U.
ZLASYF is an auxiliary routine called by ZSYTRF. It uses blocked code
(calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or
A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlasyf_aa.html'>stdlib_zlasyf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>DLATRF_AA factorizes a panel of a complex symmetric matrix A using
the Aasen's algorithm. The panel consists of a set of NB rows of A
when UPLO is U, or a set of NB columns when UPLO is L.
In order to factorize the panel, the Aasen's algorithm requires the
last row, or column, of the previous panel. The first row, or column,
of A is set to be the first row, or column, of an identity matrix,
which is used to factorize the first panel.
The resulting J-th row of U, or J-th column of L, is stored in the
(J-1)-th row, or column, of A (without the unit diagonals), while
the diagonal and subdiagonal of A are overwritten by those of T.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlasyf_rk.html'>stdlib_zlasyf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman (rook) diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L',
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
ZLASYF_RK is an auxiliary routine called by ZSYTRF_RK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlasyf_rook.html'>stdlib_zlasyf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method. The partial factorization has the form:
A  =  ( I  U12 ) ( A11  0  ) (  I       0    )  if UPLO = 'U', or:
( 0  U22 ) (  0   D  ) ( U12<strong>T U22</strong>T )
A  =  ( L11  0 ) (  D   0  ) ( L11<strong>T L21</strong>T )  if UPLO = 'L'
( L21  I ) (  0  A22 ) (  0       I    )
where the order of D is at most NB. The actual order is returned in
the argument KB, and is either NB or NB-1, or N if N &lt;= NB.
ZLASYF_ROOK is an auxiliary routine called by ZSYTRF_ROOK. It uses
blocked code (calling Level 3 BLAS) to update the submatrix
A11 (if UPLO = 'U') or A22 (if UPLO = 'L').</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlat2c.html'>stdlib_zlat2c</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>triangular matrix, A.
RMAX is the overflow for the SINGLE PRECISION arithmetic
ZLAT2C checks that all the entries of A are between -RMAX and
RMAX. If not the conversion is aborted and a flag is raised.
This is an auxiliary routine so there is no argument checking.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatbs.html'>stdlib_zlatbs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow, where A is an upper or lower
triangular band matrix.  Here A</strong>T denotes the transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine ZTBSV is called.  If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A*x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatdf.html'>stdlib_zlatdf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>by solving for x in Z * x = b, where b is chosen such that the norm
of x is as large as possible. It is assumed that LU decomposition
of Z has been computed by ZGETC2. On entry RHS = f holds the
contribution from earlier solved sub-systems, and on return RHS = x.
The factorization of Z returned by ZGETC2 has the form
Z = P * L * U * Q, where P and Q are permutation matrices. L is lower
triangular with unit diagonal elements and U is upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatps.html'>stdlib_zlatps</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow, where A is an upper or lower
triangular matrix stored in packed form.  Here A</strong>T denotes the
transpose of A, A*<em>H denotes the conjugate transpose of A, x and b
are n-element vectors, and s is a scaling factor, usually less than
or equal to 1, chosen so that the components of x will be less than
the overflow threshold.  If the unscaled problem will not cause
overflow, the Level 2 BLAS routine ZTPSV is called. If the matrix A
is singular (A(j,j) = 0 for some j), then s is set to 0 and a
non-trivial solution to A</em>x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatrd.html'>stdlib_zlatrd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian tridiagonal form by a unitary similarity
transformation Q**H * A * Q, and returns the matrices V and W which are
needed to apply the transformation to the unreduced part of A.
If UPLO = 'U', ZLATRD reduces the last NB rows and columns of a
matrix, of which the upper triangle is supplied;
if UPLO = 'L', ZLATRD reduces the first NB rows and columns of a
matrix, of which the lower triangle is supplied.
This is an auxiliary routine called by ZHETRD.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatrs.html'>stdlib_zlatrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * x = s<em>b,  A</em><em>T * x = s</em>b,  or  A<strong>H * x = s*b,
with scaling to prevent overflow.  Here A is an upper or lower
triangular matrix, A</strong>T denotes the transpose of A, A*<em>H denotes the
conjugate transpose of A, x and b are n-element vectors, and s is a
scaling factor, usually less than or equal to 1, chosen so that the
components of x will be less than the overflow threshold.  If the
unscaled problem will not cause overflow, the Level 2 BLAS routine
ZTRSV is called. If the matrix A is singular (A(j,j) = 0 for some j),
then s is set to 0 and a non-trivial solution to A</em>x = 0 is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatrz.html'>stdlib_zlatrz</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>[ A1 A2 ] = [ A(1:M,1:M) A(1:M,N-L+1:N) ] as ( R  0 ) * Z by means
of unitary transformations, where  Z is an (M+L)-by-(M+L) unitary
matrix and, R and A1 are M-by-M upper triangular matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlatsqr.html'>stdlib_zlatsqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex M-by-N matrix A for M &gt;= N:
A = Q * ( R ),
( 0 )
where:
Q is a M-by-M orthogonal matrix, stored on exit in an implicit
form in the elements below the diagonal of the array A and in
the elements of the array T;
R is an upper-triangular N-by-N matrix, stored on exit in
the elements on and above the diagonal of the array A.
0 is a (M-N)-by-N zero matrix, and is not stored.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaunhr_col_getrfnp.html'>stdlib_zlaunhr_col_getrfnp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>pivoting of a complex general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is
at least one in absolute value (so that division-by-zero not
not possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine ZUNHR_COL. In ZUNHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the blocked right-looking version of the algorithm,
calling Level 3 BLAS to update the submatrix. To factorize a block,
this routine calls the recursive routine ZLAUNHR_COL_GETRFNP2.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlaunhr_col_getrfnp2.html'>stdlib_zlaunhr_col_getrfnp2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>pivoting of a complex general M-by-N matrix A. The factorization has
the form:
A - S = L * U,
where:
S is a m-by-n diagonal sign matrix with the diagonal D, so that
D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed
as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing
i-1 steps of Gaussian elimination. This means that the diagonal
element at each step of "modified" Gaussian elimination is at
least one in absolute value (so that division-by-zero not
possible during the division by the diagonal element);
L is a M-by-N lower triangular matrix with unit diagonal elements
(lower trapezoidal if M &gt; N);
and U is a M-by-N upper triangular matrix
(upper trapezoidal if M &lt; N).
This routine is an auxiliary routine used in the Householder
reconstruction routine ZUNHR_COL. In ZUNHR_COL, this routine is
applied to an M-by-N matrix A with orthonormal columns, where each
element is bounded by one in absolute value. With the choice of
the matrix S above, one can show that the diagonal element at each
step of Gaussian elimination is the largest (in absolute value) in
the column on or below the diagonal, so that no pivoting is required
for numerical stability [1].
For more details on the Householder reconstruction algorithm,
including the modified LU factorization, see [1].
This is the recursive version of the LU factorization algorithm.
Denote A - S by B. The algorithm divides the matrix B into four
submatrices:
[  B11 | B12  ]  where B11 is n1 by n1,
B = [ -----|----- ]        B21 is (m-n1) by n1,
[  B21 | B22  ]        B12 is n1 by n2,
B22 is (m-n1) by n2,
with n1 = min(m,n)/2, n2 = n-n1.
The subroutine calls itself to factor B11, solves for B21,
solves for B12, updates B22, then calls itself to factor B22.
For more details on the recursive LU algorithm, see [2].
ZLAUNHR_COL_GETRFNP2 is called to factorize a block by the blocked
routine ZLAUNHR_COL_GETRFNP, which uses blocked code calling
Level 3 BLAS to update the submatrix. However, ZLAUNHR_COL_GETRFNP2
is self-sufficient and can be used without ZLAUNHR_COL_GETRFNP.
[1] "Reconstructing Householder vectors from tall-skinny QR",
G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen,
E. Solomonik, J. Parallel Distrib. Comput.,
vol. 85, pp. 3-31, 2015.
[2] "Recursion leads to automatic variable blocking for dense linear
algebra algorithms", F. Gustavson, IBM J. of Res. and Dev.,
vol. 41, no. 6, pp. 737-755, 1997.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlauu2.html'>stdlib_zlauu2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the unblocked form of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zlauum.html'>stdlib_zlauum</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>factor U or L is stored in the upper or lower triangular part of
the array A.
If UPLO = 'U' or 'u' then the upper triangle of the result is stored,
overwriting the factor U in A.
If UPLO = 'L' or 'l' then the lower triangle of the result is stored,
overwriting the factor L in A.
This is the blocked form of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbcon.html'>stdlib_zpbcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite band matrix using
the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by
ZPBTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbequ.html'>stdlib_zpbequ</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian positive definite band matrix A and reduce its condition
number (with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbrfs.html'>stdlib_zpbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and banded, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbstf.html'>stdlib_zpbstf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian positive definite band matrix A.
This routine is designed to be used in conjunction with ZHBGST.
The factorization has the form  A = S*<em>H</em>S  where S is a band matrix
of the same bandwidth as A and the following structure:
S = ( U    )
( M  L )
where U is upper triangular of order m = (n+kd)/2, and L is lower
triangular of order n-m.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbsv.html'>stdlib_zpbsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite band matrix and X
and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H * U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular band matrix, and L is a lower
triangular band matrix, with the same number of superdiagonals or
subdiagonals as A.  The factored form of A is then used to solve the
system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbsvx.html'>stdlib_zpbsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>compute the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N Hermitian positive definite band matrix and X
and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbtf2.html'>stdlib_zpbtf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>H * U ,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix, U**H is the conjugate transpose
of U, and L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbtrf.html'>stdlib_zpbtrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite band matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpbtrs.html'>stdlib_zpbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite band matrix A using the Cholesky factorization
A = U<strong>H <em>U or A = L</em>L</strong>H computed by ZPBTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpftrf.html'>stdlib_zpftrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpftri.html'>stdlib_zpftri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by ZPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpftrs.html'>stdlib_zpftrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>H<em>U or A = L</em>L</strong>H computed by ZPFTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpocon.html'>stdlib_zpocon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite matrix using the
Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by ZPOTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpoequ.html'>stdlib_zpoequ</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpoequb.html'>stdlib_zpoequb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian positive definite matrix A and reduce its condition number
(with respect to the two-norm).  S contains the scale factors,
S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with
elements B(i,j) = S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.  This
choice of S puts the condition number of B within a factor N of the
smallest possible condition number over all possible diagonal
scalings.
This routine differs from ZPOEQU by restricting the scaling factors
to a power of the radix.  Barring over- and underflow, scaling by
these factors introduces no additional rounding errors.  However, the
scaled diagonal entries are no longer approximately 1 but lie
between sqrt(radix) and 1/sqrt(radix).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zporfs.html'>stdlib_zporfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite,
and provides error bounds and backward error estimates for the
solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zposv.html'>stdlib_zposv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix and X and B
are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H* U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and  L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zposvx.html'>stdlib_zposvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>compute the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N Hermitian positive definite matrix and X and B
are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpotf2.html'>stdlib_zpotf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U ,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpotrf.html'>stdlib_zpotrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the block version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpotrf2.html'>stdlib_zpotrf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A using the recursive algorithm.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.
This is the recursive version of the algorithm. It divides
the matrix into four submatrices:
[  A11 | A12  ]  where A11 is n1 by n1 and A22 is n2 by n2
A = [ -----|----- ]  with n1 = n/2
[  A21 | A22  ]       n2 = n-n1
The subroutine calls itself to factor A11. Update and scale A21
or A12, update A22 then call itself to factor A22.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpotri.html'>stdlib_zpotri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by ZPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpotrs.html'>stdlib_zpotrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A using the Cholesky factorization
A = U<strong>H * U or A = L * L</strong>H computed by ZPOTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zppcon.html'>stdlib_zppcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite packed matrix using
the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H computed by
ZPPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zppequ.html'>stdlib_zppequ</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Hermitian positive definite matrix A in packed storage and reduce
its condition number (with respect to the two-norm).  S contains the
scale factors, S(i)=1/sqrt(A(i,i)), chosen so that the scaled matrix
B with elements B(i,j)=S(i)<em>A(i,j)</em>S(j) has ones on the diagonal.
This choice of S puts the condition number of B within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpprfs.html'>stdlib_zpprfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zppsv.html'>stdlib_zppsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N Hermitian positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
The Cholesky decomposition is used to factor A as
A = U<strong>H * U,  if UPLO = 'U', or
A = L * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is a lower triangular
matrix.  The factored form of A is then used to solve the system of
equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zppsvx.html'>stdlib_zppsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>compute the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N Hermitian positive definite matrix stored in
packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpptrf.html'>stdlib_zpptrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A stored in packed format.
The factorization has the form
A = U<strong>H * U,  if UPLO = 'U', or
A = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpptri.html'>stdlib_zpptri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the Cholesky factorization A = U<strong>H<em>U or A = L</em>L</strong>H
computed by ZPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpptrs.html'>stdlib_zpptrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite matrix A in packed storage using the Cholesky
factorization A = U<strong>H * U or A = L * L</strong>H computed by ZPPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpstf2.html'>stdlib_zpstf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>pivoting of a complex Hermitian positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>H * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpstrf.html'>stdlib_zpstrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>pivoting of a complex Hermitian positive semidefinite matrix A.
The factorization has the form
P<strong>T * A * P = U</strong>H * U ,  if UPLO = 'U',
P<strong>T * A * P = L  * L</strong>H,  if UPLO = 'L',
where U is an upper triangular matrix and L is lower triangular, and
P is stored as vector PIV.
This algorithm does not attempt to check that A is positive
semidefinite. This version of the algorithm calls level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zptcon.html'>stdlib_zptcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex Hermitian positive definite tridiagonal matrix
using the factorization A = L<em>D</em>L<strong>H or A = U</strong>H<em>D</em>U computed by
ZPTTRF.
Norm(inv(A)) is computed by a direct method, and the reciprocal of
the condition number is computed as
RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpteqr.html'>stdlib_zpteqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric positive definite tridiagonal matrix by first factoring the
matrix using DPTTRF and then calling ZBDSQR to compute the singular
values of the bidiagonal factor.
This routine computes the eigenvalues of the positive definite
tridiagonal matrix to high relative accuracy.  This means that if the
eigenvalues range over many orders of magnitude in size, then the
small eigenvalues and corresponding eigenvectors will be computed
more accurately than, for example, with the standard QR method.
The eigenvectors of a full or band positive definite Hermitian matrix
can also be found if ZHETRD, ZHPTRD, or ZHBTRD has been used to
reduce this matrix to tridiagonal form.  (The reduction to
tridiagonal form, however, may preclude the possibility of obtaining
high relative accuracy in the small eigenvalues of the original
matrix, if these eigenvalues range over many orders of magnitude.)</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zptrfs.html'>stdlib_zptrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is Hermitian positive definite
and tridiagonal, and provides error bounds and backward error
estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zptsv.html'>stdlib_zptsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A<em>X = B, where A is an N-by-N Hermitian positive definite tridiagonal
matrix, and X and B are N-by-NRHS matrices.
A is factored as A = L</em>D<em>L</em>*H, and the factored form of A is then
used to solve the system of equations.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zptsvx.html'>stdlib_zptsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to a complex system of linear equations A*X = B, where A is an
N-by-N Hermitian positive definite tridiagonal matrix and X and B
are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpttrf.html'>stdlib_zpttrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>positive definite tridiagonal matrix A.  The factorization may also
be regarded as having the form A = U<em><em>H </em>D</em>U.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zpttrs.html'>stdlib_zpttrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B
using the factorization A = U<strong>H <em>D</em> U or A = L<em>D</em>L</strong>H computed by ZPTTRF.
D is a diagonal matrix specified in the vector D, U (or L) is a unit
bidiagonal matrix whose superdiagonal (subdiagonal) is specified in
the vector E, and X and B are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zptts2.html'>stdlib_zptts2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B
using the factorization A = U<strong>H <em>D</em>U or A = L<em>D</em>L</strong>H computed by ZPTTRF.
D is a diagonal matrix specified in the vector D, U (or L) is a unit
bidiagonal matrix whose superdiagonal (subdiagonal) is specified in
the vector E, and X and B are N by NRHS matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zrot.html'>stdlib_zrot</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>sin (S) is complex, and the vectors CX and CY are complex.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zrotg.html'>stdlib_zrotg</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>!</p><a href="../proc/stdlib_zrotg.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/stdlib_zscal.html'>stdlib_zscal</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zspcon.html'>stdlib_zspcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex symmetric packed matrix A using the
factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by ZSPTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zspmv.html'>stdlib_zspmv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zspr.html'>stdlib_zspr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a complex scalar, x is an n element vector and A is an
n by n symmetric matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsprfs.html'>stdlib_zsprfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite
and packed, and provides error bounds and backward error estimates
for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zspsv.html'>stdlib_zspsv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix stored in packed format and X
and B are N-by-NRHS matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, D is symmetric and block diagonal with 1-by-1
and 2-by-2 diagonal blocks.  The factored form of A is then used to
solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zspsvx.html'>stdlib_zspsvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = L<em>D</em>L**T to compute the solution to a complex system of linear
equations A * X = B, where A is an N-by-N symmetric matrix stored
in packed format and X and B are N-by-NRHS matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsptrf.html'>stdlib_zsptrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>stored in packed format using the Bunch-Kaufman diagonal pivoting
method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsptri.html'>stdlib_zsptri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A in packed storage using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by ZSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsptrs.html'>stdlib_zsptrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric matrix A stored in packed format using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by ZSPTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zstedc.html'>stdlib_zstedc</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.
The eigenvectors of a full or band complex Hermitian matrix can also
be found if ZHETRD or ZHPTRD or ZHBTRD has been used to reduce this
matrix to tridiagonal form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See DLAED3 for details.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zstegr.html'>stdlib_zstegr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
ZSTEGR is a compatibility wrapper around the improved ZSTEMR routine.
See ZSTEMR for further details.
One important change is that the ABSTOL parameter no longer provides any
benefit and hence is no longer used.
Note : ZSTEGR and ZSTEMR work only on machines which follow
IEEE-754 floating-point standard in their handling of infinities and
NaNs.  Normal execution may create these exceptiona values and hence
may abort due to a floating point exception in environments which
do not conform to the IEEE-754 standard.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zstein.html'>stdlib_zstein</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix T corresponding to specified eigenvalues, using inverse
iteration.
The maximum number of iterations allowed for each eigenvector is
specified by an internal parameter MAXITS (currently set to 5).
Although the eigenvectors are real, they are stored in a complex
array, which may be passed to ZUNMTR or ZUPMTR for back
transformation to the eigenvectors of a complex Hermitian matrix
which was reduced to tridiagonal form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zstemr.html'>stdlib_zstemr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
Depending on the number of desired eigenvalues, these are computed either
by bisection or the dqds algorithm. Numerically orthogonal eigenvectors are
computed by the use of various suitable L D L^T factorizations near clusters
of close eigenvalues (referred to as RRRs, Relatively Robust
Representations). An informal sketch of the algorithm follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
For more details, see:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Further Details
1.ZSTEMR works only on machines which follow IEEE-754
floating-point standard in their handling of infinities and NaNs.
This permits the use of efficient inner loops avoiding a check for
zero divisors.
2. LAPACK routines can be used to reduce a complex Hermitean matrix to
real symmetric tridiagonal form.
(Any complex Hermitean tridiagonal matrix has real values on its diagonal
and potentially complex numbers on its off-diagonals. By applying a
similarity transform with an appropriate diagonal matrix
diag(1,e^{i \phy_1}, ... , e^{i \phy_{n-1}}), the complex Hermitean
matrix can be transformed into a real symmetric matrix and complex
arithmetic can be entirely avoided.)
While the eigenvectors of the real symmetric tridiagonal matrix are real,
the eigenvectors of original complex Hermitean matrix have complex entries
in general.
Since LAPACK drivers overwrite the matrix data with the eigenvectors,
ZSTEMR accepts complex workspace to facilitate interoperability
with ZUNMTR or ZUPMTR.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsteqr.html'>stdlib_zsteqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric tridiagonal matrix using the implicit QL or QR method.
The eigenvectors of a full or band complex Hermitian matrix can also
be found if ZHETRD or ZHPTRD or ZHBTRD has been used to reduce this
matrix to tridiagonal form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zswap.html'>stdlib_zswap</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zsycon.html'>stdlib_zsycon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by ZSYTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsycon_rook.html'>stdlib_zsycon_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>1-norm) of a complex symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by ZSYTRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyconv.html'>stdlib_zsyconv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Get nondiagonal elements of D (returned in workspace) and
apply or reverse permutation done in TRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyconvf.html'>stdlib_zsyconvf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
ZSYCONVF: converts the factorization output format used in
ZSYTRF provided on entry in parameter A into the factorization
output format used in ZSYTRF_RK (or ZSYTRF_BK) that is stored
on exit in parameters A and E. It also converts in place details of
the intechanges stored in IPIV from the format used in ZSYTRF into
the format used in ZSYTRF_RK (or ZSYTRF_BK).
If parameter WAY = 'R':
ZSYCONVF performs the conversion in reverse direction, i.e.
converts the factorization output format used in ZSYTRF_RK
(or ZSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in ZSYTRF that is stored
on exit in parameter A. It also converts in place details of
the intechanges stored in IPIV from the format used in ZSYTRF_RK
(or ZSYTRF_BK) into the format used in ZSYTRF.
ZSYCONVF can also convert in Hermitian matrix case, i.e. between
formats used in ZHETRF and ZHETRF_RK (or ZHETRF_BK).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyconvf_rook.html'>stdlib_zsyconvf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>If parameter WAY = 'C':
ZSYCONVF_ROOK: converts the factorization output format used in
ZSYTRF_ROOK provided on entry in parameter A into the factorization
output format used in ZSYTRF_RK (or ZSYTRF_BK) that is stored
on exit in parameters A and E. IPIV format for ZSYTRF_ROOK and
ZSYTRF_RK (or ZSYTRF_BK) is the same and is not converted.
If parameter WAY = 'R':
ZSYCONVF_ROOK performs the conversion in reverse direction, i.e.
converts the factorization output format used in ZSYTRF_RK
(or ZSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in ZSYTRF_ROOK that is stored
on exit in parameter A. IPIV format for ZSYTRF_ROOK and
ZSYTRF_RK (or ZSYTRF_BK) is the same and is not converted.
ZSYCONVF_ROOK can also convert in Hermitian matrix case, i.e. between
formats used in ZHETRF_ROOK and ZHETRF_RK (or ZHETRF_BK).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyequb.html'>stdlib_zsyequb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsymm.html'>stdlib_zsymm</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where  alpha and beta are scalars, A is a symmetric matrix and  B and
C are m by n matrices.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsymv.html'>stdlib_zsymv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyr.html'>stdlib_zsyr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a complex scalar, x is an n element vector and A is an
n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyr2k.html'>stdlib_zsyr2k</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>B<strong>T + alpha<em>B</em>A</strong>T + beta<em>C,
or
C := alpha</em>A<strong>T<em>B + alpha</em>B</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars,  C is an  n by n symmetric matrix
and  A and B  are  n by k  matrices  in the  first  case  and  k by n
matrices in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyrfs.html'>stdlib_zsyrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations when the coefficient matrix is symmetric indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyrk.html'>stdlib_zsyrk</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars,  C is an  n by n symmetric matrix
and  A  is an  n by k  matrix in the first case and a  k by n  matrix
in the second case.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsysv.html'>stdlib_zsysv</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsysv_aa.html'>stdlib_zsysv_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>ZSYSV computes the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>T * T * U,  if UPLO = 'U', or
A = L * T * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is symmetric tridiagonal. The factored
form of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsysv_rk.html'>stdlib_zsysv_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations A * X = B, where A is an N-by-N symmetric matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
ZSYTRF_RK is called to compute the factorization of a complex
symmetric matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine ZSYTRS_3.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsysv_rook.html'>stdlib_zsysv_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
ZSYTRF_ROOK is called to compute the factorization of a complex
symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling ZSYTRS_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsysvx.html'>stdlib_zsysvx</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>solution to a complex system of linear equations A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Error bounds on the solution and a condition estimate are also
provided.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsyswapr.html'>stdlib_zsyswapr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a symmetric matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytf2.html'>stdlib_zsytf2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytf2_rk.html'>stdlib_zsytf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytf2_rook.html'>stdlib_zsytf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrf.html'>stdlib_zsytrf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrf_aa.html'>stdlib_zsytrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>T<em>T</em>U  or  A = L<em>T</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a complex symmetric tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrf_rk.html'>stdlib_zsytrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrf_rook.html'>stdlib_zsytrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytri.html'>stdlib_zsytri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by
ZSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytri_rook.html'>stdlib_zsytri_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T
computed by ZSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrs.html'>stdlib_zsytrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by ZSYTRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrs2.html'>stdlib_zsytrs2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by ZSYTRF and converted by ZSYCONV.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrs_3.html'>stdlib_zsytrs_3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization computed
by ZSYTRF_RK or ZSYTRF_BK:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrs_aa.html'>stdlib_zsytrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>symmetric matrix A using the factorization A = U<strong>T<em>T</em>U or
A = L<em>T</em>L</strong>T computed by ZSYTRF_AA.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zsytrs_rook.html'>stdlib_zsytrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by ZSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztbcon.html'>stdlib_ztbcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>triangular band matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztbmv.html'>stdlib_ztbmv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular band matrix, with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztbrfs.html'>stdlib_ztbrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular band
coefficient matrix.
The solution matrix X must be computed by ZTBTRS or some other
means before entering this routine.  ZTBRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztbsv.html'>stdlib_ztbsv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular band matrix, with ( k + 1 )
diagonals.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztbtrs.html'>stdlib_ztbtrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular band matrix of order N, and B is an
N-by-NRHS matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztfsm.html'>stdlib_ztfsm</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Level 3 BLAS like routine for A in RFP Format.
ZTFSM:  solves the matrix equation
op( A )<em>X = alpha</em>B  or  X<em>op( A ) = alpha</em>B
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**H.
A is in Rectangular Full Packed (RFP) Format.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztftri.html'>stdlib_ztftri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>format.
This is a Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztfttp.html'>stdlib_ztfttp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>format (TF) to standard packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztfttr.html'>stdlib_ztfttr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>format (TF) to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgevc.html'>stdlib_ztgevc</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a pair of complex matrices (S,P), where S and P are upper triangular.
Matrix pairs of this type are produced by the generalized Schur
factorization of a complex matrix pair (A,B):
A = Q<em>S</em>Z<strong>H,  B = Q<em>P</em>Z</strong>H
as computed by ZGGHRD + ZHGEQZ.
The right eigenvector x and the left eigenvector y of (S,P)
corresponding to an eigenvalue w are defined by:
S<em>x = w</em>P<em>x,  (y</em><em>H)</em>S = w<em>(y</em><em>H)</em>P,
where y<em><em>H denotes the conjugate tranpose of y.
The eigenvalues are not input to this routine, but are computed
directly from the diagonal elements of S and P.
This routine returns the matrices X and/or Y of right and left
eigenvectors of (S,P), or the products Z</em>X and/or Q</em>Y,
where Z and Q are input matrices.
If Q and Z are the unitary factors from the generalized Schur
factorization of a matrix pair (A,B), then Z<em>X and Q</em>Y
are the matrices of right and left eigenvectors of (A,B).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgex2.html'>stdlib_ztgex2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>in an upper triangular matrix pair (A, B) by an unitary equivalence
transformation.
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)<strong>H = Q(out) * A(out) * Z(out)</strong>H
Q(in) * B(in) * Z(in)<strong>H = Q(out) * B(out) * Z(out)</strong>H</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgexc.html'>stdlib_ztgexc</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix pair (A,B), using an unitary equivalence transformation
(A, B) := Q * (A, B) * Z<strong>H, so that the diagonal block of (A, B) with
row index IFST is moved to row ILST.
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)</strong>H = Q(out) * A(out) * Z(out)<strong>H
Q(in) * B(in) * Z(in)</strong>H = Q(out) * B(out) * Z(out)**H</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgsen.html'>stdlib_ztgsen</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix pair (A, B) (in terms of an unitary equivalence trans-
formation Q**H * (A, B) * Z), so that a selected cluster of eigenvalues
appears in the leading diagonal blocks of the pair (A,B). The leading
columns of Q and Z form unitary bases of the corresponding left and
right eigenspaces (deflating subspaces). (A, B) must be in
generalized Schur canonical form, that is, A and B are both upper
triangular.
ZTGSEN also computes the generalized eigenvalues
w(j)= ALPHA(j) / BETA(j)
of the reordered matrix pair (A, B).
Optionally, the routine computes estimates of reciprocal condition
numbers for eigenvalues and eigenspaces. These are Difu[(A11,B11),
(A22,B22)] and Difl[(A11,B11), (A22,B22)], i.e. the separation(s)
between the matrix pairs (A11, B11) and (A22,B22) that correspond to
the selected cluster and the eigenvalues outside the cluster, resp.,
and norms of "projections" onto left and right eigenspaces w.r.t.
the selected cluster in the (1,1)-block.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgsja.html'>stdlib_ztgsja</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>of two complex upper triangular (or trapezoidal) matrices A and B.
On entry, it is assumed that matrices A and B have the following
forms, which may be obtained by the preprocessing subroutine ZGGSVP
from a general M-by-N matrix A and P-by-N matrix B:
N-K-L  K    L
A =    K ( 0    A12  A13 ) if M-K-L &gt;= 0;
L ( 0     0   A23 )
M-K-L ( 0     0    0  )
N-K-L  K    L
A =  K ( 0    A12  A13 ) if M-K-L &lt; 0;
M-K ( 0     0   A23 )
N-K-L  K    L
B =  L ( 0     0   B13 )
P-L ( 0     0    0  )
where the K-by-K matrix A12 and L-by-L matrix B13 are nonsingular
upper triangular; A23 is L-by-L upper triangular if M-K-L &gt;= 0,
otherwise A23 is (M-K)-by-L upper trapezoidal.
On exit,
U<strong>H <em>A</em>Q = D1*( 0 R ),    V</strong>H <em>B</em>Q = D2<em>( 0 R ),
where U, V and Q are unitary matrices.
R is a nonsingular upper triangular matrix, and D1
and D2 are ``diagonal'' matrices, which are of the following
structures:
If M-K-L &gt;= 0,
K  L
D1 =     K ( I  0 )
L ( 0  C )
M-K-L ( 0  0 )
K  L
D2 = L   ( 0  S )
P-L ( 0  0 )
N-K-L  K    L
( 0 R ) = K (  0   R11  R12 ) K
L (  0    0   R22 ) L
where
C = diag( ALPHA(K+1), ... , ALPHA(K+L) ),
S = diag( BETA(K+1),  ... , BETA(K+L) ),
C</em><em>2 + S</em><em>2 = I.
R is stored in A(1:K+L,N-K-L+1:N) on exit.
If M-K-L &lt; 0,
K M-K K+L-M
D1 =   K ( I  0    0   )
M-K ( 0  C    0   )
K M-K K+L-M
D2 =   M-K ( 0  S    0   )
K+L-M ( 0  0    I   )
P-L ( 0  0    0   )
N-K-L  K   M-K  K+L-M
( 0 R ) =    K ( 0    R11  R12  R13  )
M-K ( 0     0   R22  R23  )
K+L-M ( 0     0    0   R33  )
where
C = diag( ALPHA(K+1), ... , ALPHA(M) ),
S = diag( BETA(K+1),  ... , BETA(M) ),
C</em><em>2 + S</em>*2 = I.
R = ( R11 R12 R13 ) is stored in A(1:M, N-K-L+1:N) and R33 is stored
(  0  R22 R23 )
in B(M-K+1:L,N+M-K-L+1:N) on exit.
The computation of the unitary transformation matrices U, V or Q
is optional.  These matrices may either be formed explicitly, or they
may be postmultiplied into input matrices U1, V1, or Q1.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgsna.html'>stdlib_ztgsna</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues and/or eigenvectors of a matrix pair (A, B).
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgsy2.html'>stdlib_ztgsy2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C               (1)
D * R - L * E = scale * F
using Level 1 and 2 BLAS, where R and L are unknown M-by-N matrices,
(A, D), (B, E) and (C, F) are given matrix pairs of size M-by-M,
N-by-N and M-by-N, respectively. A, B, D and E are upper triangular
(i.e., (A,D) and (B,E) in generalized Schur form).
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output
scaling factor chosen to avoid overflow.
In matrix notation solving equation (1) corresponds to solve
Zx = scale * b, where Z is defined as
Z = [ kron(In, A)  -kron(B<strong>H, Im) ]             (2)
[ kron(In, D)  -kron(E</strong>H, Im) ],
Ik is the identity matrix of size k and X<strong>H is the conjuguate transpose of X.
kron(X, Y) is the Kronecker product between the matrices X and Y.
If TRANS = 'C', y in the conjugate transposed system Z</strong>H<em>y = scale</em>b
is solved for, which is equivalent to solve for R and L in
A<strong>H * R  + D</strong>H * L   = scale * C           (3)
R  * B<strong>H + L  * E</strong>H  = scale * -F
This case is used to compute an estimate of Dif[(A, D), (B, E)] =
= sigma_min(Z) using reverse communication with ZLACON.
ZTGSY2 also (IJOB &gt;= 1) contributes to the computation in ZTGSYL
of an upper bound on the separation between to matrix pairs. Then
the input (A, D), (B, E) are sub-pencils of two matrix pairs in
ZTGSYL.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztgsyl.html'>stdlib_ztgsyl</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * R - L * B = scale * C            (1)
D * R - L * E = scale * F
where R and L are unknown m-by-n matrices, (A, D), (B, E) and
(C, F) are given matrix pairs of size m-by-m, n-by-n and m-by-n,
respectively, with complex entries. A, B, D and E are upper
triangular (i.e., (A,D) and (B,E) in generalized Schur form).
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1
is an output scaling factor chosen to avoid overflow.
In matrix notation (1) is equivalent to solve Zx = scale<em>b, where Z
is defined as
Z = [ kron(In, A)  -kron(B</em><em>H, Im) ]        (2)
[ kron(In, D)  -kron(E</em><em>H, Im) ],
Here Ix is the identity matrix of size x and X</em><em>H is the conjugate
transpose of X. Kron(X, Y) is the Kronecker product between the
matrices X and Y.
If TRANS = 'C', y in the conjugate transposed system Z</em><em>H </em>y = scale<em>b
is solved for, which is equivalent to solve for R and L in
A</em><em>H * R + D</em><em>H * L = scale * C           (3)
R * B</em><em>H + L * E</em>*H = scale * -F
This case (TRANS = 'C') is used to compute an one-norm-based estimate
of Dif[(A,D), (B,E)], the separation between the matrix pairs (A,D)
and (B,E), using ZLACON.
If IJOB &gt;= 1, ZTGSYL computes a Frobenius norm-based estimate of
Dif[(A,D),(B,E)]. That is, the reciprocal of a lower bound on the
reciprocal of the smallest singular value of Z.
This is a level-3 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpcon.html'>stdlib_ztpcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztplqt.html'>stdlib_ztplqt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztplqt2.html'>stdlib_ztplqt2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpmlqt.html'>stdlib_ztpmlqt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" complex block reflector H to a general
complex matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpmqrt.html'>stdlib_ztpmqrt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" complex block reflector H to a general
complex matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpmv.html'>stdlib_ztpmv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpqrt.html'>stdlib_ztpqrt</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpqrt2.html'>stdlib_ztpqrt2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztprfb.html'>stdlib_ztprfb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>conjugate transpose H**H to a complex matrix C, which is composed of two
blocks A and B, either from the left or right.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztprfs.html'>stdlib_ztprfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular packed
coefficient matrix.
The solution matrix X must be computed by ZTPTRS or some other
means before entering this routine.  ZTPRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpsv.html'>stdlib_ztpsv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix, supplied in packed form.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztptri.html'>stdlib_ztptri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A stored in packed format.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztptrs.html'>stdlib_ztptrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular matrix of order N stored in packed format,
and B is an N-by-NRHS matrix.  A check is made to verify that A is
nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpttf.html'>stdlib_ztpttf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztpttr.html'>stdlib_ztpttr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrcon.html'>stdlib_ztrcon</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrevc.html'>stdlib_ztrevc</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex upper triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a complex general matrix:  A = Q<em>T</em>Q<strong>H, as computed by ZHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix.  If Q is the unitary factor that reduces a matrix A to
Schur form T, then Q<em>X and Q</em>Y are the matrices of right and left
eigenvectors of A.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrevc3.html'>stdlib_ztrevc3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>a complex upper triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a complex general matrix:  A = Q<em>T</em>Q<strong>H, as computed by ZHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix. If Q is the unitary factor that reduces a matrix A to
Schur form T, then Q<em>X and Q</em>Y are the matrices of right and left
eigenvectors of A.
This uses a Level 3 BLAS version of the back transformation.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrexc.html'>stdlib_ztrexc</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q<strong>H, so that the diagonal element of T with row index IFST
is moved to row ILST.
The Schur form T is reordered by a unitary similarity transformation
Z</strong>H<em>T</em>Z, and optionally the matrix Q of Schur vectors is updated by
postmultplying it with Z.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrmm.html'>stdlib_ztrmm</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>B := alpha<em>op( A )</em>B,   or   B := alpha<em>B</em>op( A )
where  alpha  is a scalar,  B  is an m by n matrix,  A  is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A<strong>T   or   op( A ) = A</strong>H.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrmv.html'>stdlib_ztrmv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrrfs.html'>stdlib_ztrrfs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>solution to a system of linear equations with a triangular
coefficient matrix.
The solution matrix X must be computed by ZTRTRS or some other
means before entering this routine.  ZTRRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrsen.html'>stdlib_ztrsen</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A = Q<em>T</em>Q**H, so that a selected cluster of eigenvalues appears in
the leading positions on the diagonal of the upper triangular matrix
T, and the leading columns of Q form an orthonormal basis of the
corresponding right invariant subspace.
Optionally the routine computes the reciprocal condition numbers of
the cluster of eigenvalues and/or the invariant subspace.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrsm.html'>stdlib_ztrsm</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>op( A )<em>X = alpha</em>B,   or   X<em>op( A ) = alpha</em>B,
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A<strong>T   or   op( A ) = A</strong>H.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrsna.html'>stdlib_ztrsna</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>eigenvalues and/or right eigenvectors of a complex upper triangular
matrix T (or of any matrix Q<em>T</em>Q**H with Q unitary).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrsv.html'>stdlib_ztrsv</a></td><td><a href='../module/stdlib_linalg_blas_z.html'>stdlib_linalg_blas_z</a></td><td>Subroutine</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrsyl.html'>stdlib_ztrsyl</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>op(A)<em>X + X</em>op(B) = scale<em>C or
op(A)</em>X - X<em>op(B) = scale</em>C,
where op(A) = A or A**H, and A and B are both upper triangular. A is
M-by-M and B is N-by-N; the right hand side C and the solution X are
M-by-N; and scale is an output scale factor, set &lt;= 1 to avoid
overflow in X.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrti2.html'>stdlib_ztrti2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix.
This is the Level 2 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrtri.html'>stdlib_ztrtri</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix A.
This is the Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrtrs.html'>stdlib_ztrtrs</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular matrix of order N, and B is an N-by-NRHS
matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrttf.html'>stdlib_ztrttf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to rectangular full packed format (TF) .</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztrttp.html'>stdlib_ztrttp</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_ztzrzf.html'>stdlib_ztzrzf</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>to upper triangular form by means of unitary transformations.
The upper trapezoidal matrix A is factored as
A = ( R  0 ) * Z,
where Z is an N-by-N unitary matrix and R is an M-by-M upper
triangular matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb.html'>stdlib_zunbdb</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>partitioned unitary matrix X:
[ B11 | B12 0  0 ]
[ X11 | X12 ]   [ P1 |    ] [  0  |  0 -I  0 ] [ Q1 |    ]**H
X = [-----------] = [---------] [----------------] [---------]   .
[ X21 | X22 ]   [    | P2 ] [ B21 | B22 0  0 ] [    | Q2 ]
[  0  |  0  0  I ]
X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is
not the case, then X must be transposed and/or permuted. This can be
done in constant time using the TRANS and SIGNS options. See ZUNCSD
for details.)
The unitary matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by-
(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are
represented implicitly by Householder vectors.
B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb1.html'>stdlib_zunbdb1</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P,
M-P, or M-Q. Routines ZUNBDB2, ZUNBDB3, and ZUNBDB4 handle cases in
which Q is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb2.html'>stdlib_zunbdb2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P,
Q, or M-Q. Routines ZUNBDB1, ZUNBDB3, and ZUNBDB4 handle cases in
which P is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are P-by-P bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb3.html'>stdlib_zunbdb3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P,
Q, or M-Q. Routines ZUNBDB1, ZUNBDB2, and ZUNBDB4 handle cases in
which M-P is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb4.html'>stdlib_zunbdb4</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P,
M-P, or Q. Routines ZUNBDB1, ZUNBDB2, and ZUNBDB3 handle cases in
which M-Q is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb5.html'>stdlib_zunbdb5</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then some other vector from the orthogonal complement
is returned. This vector is chosen in an arbitrary but deterministic
way.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunbdb6.html'>stdlib_zunbdb6</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then the zero vector is returned.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zuncsd.html'>stdlib_zuncsd</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>unitary matrix X:
[  I  0  0 |  0  0  0 ]
[  0  C  0 |  0 -S  0 ]
[ X11 | X12 ]   [ U1 |    ] [  0  0  0 |  0  0 -I ] [ V1 |    ]**H
X = [-----------] = [---------] [---------------------] [---------]   .
[ X21 | X22 ]   [    | U2 ] [  0  0  0 |  I  0  0 ] [    | V2 ]
[  0  S  0 |  0  C  0 ]
[  0  0  I |  0  0  0 ]
X11 is P-by-Q. The unitary matrices U1, U2, V1, and V2 are P-by-P,
(M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are
R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in
which R = MIN(P,M-P,Q,M-Q).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zuncsd2by1.html'>stdlib_zuncsd2by1</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>orthonormal columns that has been partitioned into a 2-by-1 block
structure:
[  I1 0  0 ]
[  0  C  0 ]
[ X11 ]   [ U1 |    ] [  0  0  0 ]
X = [-----] = [---------] [----------] V1**T .
[ X21 ]   [    | U2 ] [  0  0  0 ]
[  0  S  0 ]
[  0  0  I2]
X11 is P-by-Q. The unitary matrices U1, U2, and V1 are P-by-P,
(M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R
nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which
R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a
K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zung2l.html'>stdlib_zung2l</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the last n columns of a product of k elementary
reflectors of order m
Q  =  H(k) . . . H(2) H(1)
as returned by ZGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zung2r.html'>stdlib_zung2r</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the first n columns of a product of k elementary
reflectors of order m
Q  =  H(1) H(2) . . . H(k)
as returned by ZGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungbr.html'>stdlib_zungbr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>determined by ZGEBRD when reducing a complex matrix A to bidiagonal
form: A = Q * B * P<strong>H.  Q and P</strong>H are defined as products of
elementary reflectors H(i) or G(i) respectively.
If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q
is of order M:
if m &gt;= k, Q = H(1) H(2) . . . H(k) and ZUNGBR returns the first n
columns of Q, where m &gt;= n &gt;= k;
if m &lt; k, Q = H(1) H(2) . . . H(m-1) and ZUNGBR returns Q as an
M-by-M matrix.
If VECT = 'P', A is assumed to have been a K-by-N matrix, and P<strong>H
is of order N:
if k &lt; n, P</strong>H = G(k) . . . G(2) G(1) and ZUNGBR returns the first m
rows of P<strong>H, where n &gt;= m &gt;= k;
if k &gt;= n, P</strong>H = G(n-1) . . . G(2) G(1) and ZUNGBR returns P**H as
an N-by-N matrix.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunghr.html'>stdlib_zunghr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>product of IHI-ILO elementary reflectors of order N, as returned by
ZGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungl2.html'>stdlib_zungl2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the first m rows of a product of k elementary
reflectors of order n
Q  =  H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by ZGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunglq.html'>stdlib_zunglq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the first M rows of a product of K elementary
reflectors of order N
Q  =  H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by ZGELQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungql.html'>stdlib_zungql</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the last N columns of a product of K elementary
reflectors of order M
Q  =  H(k) . . . H(2) H(1)
as returned by ZGEQLF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungqr.html'>stdlib_zungqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the first N columns of a product of K elementary
reflectors of order M
Q  =  H(1) H(2) . . . H(k)
as returned by ZGEQRF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungr2.html'>stdlib_zungr2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the last m rows of a product of k elementary
reflectors of order n
Q  =  H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by ZGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungrq.html'>stdlib_zungrq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>which is defined as the last M rows of a product of K elementary
reflectors of order N
Q  =  H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by ZGERQF.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungtr.html'>stdlib_zungtr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors of order N, as returned by
ZHETRD:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungtsqr.html'>stdlib_zungtsqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>columns, which are the first N columns of a product of comlpex unitary
matrices of order M which are returned by ZLATSQR
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
See the documentation for ZLATSQR.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zungtsqr_row.html'>stdlib_zungtsqr_row</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>orthonormal columns from the output of ZLATSQR. These N orthonormal
columns are the first N columns of a product of complex unitary
matrices Q(k)_in of order M, which are returned by ZLATSQR in
a special format.
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
The input matrices Q(k)_in are stored in row and column blocks in A.
See the documentation of ZLATSQR for more details on the format of
Q(k)_in, where each Q(k)_in is represented by block Householder
transformations. This routine calls an auxiliary routine ZLARFB_GETT,
where the computation is performed on each individual block. The
algorithm first sweeps NB-sized column blocks from the right to left
starting in the bottom row block and continues to the top row block
(hence _ROW in the routine name). This sweep is in reverse order of
the order in which ZLATSQR generates the output blocks.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunhr_col.html'>stdlib_zunhr_col</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>as input, stored in A, and performs Householder Reconstruction (HR),
i.e. reconstructs Householder vectors V(i) implicitly representing
another M-by-N matrix Q_out, with the property that Q_in = Q_out*S,
where S is an N-by-N diagonal matrix with diagonal entries
equal to +1 or -1. The Householder vectors (columns V(i) of V) are
stored in A on output, and the diagonal entries of S are stored in D.
Block reflectors are also returned in T
(same output format as ZGEQRT).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunm22.html'>stdlib_zunm22</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td></td></tr>
			   <tr><td><a href='../proc/stdlib_zunm2l.html'>stdlib_zunm2l</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by ZGEQLF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunm2r.html'>stdlib_zunm2r</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by ZGEQRF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmbr.html'>stdlib_zunmbr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>If VECT = 'Q', ZUNMBR: overwrites the general complex M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
If VECT = 'P', ZUNMBR overwrites the general complex M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      P * C          C * P
TRANS = 'C':      P<strong>H * C       C * P</strong>H
Here Q and P<strong>H are the unitary matrices determined by ZGEBRD when
reducing a complex matrix A to bidiagonal form: A = Q * B * P</strong>H. Q
and P<strong>H are defined as products of elementary reflectors H(i) and
G(i) respectively.
Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the
order of the unitary matrix Q or P</strong>H that is applied.
If VECT = 'Q', A is assumed to have been an NQ-by-K matrix:
if nq &gt;= k, Q = H(1) H(2) . . . H(k);
if nq &lt; k, Q = H(1) H(2) . . . H(nq-1).
If VECT = 'P', A is assumed to have been a K-by-NQ matrix:
if k &lt; nq, P = G(1) G(2) . . . G(k);
if k &gt;= nq, P = G(1) G(2) . . . G(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmhr.html'>stdlib_zunmhr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
IHI-ILO elementary reflectors, as returned by ZGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunml2.html'>stdlib_zunml2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by ZGELQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmlq.html'>stdlib_zunmlq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by ZGELQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmql.html'>stdlib_zunmql</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by ZGEQLF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmqr.html'>stdlib_zunmqr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by ZGEQRF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmr2.html'>stdlib_zunmr2</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by ZGERQF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmr3.html'>stdlib_zunmr3</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by ZTZRZF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmrq.html'>stdlib_zunmrq</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by ZGERQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmrz.html'>stdlib_zunmrz</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by ZTZRZF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zunmtr.html'>stdlib_zunmtr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by ZHETRD:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zupgtr.html'>stdlib_zupgtr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>product of n-1 elementary reflectors H(i) of order n, as returned by
ZHPTRD using packed storage:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../proc/stdlib_zupmtr.html'>stdlib_zupmtr</a></td><td><a href='../module/stdlib_linalg_lapack_z.html'>stdlib_linalg_lapack_z</a></td><td>Subroutine</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by ZHPTRD using packed
storage:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/stebz.html'>stebz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix T.  The user may ask for all eigenvalues, all eigenvalues
in the half-open interval (VL, VU], or the IL-th through IU-th
eigenvalues.
To avoid overflow, the matrix must be scaled so that its
largest element is no greater than overflow<strong>(1/2) * underflow</strong>(1/4) in absolute value, and for greatest
accuracy, it should not be much smaller than that.
See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
Matrix", Report CS41, Computer Science Dept., Stanford
University, July 21, 1966.</p></td></tr>
			   <tr><td><a href='../interface/stedc.html'>stedc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric tridiagonal matrix using the divide and conquer method.
The eigenvectors of a full or band complex Hermitian matrix can also
be found if CHETRD or CHPTRD or CHBTRD has been used to reduce this
matrix to tridiagonal form.
This code makes very mild assumptions about floating point
arithmetic. It will work on machines with a guard digit in
add/subtract, or on those binary machines without guard digits
which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2.
It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.  See SLAED3 for details.</p></td></tr>
			   <tr><td><a href='../interface/stegr.html'>stegr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
STEGR is a compatibility wrapper around the improved CSTEMR routine.
See SSTEMR for further details.
One important change is that the ABSTOL parameter no longer provides any
benefit and hence is no longer used.
Note : STEGR and CSTEMR work only on machines which follow
IEEE-754 floating-point standard in their handling of infinities and
NaNs.  Normal execution may create these exceptiona values and hence
may abort due to a floating point exception in environments which
do not conform to the IEEE-754 standard.</p></td></tr>
			   <tr><td><a href='../interface/stein.html'>stein</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix T corresponding to specified eigenvalues, using inverse
iteration.
The maximum number of iterations allowed for each eigenvector is
specified by an internal parameter MAXITS (currently set to 5).
Although the eigenvectors are real, they are stored in a complex
array, which may be passed to CUNMTR or CUPMTR for back
transformation to the eigenvectors of a complex Hermitian matrix
which was reduced to tridiagonal form.</p></td></tr>
			   <tr><td><a href='../interface/stemr.html'>stemr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real symmetric tridiagonal matrix T. Any such unreduced matrix has
a well defined set of pairwise different real eigenvalues, the corresponding
real eigenvectors are pairwise orthogonal.
The spectrum may be computed either completely or partially by specifying
either an interval (VL,VU] or a range of indices IL:IU for the desired
eigenvalues.
Depending on the number of desired eigenvalues, these are computed either
by bisection or the dqds algorithm. Numerically orthogonal eigenvectors are
computed by the use of various suitable L D L^T factorizations near clusters
of close eigenvalues (referred to as RRRs, Relatively Robust
Representations). An informal sketch of the algorithm follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
For more details, see:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Further Details
1.STEMR works only on machines which follow IEEE-754
floating-point standard in their handling of infinities and NaNs.
This permits the use of efficient inner loops avoiding a check for
zero divisors.
2. LAPACK routines can be used to reduce a complex Hermitean matrix to
real symmetric tridiagonal form.
(Any complex Hermitean tridiagonal matrix has real values on its diagonal
and potentially complex numbers on its off-diagonals. By applying a
similarity transform with an appropriate diagonal matrix
diag(1,e^{i \phy_1}, ... , e^{i \phy_{n-1}}), the complex Hermitean
matrix can be transformed into a real symmetric matrix and complex
arithmetic can be entirely avoided.)
While the eigenvectors of the real symmetric tridiagonal matrix are real,
the eigenvectors of original complex Hermitean matrix have complex entries
in general.
Since LAPACK drivers overwrite the matrix data with the eigenvectors,
STEMR accepts complex workspace to facilitate interoperability
with CUNMTR or CUPMTR.</p></td></tr>
			   <tr><td><a href='../interface/steqr.html'>steqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric tridiagonal matrix using the implicit QL or QR method.
The eigenvectors of a full or band complex Hermitian matrix can also
be found if CHETRD or CHPTRD or CHBTRD has been used to reduce this
matrix to tridiagonal form.</p></td></tr>
			   <tr><td><a href='../interface/sterf.html'>sterf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the Pal-Walker-Kahan variant of the QL or QR algorithm.</p></td></tr>
			   <tr><td><a href='../interface/stev.html'>stev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>real symmetric tridiagonal matrix A.</p></td></tr>
			   <tr><td><a href='../interface/stevd.html'>stevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>real symmetric tridiagonal matrix. If eigenvectors are desired, it
uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/stevr.html'>stevr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real symmetric tridiagonal matrix T.  Eigenvalues and
eigenvectors can be selected by specifying either a range of values
or a range of indices for the desired eigenvalues.
Whenever possible, STEVR calls DSTEMR to compute the
eigenspectrum using Relatively Robust Representations.  DSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows. For the i-th
unreduced block of T,
(a) Compute T - sigma_i = L_i D_i L_i^T, such that L_i D_i L_i^T
is a relatively robust representation,
(b) Compute the eigenvalues, lambda_j, of L_i D_i L_i^T to high
relative accuracy by the dqds algorithm,
(c) If there is a cluster of close eigenvalues, "choose" sigma_i
close to the cluster, and go to step (a),
(d) Given the approximate eigenvalue lambda_j of L_i D_i L_i^T,
compute the corresponding eigenvector by forming a
rank-revealing twisted factorization.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem", by Inderjit Dhillon,
Computer Science Division Technical Report No. UCB//CSD-97-971,
UC Berkeley, May 1997.
Note 1 : STEVR calls DSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
STEVR calls DSTEBZ and DSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of DSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../interface/string_type.html'>string_type</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Constructor for new string instances</p></td></tr>
			   <tr><td><a href='../interface/stringlist_type.html'>stringlist_type</a></td><td><a href='../module/stdlib_stringlist_type.html'>stdlib_stringlist_type</a></td><td>Interface</td><td><p>Constructor for stringlist
Returns an instance of type stringlist_type
<a href="../page/specs/stdlib_stringlist_type.html#stringlist_type">Specifications</a></p></td></tr>
			   <tr><td><a href='../interface/strip.html'>strip</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Remove leading and trailing whitespace characters.</p><a href="../interface/strip.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/swap.html'>swap</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>SWAP: interchanges two vectors.</p></td></tr>
			   <tr><td><a href='../interface/sycon.html'>sycon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSYTRF.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/sycon_rook.html'>sycon_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>1-norm) of a complex symmetric matrix A using the factorization
A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by CSYTRF_ROOK.
An estimate is obtained for norm(inv(A)), and the reciprocal of the
condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))).</p></td></tr>
			   <tr><td><a href='../interface/syconv.html'>syconv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Get Non-diag elements of D (returned in workspace) and
apply or reverse permutation done in TRF.</p></td></tr>
			   <tr><td><a href='../interface/syconvf.html'>syconvf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>If parameter WAY = 'C':
SYCONVF: converts the factorization output format used in
CSYTRF provided on entry in parameter A into the factorization
output format used in CSYTRF_RK (or CSYTRF_BK) that is stored
on exit in parameters A and E. It also converts in place details of
the intechanges stored in IPIV from the format used in CSYTRF into
the format used in CSYTRF_RK (or CSYTRF_BK).
If parameter WAY = 'R':
SYCONVF performs the conversion in reverse direction, i.e.
converts the factorization output format used in CSYTRF_RK
(or CSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in CSYTRF that is stored
on exit in parameter A. It also converts in place details of
the intechanges stored in IPIV from the format used in CSYTRF_RK
(or CSYTRF_BK) into the format used in CSYTRF.
SYCONVF can also convert in Hermitian matrix case, i.e. between
formats used in CHETRF and CHETRF_RK (or CHETRF_BK).</p></td></tr>
			   <tr><td><a href='../interface/syconvf_rook.html'>syconvf_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>If parameter WAY = 'C':
SYCONVF_ROOK: converts the factorization output format used in
CSYTRF_ROOK provided on entry in parameter A into the factorization
output format used in CSYTRF_RK (or CSYTRF_BK) that is stored
on exit in parameters A and E. IPIV format for CSYTRF_ROOK and
CSYTRF_RK (or CSYTRF_BK) is the same and is not converted.
If parameter WAY = 'R':
SYCONVF_ROOK performs the conversion in reverse direction, i.e.
converts the factorization output format used in CSYTRF_RK
(or CSYTRF_BK) provided on entry in parameters A and E into
the factorization output format used in CSYTRF_ROOK that is stored
on exit in parameter A. IPIV format for CSYTRF_ROOK and
CSYTRF_RK (or CSYTRF_BK) is the same and is not converted.
SYCONVF_ROOK can also convert in Hermitian matrix case, i.e. between
formats used in CHETRF_ROOK and CHETRF_RK (or CHETRF_BK).</p></td></tr>
			   <tr><td><a href='../interface/syequb.html'>syequb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric matrix A (with respect to the Euclidean norm) and reduce
its condition number. The scale factors S are computed by the BIN
algorithm (see references) so that the scaled matrix B with elements
B(i,j) = S(i)<em>A(i,j)</em>S(j) has a condition number within a factor N of
the smallest possible condition number over all possible diagonal
scalings.</p></td></tr>
			   <tr><td><a href='../interface/syev.html'>syev</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>real symmetric matrix A.</p></td></tr>
			   <tr><td><a href='../interface/syevd.html'>syevd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>real symmetric matrix A. If eigenvectors are desired, it uses a
divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.
Because of large use of BLAS of level 3, SYEVD needs N**2 more
workspace than DSYEVX.</p></td></tr>
			   <tr><td><a href='../interface/syevr.html'>syevr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real symmetric matrix A.  Eigenvalues and eigenvectors can be
selected by specifying either a range of values or a range of
indices for the desired eigenvalues.
SYEVR first reduces the matrix A to tridiagonal form T with a call
to DSYTRD.  Then, whenever possible, SYEVR calls DSTEMR to compute
the eigenspectrum using Relatively Robust Representations.  DSTEMR
computes eigenvalues by the dqds algorithm, while orthogonal
eigenvectors are computed from various "good" L D L^T representations
(also known as Relatively Robust Representations). Gram-Schmidt
orthogonalization is avoided as far as possible. More specifically,
the various steps of the algorithm are as follows.
For each unreduced block (submatrix) of T,
(a) Compute T - sigma I  = L D L^T, so that L and D
define all the wanted eigenvalues to high relative accuracy.
This means that small relative changes in the entries of D and L
cause only small relative changes in the eigenvalues and
eigenvectors. The standard (unfactored) representation of the
tridiagonal matrix T does not have this property in general.
(b) Compute the eigenvalues to suitable accuracy.
If the eigenvectors are desired, the algorithm attains full
accuracy of the computed eigenvalues only right before
the corresponding vectors have to be computed, see steps c) and d).
(c) For each cluster of close eigenvalues, select a new
shift close to the cluster, find a new factorization, and refine
the shifted eigenvalues to suitable accuracy.
(d) For each eigenvalue with a large enough relative separation compute
the corresponding eigenvector by forming a rank revealing twisted
factorization. Go back to (c) for any clusters that remain.
The desired accuracy of the output can be specified by the input
parameter ABSTOL.
For more details, see DSTEMR's documentation and:
- Inderjit S. Dhillon and Beresford N. Parlett: "Multiple representations
to compute orthogonal eigenvectors of symmetric tridiagonal matrices,"
Linear Algebra and its Applications, 387(1), pp. 1-28, August 2004.
- Inderjit Dhillon and Beresford Parlett: "Orthogonal Eigenvectors and
Relative Gaps," SIAM Journal on Matrix Analysis and Applications, Vol. 25,
2004.  Also LAPACK Working Note 154.
- Inderjit Dhillon: "A new O(n^2) algorithm for the symmetric
tridiagonal eigenvalue/eigenvector problem",
Computer Science Division Technical Report No. UCB/CSD-97-971,
UC Berkeley, May 1997.
Note 1 : SYEVR calls DSTEMR when the full spectrum is requested
on machines which conform to the ieee-754 floating point standard.
SYEVR calls DSTEBZ and DSTEIN on non-ieee machines and
when partial spectrum requests are made.
Normal execution of DSTEMR may create NaNs and infinities and
hence may abort due to a floating point exception in environments
which do not handle NaNs and infinities in the ieee standard default
manner.</p></td></tr>
			   <tr><td><a href='../interface/sygst.html'>sygst</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to standard form.
If ITYPE = 1, the problem is A<em>x = lambda</em>B<em>x,
and A is overwritten by inv(U</em><em>T)</em>A<em>inv(U) or inv(L)</em>A<em>inv(L</em><em>T)
If ITYPE = 2 or 3, the problem is A</em>B<em>x = lambda</em>x or
B<em>A</em>x = lambda<em>x, and A is overwritten by U</em>A<em>U</em><em>T or L</em><em>T</em>A<em>L.
B must have been previously factorized as U</em><em>T</em>U or L<em>L</em>*T by DPOTRF.</p></td></tr>
			   <tr><td><a href='../interface/sygv.html'>sygv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.
Here A and B are assumed to be symmetric and B is also
positive definite.</p></td></tr>
			   <tr><td><a href='../interface/sygvd.html'>sygvd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of a real generalized symmetric-definite eigenproblem, of the form
A<em>x=(lambda)</em>B<em>x,  A</em>Bx=(lambda)<em>x,  or B</em>A<em>x=(lambda)</em>x.  Here A and
B are assumed to be symmetric and B is also positive definite.
If eigenvectors are desired, it uses a divide and conquer algorithm.
The divide and conquer algorithm makes very mild assumptions about
floating point arithmetic. It will work on machines with a guard
digit in add/subtract, or on those binary machines without guard
digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or
Cray-2. It could conceivably fail on hexadecimal or decimal machines
without guard digits, but we know of none.</p></td></tr>
			   <tr><td><a href='../interface/symm.html'>symm</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>A</em>B + beta<em>C,
or
C := alpha</em>B<em>A + beta</em>C,
where  alpha and beta are scalars, A is a symmetric matrix and  B and
C are m by n matrices.</p></td></tr>
			   <tr><td><a href='../interface/symv.html'>symv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../interface/symv~2.html'>symv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>y := alpha<em>A</em>x + beta*y,
where alpha and beta are scalars, x and y are n element vectors and
A is an n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../interface/syr.html'>syr</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>x**T + A,
where alpha is a real scalar, x is an n element vector and A is an
n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../interface/syr~2.html'>syr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A := alpha<em>x</em>x**H + A,
where alpha is a complex scalar, x is an n element vector and A is an
n by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../interface/syr2.html'>syr2</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A := alpha<em>x</em>y<strong>T + alpha<em>y</em>x</strong>T + A,
where alpha is a scalar, x and y are n element vectors and A is an n
by n symmetric matrix.</p></td></tr>
			   <tr><td><a href='../interface/syr2k.html'>syr2k</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>A</em>B<strong>T + alpha<em>B</em>A</strong>T + beta<em>C,
or
C := alpha</em>A<strong>T<em>B + alpha</em>B</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars,  C is an  n by n symmetric matrix
and  A and B  are  n by k  matrices  in the  first  case  and  k by n
matrices in the second case.</p></td></tr>
			   <tr><td><a href='../interface/syrfs.html'>syrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations when the coefficient matrix is symmetric indefinite, and
provides error bounds and backward error estimates for the solution.</p></td></tr>
			   <tr><td><a href='../interface/syrk.html'>syrk</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>C := alpha<em>A</em>A<strong>T + beta<em>C,
or
C := alpha</em>A</strong>T<em>A + beta</em>C,
where  alpha and beta  are scalars,  C is an  n by n symmetric matrix
and  A  is an  n by k  matrix in the first case and a  k by n  matrix
in the second case.</p></td></tr>
			   <tr><td><a href='../interface/sysv.html'>sysv</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.  The factored form of A is then
used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/sysv_aa.html'>sysv_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>CSYSV computes the solution to a complex system of linear equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
Aasen's algorithm is used to factor A as
A = U<strong>T * T * U,  if UPLO = 'U', or
A = L * T * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is symmetric tridiagonal. The factored
form of A is then used to solve the system of equations A * X = B.</p></td></tr>
			   <tr><td><a href='../interface/sysv_rk.html'>sysv_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations A * X = B, where A is an N-by-N symmetric matrix
and X and B are N-by-NRHS matrices.
The bounded Bunch-Kaufman (rook) diagonal pivoting method is used
to factor A as
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T),  if UPLO = 'U', or
A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),  if UPLO = 'L',
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
CSYTRF_RK is called to compute the factorization of a complex
symmetric matrix.  The factored form of A is then used to solve
the system of equations A * X = B by calling BLAS3 routine CSYTRS_3.</p></td></tr>
			   <tr><td><a href='../interface/sysv_rook.html'>sysv_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>equations
A * X = B,
where A is an N-by-N symmetric matrix and X and B are N-by-NRHS
matrices.
The diagonal pivoting method is used to factor A as
A = U * D * U<strong>T,  if UPLO = 'U', or
A = L * D * L</strong>T,  if UPLO = 'L',
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
CSYTRF_ROOK is called to compute the factorization of a complex
symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal
pivoting method.
The factored form of A is then used to solve the system
of equations A * X = B by calling CSYTRS_ROOK.</p></td></tr>
			   <tr><td><a href='../interface/syswapr.html'>syswapr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a symmetric matrix.</p></td></tr>
			   <tr><td><a href='../interface/sytf2_rk.html'>sytf2_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../interface/sytf2_rook.html'>sytf2_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method:
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, U**T is the transpose of U, and D is symmetric and
block diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the unblocked version of the algorithm, calling Level 2 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/sytrd.html'>sytrd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal form T by an orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/sytrd_sb2st.html'>sytrd_sb2st</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>tridiagonal form T by a orthogonal similarity transformation:
Q**T * A * Q = T.</p></td></tr>
			   <tr><td><a href='../interface/sytrd_sy2sb.html'>sytrd_sy2sb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>band-diagonal form AB by a orthogonal similarity transformation:
Q**T * A * Q = AB.</p></td></tr>
			   <tr><td><a href='../interface/sytrf.html'>sytrf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the Bunch-Kaufman diagonal pivoting method.  The form of the
factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/sytrf_aa.html'>sytrf_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the Aasen's algorithm.  The form of the factorization is
A = U<strong>T<em>T</em>U  or  A = L<em>T</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and T is a complex symmetric tridiagonal matrix.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/sytrf_rk.html'>sytrf_rk</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman (rook) diagonal pivoting method:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.
For more information see Further Details section.</p></td></tr>
			   <tr><td><a href='../interface/sytrf_rook.html'>sytrf_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>using the bounded Bunch-Kaufman ("rook") diagonal pivoting method.
The form of the factorization is
A = U<em>D</em>U<strong>T  or  A = L<em>D</em>L</strong>T
where U (or L) is a product of permutation and unit upper (lower)
triangular matrices, and D is symmetric and block diagonal with
1-by-1 and 2-by-2 diagonal blocks.
This is the blocked version of the algorithm, calling Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/sytri.html'>sytri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T computed by
CSYTRF.</p></td></tr>
			   <tr><td><a href='../interface/sytri_rook.html'>sytri_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A using the factorization A = U<em>D</em>U<strong>T or A = L<em>D</em>L</strong>T
computed by CSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../interface/sytrs.html'>sytrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSYTRF.</p></td></tr>
			   <tr><td><a href='../interface/sytrs2.html'>sytrs2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSYTRF and converted by CSYCONV.</p></td></tr>
			   <tr><td><a href='../interface/sytrs_3.html'>sytrs_3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric matrix A using the factorization computed
by CSYTRF_RK or CSYTRF_BK:
A = P<em>U</em>D<em>(U</em><em>T)</em>(P<strong>T) or A = P<em>L</em>D*(L</strong>T)<em>(P</em><em>T),
where U (or L) is unit upper (or lower) triangular matrix,
U</em><em>T (or L</em><em>T) is the transpose of U (or L), P is a permutation
matrix, P</em>*T is the transpose of P, and D is symmetric and block
diagonal with 1-by-1 and 2-by-2 diagonal blocks.
This algorithm is using Level 3 BLAS.</p></td></tr>
			   <tr><td><a href='../interface/sytrs_aa.html'>sytrs_aa</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>symmetric matrix A using the factorization A = U<strong>T<em>T</em>U or
A = L<em>T</em>L</strong>T computed by CSYTRF_AA.</p></td></tr>
			   <tr><td><a href='../interface/sytrs_rook.html'>sytrs_rook</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex symmetric matrix A using the factorization A = U<em>D</em>U<strong>T or
A = L<em>D</em>L</strong>T computed by CSYTRF_ROOK.</p></td></tr>
			   <tr><td><a href='../interface/tbcon.html'>tbcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>triangular band matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../interface/tbmv.html'>tbmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular band matrix, with ( k + 1 ) diagonals.</p></td></tr>
			   <tr><td><a href='../interface/tbrfs.html'>tbrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>solution to a system of linear equations with a triangular band
coefficient matrix.
The solution matrix X must be computed by CTBTRS or some other
means before entering this routine.  TBRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../interface/tbsv.html'>tbsv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular band matrix, with ( k + 1 )
diagonals.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../interface/tbtrs.html'>tbtrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular band matrix of order N, and B is an
N-by-NRHS matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../interface/tfsm.html'>tfsm</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Level 3 BLAS like routine for A in RFP Format.
TFSM: solves the matrix equation
op( A )<em>X = alpha</em>B  or  X<em>op( A ) = alpha</em>B
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A**H.
A is in Rectangular Full Packed (RFP) Format.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../interface/tftri.html'>tftri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>format.
This is a Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../interface/tfttp.html'>tfttp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>format (TF) to standard packed format (TP).</p></td></tr>
			   <tr><td><a href='../interface/tfttr.html'>tfttr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>format (TF) to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../interface/tgevc.html'>tgevc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a pair of complex matrices (S,P), where S and P are upper triangular.
Matrix pairs of this type are produced by the generalized Schur
factorization of a complex matrix pair (A,B):
A = Q<em>S</em>Z<strong>H,  B = Q<em>P</em>Z</strong>H
as computed by CGGHRD + CHGEQZ.
The right eigenvector x and the left eigenvector y of (S,P)
corresponding to an eigenvalue w are defined by:
S<em>x = w</em>P<em>x,  (y</em><em>H)</em>S = w<em>(y</em><em>H)</em>P,
where y<em><em>H denotes the conjugate tranpose of y.
The eigenvalues are not input to this routine, but are computed
directly from the diagonal elements of S and P.
This routine returns the matrices X and/or Y of right and left
eigenvectors of (S,P), or the products Z</em>X and/or Q</em>Y,
where Z and Q are input matrices.
If Q and Z are the unitary factors from the generalized Schur
factorization of a matrix pair (A,B), then Z<em>X and Q</em>Y
are the matrices of right and left eigenvectors of (A,B).</p></td></tr>
			   <tr><td><a href='../interface/tgexc.html'>tgexc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix pair (A,B), using an unitary equivalence transformation
(A, B) := Q * (A, B) * Z<strong>H, so that the diagonal block of (A, B) with
row index IFST is moved to row ILST.
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.
Optionally, the matrices Q and Z of generalized Schur vectors are
updated.
Q(in) * A(in) * Z(in)</strong>H = Q(out) * A(out) * Z(out)<strong>H
Q(in) * B(in) * Z(in)</strong>H = Q(out) * B(out) * Z(out)**H</p></td></tr>
			   <tr><td><a href='../interface/tgsen.html'>tgsen</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix pair (A, B) (in terms of an unitary equivalence trans-
formation Q**H * (A, B) * Z), so that a selected cluster of eigenvalues
appears in the leading diagonal blocks of the pair (A,B). The leading
columns of Q and Z form unitary bases of the corresponding left and
right eigenspaces (deflating subspaces). (A, B) must be in
generalized Schur canonical form, that is, A and B are both upper
triangular.
TGSEN also computes the generalized eigenvalues
w(j)= ALPHA(j) / BETA(j)
of the reordered matrix pair (A, B).
Optionally, the routine computes estimates of reciprocal condition
numbers for eigenvalues and eigenspaces. These are Difu[(A11,B11),
(A22,B22)] and Difl[(A11,B11), (A22,B22)], i.e. the separation(s)
between the matrix pairs (A11, B11) and (A22,B22) that correspond to
the selected cluster and the eigenvalues outside the cluster, resp.,
and norms of "projections" onto left and right eigenspaces w.r.t.
the selected cluster in the (1,1)-block.</p></td></tr>
			   <tr><td><a href='../interface/tgsja.html'>tgsja</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>of two complex upper triangular (or trapezoidal) matrices A and B.
On entry, it is assumed that matrices A and B have the following
forms, which may be obtained by the preprocessing subroutine CGGSVP
from a general M-by-N matrix A and P-by-N matrix B:
N-K-L  K    L
A =    K ( 0    A12  A13 ) if M-K-L &gt;= 0;
L ( 0     0   A23 )
M-K-L ( 0     0    0  )
N-K-L  K    L
A =  K ( 0    A12  A13 ) if M-K-L &lt; 0;
M-K ( 0     0   A23 )
N-K-L  K    L
B =  L ( 0     0   B13 )
P-L ( 0     0    0  )
where the K-by-K matrix A12 and L-by-L matrix B13 are nonsingular
upper triangular; A23 is L-by-L upper triangular if M-K-L &gt;= 0,
otherwise A23 is (M-K)-by-L upper trapezoidal.
On exit,
U<strong>H <em>A</em>Q = D1*( 0 R ),    V</strong>H <em>B</em>Q = D2<em>( 0 R ),
where U, V and Q are unitary matrices.
R is a nonsingular upper triangular matrix, and D1
and D2 are ``diagonal'' matrices, which are of the following
structures:
If M-K-L &gt;= 0,
K  L
D1 =     K ( I  0 )
L ( 0  C )
M-K-L ( 0  0 )
K  L
D2 = L   ( 0  S )
P-L ( 0  0 )
N-K-L  K    L
( 0 R ) = K (  0   R11  R12 ) K
L (  0    0   R22 ) L
where
C = diag( ALPHA(K+1), ... , ALPHA(K+L) ),
S = diag( BETA(K+1),  ... , BETA(K+L) ),
C</em><em>2 + S</em><em>2 = I.
R is stored in A(1:K+L,N-K-L+1:N) on exit.
If M-K-L &lt; 0,
K M-K K+L-M
D1 =   K ( I  0    0   )
M-K ( 0  C    0   )
K M-K K+L-M
D2 =   M-K ( 0  S    0   )
K+L-M ( 0  0    I   )
P-L ( 0  0    0   )
N-K-L  K   M-K  K+L-M
( 0 R ) =    K ( 0    R11  R12  R13  )
M-K ( 0     0   R22  R23  )
K+L-M ( 0     0    0   R33  )
where
C = diag( ALPHA(K+1), ... , ALPHA(M) ),
S = diag( BETA(K+1),  ... , BETA(M) ),
C</em><em>2 + S</em>*2 = I.
R = ( R11 R12 R13 ) is stored in A(1:M, N-K-L+1:N) and R33 is stored
(  0  R22 R23 )
in B(M-K+1:L,N+M-K-L+1:N) on exit.
The computation of the unitary transformation matrices U, V or Q
is optional.  These matrices may either be formed explicitly, or they
may be postmultiplied into input matrices U1, V1, or Q1.</p></td></tr>
			   <tr><td><a href='../interface/tgsna.html'>tgsna</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvalues and/or eigenvectors of a matrix pair (A, B).
(A, B) must be in generalized Schur canonical form, that is, A and
B are both upper triangular.</p></td></tr>
			   <tr><td><a href='../interface/tgsyl.html'>tgsyl</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * R - L * B = scale * C            (1)
D * R - L * E = scale * F
where R and L are unknown m-by-n matrices, (A, D), (B, E) and
(C, F) are given matrix pairs of size m-by-m, n-by-n and m-by-n,
respectively, with complex entries. A, B, D and E are upper
triangular (i.e., (A,D) and (B,E) in generalized Schur form).
The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1
is an output scaling factor chosen to avoid overflow.
In matrix notation (1) is equivalent to solve Zx = scale<em>b, where Z
is defined as
Z = [ kron(In, A)  -kron(B</em><em>H, Im) ]        (2)
[ kron(In, D)  -kron(E</em><em>H, Im) ],
Here Ix is the identity matrix of size x and X</em><em>H is the conjugate
transpose of X. Kron(X, Y) is the Kronecker product between the
matrices X and Y.
If TRANS = 'C', y in the conjugate transposed system Z</em><em>H </em>y = scale<em>b
is solved for, which is equivalent to solve for R and L in
A</em><em>H * R + D</em><em>H * L = scale * C           (3)
R * B</em><em>H + L * E</em>*H = scale * -F
This case (TRANS = 'C') is used to compute an one-norm-based estimate
of Dif[(A,D), (B,E)], the separation between the matrix pairs (A,D)
and (B,E), using CLACON.
If IJOB &gt;= 1, TGSYL computes a Frobenius norm-based estimate of
Dif[(A,D),(B,E)]. That is, the reciprocal of a lower bound on the
reciprocal of the smallest singular value of Z.
This is a level-3 BLAS algorithm.</p></td></tr>
			   <tr><td><a href='../interface/to_lower.html'>to_lower</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the lowercase version of the character sequence hold by the input string</p><a href="../interface/to_lower.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/to_lower.html'>to_lower</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Convert character variable to lower case
(<a href="../page/specs/stdlib_ascii.html#to_lower">Specification</a>)</p><a href="../proc/to_lower.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/to_sentence.html'>to_sentence</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the sentencecase version of the character sequence hold by the input string</p><a href="../interface/to_sentence.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/to_sentence.html'>to_sentence</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Converts character sequence to sentence case
(<a href="../page/specs/stdlib_ascii.html#to_sentence">Specification</a>)</p><a href="../proc/to_sentence.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/to_string.html'>to_string</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Format or transfer other types as a string.
(<a href="../page/specs/stdlib_strings.html#to_string">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/to_string~2.html'>to_string</a></td><td><a href='../module/stdlib_ansi.html'>stdlib_ansi</a></td><td>Interface</td><td></td></tr>
			   <tr><td><a href='../interface/to_title.html'>to_title</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the titlecase version of the character sequence hold by the input string</p><a href="../interface/to_title.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/to_title.html'>to_title</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Converts character sequence to title case
(<a href="../page/specs/stdlib_ascii.html#to_title">Specification</a>)</p><a href="../proc/to_title.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/to_upper.html'>to_upper</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the uppercase version of the character sequence hold by the input string</p><a href="../interface/to_upper.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../proc/to_upper.html'>to_upper</a></td><td><a href='../module/stdlib_ascii.html'>stdlib_ascii</a></td><td>Function</td><td><p>Convert character variable to upper case
(<a href="../page/specs/stdlib_ascii.html#to_upper">Specification</a>)</p><a href="../proc/to_upper.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/tpcon.html'>tpcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../interface/tplqt.html'>tplqt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../interface/tplqt2.html'>tplqt2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../interface/tpmlqt.html'>tpmlqt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>"triangular-pentagonal" complex block reflector H to a general
complex matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../interface/tpmqrt.html'>tpmqrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>"triangular-pentagonal" complex block reflector H to a general
complex matrix C, which consists of two blocks A and B.</p></td></tr>
			   <tr><td><a href='../interface/tpmv.html'>tpmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix, supplied in packed form.</p></td></tr>
			   <tr><td><a href='../interface/tpqrt.html'>tpqrt</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>"triangular-pentagonal" matrix C, which is composed of a
triangular block A and pentagonal block B, using the compact
WY representation for Q.</p></td></tr>
			   <tr><td><a href='../interface/tpqrt2.html'>tpqrt2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix C, which is composed of a triangular block A and pentagonal block B,
using the compact WY representation for Q.</p></td></tr>
			   <tr><td><a href='../interface/tprfb.html'>tprfb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>conjugate transpose H**H to a complex matrix C, which is composed of two
blocks A and B, either from the left or right.</p></td></tr>
			   <tr><td><a href='../interface/tprfs.html'>tprfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>solution to a system of linear equations with a triangular packed
coefficient matrix.
The solution matrix X must be computed by CTPTRS or some other
means before entering this routine.  TPRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../interface/tpsv.html'>tpsv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix, supplied in packed form.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../interface/tptri.html'>tptri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A stored in packed format.</p></td></tr>
			   <tr><td><a href='../interface/tptrs.html'>tptrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular matrix of order N stored in packed format,
and B is an N-by-NRHS matrix.  A check is made to verify that A is
nonsingular.</p></td></tr>
			   <tr><td><a href='../interface/tpttf.html'>tpttf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to rectangular full packed format (TF).</p></td></tr>
			   <tr><td><a href='../interface/tpttr.html'>tpttr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to standard full format (TR).</p></td></tr>
			   <tr><td><a href='../interface/trace.html'>trace</a></td><td><a href='../module/stdlib_linalg.html'>stdlib_linalg</a></td><td>Interface</td><td><p>Computes the trace of a matrix
(<a href="../page/specs/stdlib_linalg.html#
trace-trace-of-a-matrix">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/trapz.html'>trapz</a></td><td><a href='../module/stdlib_quadrature.html'>stdlib_quadrature</a></td><td>Interface</td><td><p>Integrates sampled values using trapezoidal rule
(<a href="../page/specs/stdlib_quadrature.html#description">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/trapz_weights.html'>trapz_weights</a></td><td><a href='../module/stdlib_quadrature.html'>stdlib_quadrature</a></td><td>Interface</td><td><p>Integrates sampled values using trapezoidal rule weights for given abscissas
(<a href="../page/specs/stdlib_quadrature.html#description_1">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/trcon.html'>trcon</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>triangular matrix A, in either the 1-norm or the infinity-norm.
The norm of A is computed and an estimate is obtained for
norm(inv(A)), then the reciprocal of the condition number is
computed as
RCOND = 1 / ( norm(A) * norm(inv(A)) ).</p></td></tr>
			   <tr><td><a href='../interface/trevc.html'>trevc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex upper triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a complex general matrix:  A = Q<em>T</em>Q<strong>H, as computed by CHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix.  If Q is the unitary factor that reduces a matrix A to
Schur form T, then Q<em>X and Q</em>Y are the matrices of right and left
eigenvectors of A.</p></td></tr>
			   <tr><td><a href='../interface/trevc3.html'>trevc3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>a complex upper triangular matrix T.
Matrices of this type are produced by the Schur factorization of
a complex general matrix:  A = Q<em>T</em>Q<strong>H, as computed by CHSEQR.
The right eigenvector x and the left eigenvector y of T corresponding
to an eigenvalue w are defined by:
T<em>x = w</em>x,     (y</strong>H)<em>T = w</em>(y<strong>H)
where y</strong>H denotes the conjugate transpose of the vector y.
The eigenvalues are not input to this routine, but are read directly
from the diagonal of T.
This routine returns the matrices X and/or Y of right and left
eigenvectors of T, or the products Q<em>X and/or Q</em>Y, where Q is an
input matrix. If Q is the unitary factor that reduces a matrix A to
Schur form T, then Q<em>X and Q</em>Y are the matrices of right and left
eigenvectors of A.
This uses a Level 3 BLAS version of the back transformation.</p></td></tr>
			   <tr><td><a href='../interface/trexc.html'>trexc</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = Q<em>T</em>Q<strong>H, so that the diagonal element of T with row index IFST
is moved to row ILST.
The Schur form T is reordered by a unitary similarity transformation
Z</strong>H<em>T</em>Z, and optionally the matrix Q of Schur vectors is updated by
postmultplying it with Z.</p></td></tr>
			   <tr><td><a href='../interface/trim.html'>trim</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Returns the character sequence hold by the string without trailing spaces.</p><a href="../interface/trim.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/trmm.html'>trmm</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>B := alpha<em>op( A )</em>B,   or   B := alpha<em>B</em>op( A )
where  alpha  is a scalar,  B  is an m by n matrix,  A  is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A<strong>T   or   op( A ) = A</strong>H.</p></td></tr>
			   <tr><td><a href='../interface/trmv.html'>trmv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>x := A<em>x,   or   x := A</em><em>T</em>x,   or   x := A*<em>H</em>x,
where x is an n element vector and  A is an n by n unit, or non-unit,
upper or lower triangular matrix.</p></td></tr>
			   <tr><td><a href='../interface/trrfs.html'>trrfs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>solution to a system of linear equations with a triangular
coefficient matrix.
The solution matrix X must be computed by CTRTRS or some other
means before entering this routine.  TRRFS does not do iterative
refinement because doing so cannot improve the backward error.</p></td></tr>
			   <tr><td><a href='../interface/trsen.html'>trsen</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A = Q<em>T</em>Q**H, so that a selected cluster of eigenvalues appears in
the leading positions on the diagonal of the upper triangular matrix
T, and the leading columns of Q form an orthonormal basis of the
corresponding right invariant subspace.
Optionally the routine computes the reciprocal condition numbers of
the cluster of eigenvalues and/or the invariant subspace.</p></td></tr>
			   <tr><td><a href='../interface/trsm.html'>trsm</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>op( A )<em>X = alpha</em>B,   or   X<em>op( A ) = alpha</em>B,
where alpha is a scalar, X and B are m by n matrices, A is a unit, or
non-unit,  upper or lower triangular matrix  and  op( A )  is one  of
op( A ) = A   or   op( A ) = A<strong>T   or   op( A ) = A</strong>H.
The matrix X is overwritten on B.</p></td></tr>
			   <tr><td><a href='../interface/trsna.html'>trsna</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>eigenvalues and/or right eigenvectors of a complex upper triangular
matrix T (or of any matrix Q<em>T</em>Q**H with Q unitary).</p></td></tr>
			   <tr><td><a href='../interface/trsv.html'>trsv</a></td><td><a href='../module/stdlib_linalg_blas.html'>stdlib_linalg_blas</a></td><td>Interface</td><td><p>A<em>x = b,   or   A</em><em>T</em>x = b,   or   A*<em>H</em>x = b,
where b and x are n element vectors and A is an n by n unit, or
non-unit, upper or lower triangular matrix.
No test for singularity or near-singularity is included in this
routine. Such tests must be performed before calling this routine.</p></td></tr>
			   <tr><td><a href='../interface/trsyl.html'>trsyl</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>op(A)<em>X + X</em>op(B) = scale<em>C or
op(A)</em>X - X<em>op(B) = scale</em>C,
where op(A) = A or A**H, and A and B are both upper triangular. A is
M-by-M and B is N-by-N; the right hand side C and the solution X are
M-by-N; and scale is an output scale factor, set &lt;= 1 to avoid
overflow in X.</p></td></tr>
			   <tr><td><a href='../interface/trtri.html'>trtri</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix A.
This is the Level 3 BLAS version of the algorithm.</p></td></tr>
			   <tr><td><a href='../interface/trtrs.html'>trtrs</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>A * X = B,  A<strong>T * X = B,  or  A</strong>H * X = B,
where A is a triangular matrix of order N, and B is an N-by-NRHS
matrix.  A check is made to verify that A is nonsingular.</p></td></tr>
			   <tr><td><a href='../interface/trttf.html'>trttf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to rectangular full packed format (TF) .</p></td></tr>
			   <tr><td><a href='../interface/trttp.html'>trttp</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>packed format (TP).</p></td></tr>
			   <tr><td><a href='../proc/trueloc.html'>trueloc</a></td><td><a href='../module/stdlib_array.html'>stdlib_array</a></td><td>Function</td><td><p>Return the positions of the true elements in array.
<a href="../page/specs/stdlib_array.html#trueloc">Specification</a></p></td></tr>
			   <tr><td><a href='../interface/tzrzf.html'>tzrzf</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>to upper triangular form by means of unitary transformations.
The upper trapezoidal matrix A is factored as
A = ( R  0 ) * Z,
where Z is an N-by-N unitary matrix and R is an M-by-M upper
triangular matrix.</p></td></tr>
			   <tr><td><a href='../interface/unbdb.html'>unbdb</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>partitioned unitary matrix X:
[ B11 | B12 0  0 ]
[ X11 | X12 ]   [ P1 |    ] [  0  |  0 -I  0 ] [ Q1 |    ]**H
X = [-----------] = [---------] [----------------] [---------]   .
[ X21 | X22 ]   [    | P2 ] [ B21 | B22 0  0 ] [    | Q2 ]
[  0  |  0  0  I ]
X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is
not the case, then X must be transposed and/or permuted. This can be
done in constant time using the TRANS and SIGNS options. See CUNCSD
for details.)
The unitary matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by-
(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are
represented implicitly by Householder vectors.
B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/unbdb1.html'>unbdb1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P,
M-P, or M-Q. Routines CUNBDB2, CUNBDB3, and CUNBDB4 handle cases in
which Q is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/unbdb2.html'>unbdb2</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P,
Q, or M-Q. Routines CUNBDB1, CUNBDB3, and CUNBDB4 handle cases in
which P is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are P-by-P bidiagonal matrices represented implicitly by
angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/unbdb3.html'>unbdb3</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P,
Q, or M-Q. Routines CUNBDB1, CUNBDB2, and CUNBDB4 handle cases in
which M-P is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/unbdb4.html'>unbdb4</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>matrix X with orthonomal columns:
[ B11 ]
[ X11 ]   [ P1 |    ] [  0  ]
[-----] = [---------] [-----] Q1**T .
[ X21 ]   [    | P2 ] [ B21 ]
[  0  ]
X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P,
M-P, or Q. Routines CUNBDB1, CUNBDB2, and CUNBDB3 handle cases in
which M-Q is not the minimum dimension.
The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P),
and (M-Q)-by-(M-Q), respectively. They are represented implicitly by
Householder vectors.
B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented
implicitly by angles THETA, PHI.</p></td></tr>
			   <tr><td><a href='../interface/unbdb5.html'>unbdb5</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then some other vector from the orthogonal complement
is returned. This vector is chosen in an arbitrary but deterministic
way.</p></td></tr>
			   <tr><td><a href='../interface/unbdb6.html'>unbdb6</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>X = [ X1 ]
[ X2 ]
with respect to the columns of
Q = [ Q1 ] .
[ Q2 ]
The columns of Q must be orthonormal.
If the projection is zero according to Kahan's "twice is enough"
criterion, then the zero vector is returned.</p></td></tr>
			   <tr><td><a href='../interface/uncsd.html'>uncsd</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>unitary matrix X:
[  I  0  0 |  0  0  0 ]
[  0  C  0 |  0 -S  0 ]
[ X11 | X12 ]   [ U1 |    ] [  0  0  0 |  0  0 -I ] [ V1 |    ]**H
X = [-----------] = [---------] [---------------------] [---------]   .
[ X21 | X22 ]   [    | U2 ] [  0  0  0 |  I  0  0 ] [    | V2 ]
[  0  S  0 |  0  C  0 ]
[  0  0  I |  0  0  0 ]
X11 is P-by-Q. The unitary matrices U1, U2, V1, and V2 are P-by-P,
(M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are
R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in
which R = MIN(P,M-P,Q,M-Q).</p></td></tr>
			   <tr><td><a href='../interface/uncsd2by1.html'>uncsd2by1</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>orthonormal columns that has been partitioned into a 2-by-1 block
structure:
[  I1 0  0 ]
[  0  C  0 ]
[ X11 ]   [ U1 |    ] [  0  0  0 ]
X = [-----] = [---------] [----------] V1**T .
[ X21 ]   [    | U2 ] [  0  0  0 ]
[  0  S  0 ]
[  0  0  I2]
X11 is P-by-Q. The unitary matrices U1, U2, and V1 are P-by-P,
(M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R
nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which
R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a
K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0).</p></td></tr>
			   <tr><td><a href='../interface/ung2l.html'>ung2l</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the last n columns of a product of k elementary
reflectors of order m
Q  =  H(k) . . . H(2) H(1)
as returned by CGEQLF.</p></td></tr>
			   <tr><td><a href='../interface/ung2r.html'>ung2r</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the first n columns of a product of k elementary
reflectors of order m
Q  =  H(1) H(2) . . . H(k)
as returned by CGEQRF.</p></td></tr>
			   <tr><td><a href='../interface/ungbr.html'>ungbr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>determined by CGEBRD when reducing a complex matrix A to bidiagonal
form: A = Q * B * P<strong>H.  Q and P</strong>H are defined as products of
elementary reflectors H(i) or G(i) respectively.
If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q
is of order M:
if m &gt;= k, Q = H(1) H(2) . . . H(k) and UNGBR returns the first n
columns of Q, where m &gt;= n &gt;= k;
if m &lt; k, Q = H(1) H(2) . . . H(m-1) and UNGBR returns Q as an
M-by-M matrix.
If VECT = 'P', A is assumed to have been a K-by-N matrix, and P<strong>H
is of order N:
if k &lt; n, P</strong>H = G(k) . . . G(2) G(1) and UNGBR returns the first m
rows of P<strong>H, where n &gt;= m &gt;= k;
if k &gt;= n, P</strong>H = G(n-1) . . . G(2) G(1) and UNGBR returns P**H as
an N-by-N matrix.</p></td></tr>
			   <tr><td><a href='../interface/unghr.html'>unghr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>product of IHI-ILO elementary reflectors of order N, as returned by
CGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../interface/unglq.html'>unglq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the first M rows of a product of K elementary
reflectors of order N
Q  =  H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by CGELQF.</p></td></tr>
			   <tr><td><a href='../interface/ungql.html'>ungql</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the last N columns of a product of K elementary
reflectors of order M
Q  =  H(k) . . . H(2) H(1)
as returned by CGEQLF.</p></td></tr>
			   <tr><td><a href='../interface/ungqr.html'>ungqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the first N columns of a product of K elementary
reflectors of order M
Q  =  H(1) H(2) . . . H(k)
as returned by CGEQRF.</p></td></tr>
			   <tr><td><a href='../interface/ungrq.html'>ungrq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>which is defined as the last M rows of a product of K elementary
reflectors of order N
Q  =  H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by CGERQF.</p></td></tr>
			   <tr><td><a href='../interface/ungtr.html'>ungtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>product of n-1 elementary reflectors of order N, as returned by
CHETRD:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../interface/ungtsqr.html'>ungtsqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>columns, which are the first N columns of a product of comlpex unitary
matrices of order M which are returned by CLATSQR
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
See the documentation for CLATSQR.</p></td></tr>
			   <tr><td><a href='../interface/ungtsqr_row.html'>ungtsqr_row</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>orthonormal columns from the output of CLATSQR. These N orthonormal
columns are the first N columns of a product of complex unitary
matrices Q(k)_in of order M, which are returned by CLATSQR in
a special format.
Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ).
The input matrices Q(k)_in are stored in row and column blocks in A.
See the documentation of CLATSQR for more details on the format of
Q(k)_in, where each Q(k)_in is represented by block Householder
transformations. This routine calls an auxiliary routine CLARFB_GETT,
where the computation is performed on each individual block. The
algorithm first sweeps NB-sized column blocks from the right to left
starting in the bottom row block and continues to the top row block
(hence _ROW in the routine name). This sweep is in reverse order of
the order in which CLATSQR generates the output blocks.</p></td></tr>
			   <tr><td><a href='../interface/unhr_col.html'>unhr_col</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>as input, stored in A, and performs Householder Reconstruction (HR),
i.e. reconstructs Householder vectors V(i) implicitly representing
another M-by-N matrix Q_out, with the property that Q_in = Q_out*S,
where S is an N-by-N diagonal matrix with diagonal entries
equal to +1 or -1. The Householder vectors (columns V(i) of V) are
stored in A on output, and the diagonal entries of S are stored in D.
Block reflectors are also returned in T
(same output format as CGEQRT).</p></td></tr>
			   <tr><td><a href='../proc/universal_mult_hash.html'>universal_mult_hash</a></td><td><a href='../module/stdlib_hash_64bit.html'>stdlib_hash_64bit</a></td><td>Function</td><td><p>Uses the "random" odd 64 bit integer <code>seed</code> to map the 64 bit integer <code>key</code> to
an unsigned integer value with only <code>nbits</code> bits where <code>nbits</code> is less than 64.
(<a href="../page/specs/stdlib_hash_procedures.html#universal_mult_hash-maps-an-integer-to-a-smaller-number-of-bits_1">Specification</a>)</p></td></tr>
			   <tr><td><a href='../proc/universal_mult_hash~2.html'>universal_mult_hash</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Function</td><td><p>Uses the "random" odd 32 bit integer <code>seed</code> to map the 32 bit integer <code>key</code> to
an unsigned integer value with only <code>nbits</code> bits where <code>nbits</code> is less than 32
(<a href="../page/specs/stdlib_hash_procedures.html#universal_mult_hash-maps-an-integer-to-a-smaller-number-of-bits">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/unm2l.html'>unm2l</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by CGEQLF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unm2r.html'>unm2r</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>Q * C  if SIDE = 'L' and TRANS = 'N', or
Q<strong>H* C  if SIDE = 'L' and TRANS = 'C', or
C * Q  if SIDE = 'R' and TRANS = 'N', or
C * Q</strong>H if SIDE = 'R' and TRANS = 'C',
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CGEQRF. Q is of order m if SIDE = 'L' and of order n
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unmbr.html'>unmbr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>If VECT = 'Q', UNMBR: overwrites the general complex M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
If VECT = 'P', UNMBR overwrites the general complex M-by-N matrix C
with
SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      P * C          C * P
TRANS = 'C':      P<strong>H * C       C * P</strong>H
Here Q and P<strong>H are the unitary matrices determined by CGEBRD when
reducing a complex matrix A to bidiagonal form: A = Q * B * P</strong>H. Q
and P<strong>H are defined as products of elementary reflectors H(i) and
G(i) respectively.
Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the
order of the unitary matrix Q or P</strong>H that is applied.
If VECT = 'Q', A is assumed to have been an NQ-by-K matrix:
if nq &gt;= k, Q = H(1) H(2) . . . H(k);
if nq &lt; k, Q = H(1) H(2) . . . H(nq-1).
If VECT = 'P', A is assumed to have been a K-by-NQ matrix:
if k &lt; nq, P = G(1) G(2) . . . G(k);
if k &gt;= nq, P = G(1) G(2) . . . G(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/unmhr.html'>unmhr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
IHI-ILO elementary reflectors, as returned by CGEHRD:
Q = H(ilo) H(ilo+1) . . . H(ihi-1).</p></td></tr>
			   <tr><td><a href='../interface/unmlq.html'>unmlq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k)<strong>H . . . H(2)</strong>H H(1)**H
as returned by CGELQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unmql.html'>unmql</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(k) . . . H(2) H(1)
as returned by CGEQLF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unmqr.html'>unmqr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CGEQRF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unmrq.html'>unmrq</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1)<strong>H H(2)</strong>H . . . H(k)**H
as returned by CGERQF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unmrz.html'>unmrz</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix defined as the product of k
elementary reflectors
Q = H(1) H(2) . . . H(k)
as returned by CTZRZF. Q is of order M if SIDE = 'L' and of order N
if SIDE = 'R'.</p></td></tr>
			   <tr><td><a href='../interface/unmtr.html'>unmtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by CHETRD:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/upgtr.html'>upgtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>product of n-1 elementary reflectors H(i) of order n, as returned by
CHPTRD using packed storage:
if UPLO = 'U', Q = H(n-1) . . . H(2) H(1),
if UPLO = 'L', Q = H(1) H(2) . . . H(n-1).</p></td></tr>
			   <tr><td><a href='../interface/upmtr.html'>upmtr</a></td><td><a href='../module/stdlib_linalg_lapack.html'>stdlib_linalg_lapack</a></td><td>Interface</td><td><p>SIDE = 'L'     SIDE = 'R'
TRANS = 'N':      Q * C          C * Q
TRANS = 'C':      Q<strong>H * C       C * Q</strong>H
where Q is a complex unitary matrix of order nq, with nq = m if
SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of
nq-1 elementary reflectors, as returned by CHPTRD using packed
storage:
if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1);
if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1).</p></td></tr>
			   <tr><td><a href='../interface/upper_incomplete_gamma.html'>upper_incomplete_gamma</a></td><td><a href='../module/stdlib_specialfunctions_gamma.html'>stdlib_specialfunctions_gamma</a></td><td>Interface</td><td><p>Upper incomplete gamma function</p></td></tr>
			   <tr><td><a href='../interface/var.html'>var</a></td><td><a href='../module/stdlib_stats.html'>stdlib_stats</a></td><td>Interface</td><td><p>Variance of array elements
(<a href="../page/specs/stdlib_stats.html#var-variance-of-array-elements">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/verify.html'>verify</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Scan a string for the absence of a set of characters. Verifies that all
the characters in string belong to the set of characters in set.</p><a href="../interface/verify.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/water_hash.html'>water_hash</a></td><td><a href='../module/stdlib_hash_32bit.html'>stdlib_hash_32bit</a></td><td>Interface</td><td><p>WATER_HASH interfaces
(<a href="../page/specs/stdlib_hash_procedures.html#water_hash-calculates-a-hash-code-from-a-key-and-a-seed">Specification</a>)</p></td></tr>
			   <tr><td><a href='../interface/write%28formatted%29.html'>write(formatted)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Write the character sequence hold by the string to a connected formatted
unit.</p></td></tr>
			   <tr><td><a href='../interface/write%28unformatted%29.html'>write(unformatted)</a></td><td><a href='../module/stdlib_string_type.html'>stdlib_string_type</a></td><td>Interface</td><td><p>Write the character sequence hold by the string to a connected unformatted
unit.</p></td></tr>
			   <tr><td><a href='../interface/xor.html'>xor</a></td><td><a href='../module/stdlib_bitsets.html'>stdlib_bitsets</a></td><td>Interface</td><td><p>Sets the bits in <code>set1</code> to the bitwise <code>xor</code> of the original bits in <code>set1</code>
 and <code>set2</code>. The sets must have the same number of bits
 otherwise the result is undefined.
(<a href="../page/specs/stdlib_bitsets.html#xor-bitwise-exclusive-or">Specification</a>)</p><a href="../interface/xor.html" class="pull-right"><emph>Read more&hellip;</emph></a></td></tr>
			   <tr><td><a href='../interface/zfill.html'>zfill</a></td><td><a href='../module/stdlib_strings.html'>stdlib_strings</a></td><td>Interface</td><td><p>Left pad the input string with zeros.
<a href="../page/specs/stdlib_strings.html#zfill">Specifications</a></p></td></tr>
			 </tbody></table>
             
        </div>
      </div>
    <hr>    
    </div> <!-- /container -->
    <footer>
      <div class="container">
      <div class="row">
        <div class="col-xs-6 col-md-6"><p>Fortran-lang/stdlib was developed by fortran-lang/stdlib contributors<br>&copy; 2024 <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
<br /><small>e88daa3</small></p>
        </div>
        <div class="col-xs-6 col-md-6">
          <p class="text-right">
            Documentation generated by 
            <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
 on 2024-04-02 08:24            </p>
        </div>
      </div>
      <br>
      </div> <!-- /container -->    
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
<!--
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
-->
    <script src="../js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../js/ie10-viewport-bug-workaround.js"></script>

    <!-- MathJax JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
        jax: ['input/TeX','input/MathML','output/HTML-CSS'],
        extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
      });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script src="../tipuesearch/tipuesearch_content.js"></script>
    <script src="../tipuesearch/tipuesearch_set.js"></script>
    <script src="../tipuesearch/tipuesearch.js"></script>
    
  </body>
</html>